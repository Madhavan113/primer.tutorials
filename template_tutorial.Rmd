---
title: XX
author: XX
tutorial:
  id: XX (should be the number + title, everything in lower case, all spaces and weird
    characters replaced with dashes. See Instructions for details.)
output:
  learnr::tutorial:
    progressive: yes
    allow_skip: yes
runtime: shiny_prerendered
description: 'Chapter XX Tutorial: XX'
---

```{r setup, include = FALSE}
# XX: First packages are ones which students don't know about or load up. learnr
# and tutorial.helpers are required for the tutorial to work at all. gt needed
# because we show a Preceptor Table to the students, which is built with this
# package, even though we don't show students how to do so.

library(learnr)
library(tutorial.helpers)
library(gt)

# XX: Any package from here is something that we want students to explicitly
# load up in the tutorial. This serves two purposes. First, it provides an
# occasion for knowledge drops. Second, it reminds students that these packages
# must be loaded in the Console if they want any of the code from the tutorial
# to work in the Console. (Of course, different lines of code require different
# packages.) The most common package to be added to this section, and which
# should also be loaded by students, is a data source like primer.data. It
# should be placed after library(tidyverse) since that is when it is loaded in
# the tutorial.

library(tidyverse)
library(brms)
library(tidybayes)
library(gtsummary)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

# XX: Never include setup code that takes more than a few seconds to run. For
# example, using brm() takes too much time. Instead, do the below. See
# https://ppbds.github.io/tutorial.helpers/articles/instructions.html#data for
# background.

# fit_height <- brm(height ~ age,
#                   data = no_na_nhanes,
#                   family = gaussian(),
#                   silent = 2,
#                   refresh = 0,
#                   seed = 16)
# write_rds(fit_height, "data/fit_height.rds")

# fit_height <- read_rds("data/fit_height.rds")
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Instructions to Users of this Template -->

<!-- This is the template tutorial for creating any tutorial which uses the Cardinal Virtues to answer a question given a data set. Although its primary use is for the main chapters in the Primer, it could be used for independent tutorials as well. The letters `XX` are used to indicate locations which require editing. Comments with instructions are interspersed. -->

<!-- Read https://ppbds.github.io/primer/cardinal-virtues.html for details on the Cardinal Virtues.  -->

<!-- Delete all these instructions once you are done with the tutorial. The only comments remaining should be ones that you wrote, comments specific to your tutorial --- like modeling approaches that you tried but did not use, other approaches that might be considered in the future and so on. -->

<!-- The tutorial is not done until you deal with, and remove, every XX. In general, XX will either mark a comment, which you should delete entirely once you have read it (and/or followed its instructions), or it will mark an object which you need to replace with the name that you have chosen. -->

<!-- Once you decide the appropriate replacement for `fit_XX` and `XX.qmd`, you can do a global replace to fix them all. -->

<!-- We sometimes connect XX to another word or phrase, as in [XX: unit] or `[XX: the tibble]`. In these cases, the XX indicates that this is something that you need to replace and the other words/symbols are there to guide you as to what the replacement should be. But you delete everything within the backets. For example, you might replace [XX: unit] with "candidate" (with no quotation marks) or whatever the type of unit we have in this problem. Similarly, `[XX: the tibble]` would be replaced with `trains` or whatever tibble is used in this tutorial. In both cases, we provide the correct punctuation. The word "candidate" would not have any punctuation since it is just a word in a sentence. But a tibble like `trains` needs to be surrounded by backticks. -->

<!-- Whenever creating an object which will be used in later questions, never have students do the assignment themselves. Instead, have a series of one or more questions which create the object, often by building a pipe line-by-line, with each step creating output which can be examined and discussed. Then, when the creation is done, have a last question which says, more or less, "Behind the scenes, we have assigned the result of the pipe [or whatever function call was used] to the object `fit_obj`. To confirm, type `fit_obj` and hit "Run Code." -->

<!-- Note that the questions are a mixture of our three types: code, written (with answer) and written (without answer). The last is only (?) used for questions in which we ask the student to run a command like `show_file()`. Otherwise, we always provide an excellent written answer because students will generally look closely at our answer because they are concerned about whether or not their written answer matches ours. -->

<!-- A plot, especially of the outcome or key covariate, often makes for an excellent knowledge drop. Just have a code chunk with no code chunk label. -->

<!-- Whenever you tell a student to make a change in the QMD, you should tell them to `Command/Ctrl + Shift + K` in order to render the document. This will also cause it to be saved. This is good practice for catching bugs early. (Professionals do this.) Then, the last step in these exercises is often some version of show_file() and then CP/CR. -->

<!-- Make use of, e.g., `show_file("tutorial-6.qmd", start = -5)` to get just the last 5 lines of the QMD. We don't want students to copy/paste the whole document. We also don't need to ensure that we get whatever it is that was just changed. We never look! Instead, we are just plausibly threatening to look.  -->

<!-- Most of the questions in the Temperance section relate to constructing a graphic. This leads lots of opportunities for knowledge drops. This is a good place to mention items from Courage which you might not have had room for in that section. -->

<!-- Make sure to uncomment the test code chunks once you have created the necessary objects. -->

<!-- Future Improvements To Make in This Document -->

<!-- In the same way that we give several quotes to choose from at the start of each section, we ought to give several different knowledge drops to choose from, in order of sophistication, for many of the standard questions, especially related to things like families and link functions. No need for authors to reinvent the wheel.  -->

<!-- We might also consider splitting up some of the Virtues into separate topics. After all, 20+ questions in a single topic is a bit much. -->

<!-- Would be nice if part of the testing would run all the object creation code so that we can be sure all that code works. But that would have to be during testing only. We don't want that code to execute during Run Tutorial because it often takes too long. -->


<!-- Things which DK is considering adding: -->

<!-- The specific question is always either causal or predictive. (Note that few people use the term "predictive." We just use it to distinguish from "causal." Maybe "non-causal" would be a better term. If it is causal, you should use key causal language in the question, like "What is the causal effect of . . ." If the model is non-causal, the question should clearly compare two groups of units. "What is the difference in immigration attitudes between Democrats and Republicans?") -->

<!-- Controlling/adjusting for things. -->

<!-- The question can not specify values for more than one covariate, simply because you do not know what covariates will be included in the model until to create it. Indeed, there is an argument that the question should not mention any covariates! But, we recommend the use of one. First, you must mention the covariate (i.e., the treatment) in a causal model. Second, it is not unreasonable to specify, before you start, a covariate whose connection, if any, to the outcome is of special interest. -->


<!-- The question just gets you started. It leads to the creation of the model.  -->

<!-- All data manipulation in EDA, including data shrinking, but that would be accompanied by a discussion of 1,000 observations per parameter. -->

<!-- Recall this line:  Need to ensure that, in the Courage section, students go through all three and understand how they are connected. Need to remind students about categorical variables turning into multiple 0/1 variables. Need to remind students that we can think in terms of individual rows or in terms of vectors. -->

<!-- Consider adding the model creation and saving code to a separate model.R script. Then, in analysis.R, you could just read it in. Would also be useful, in at least some tutorials, to highlight using a small sample of the data in initial fitting. -->

<!-- In the modern world, all parameters are nuisance parameters. -->

<!-- Does it make sense to have an introductory sentence which highlights the two sides of the general question? -->

## Introduction
### 

This tutorial covers [Chapter XX: XX](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

<!-- XX: If your tutorial is based on something other than the Primer then, obviously, you need a different Introduction and Summary. Recall this advice: https://ppbds.github.io/tutorial.helpers/articles/instructions.html#structure -->

## The Question
### 

<!-- XX: Pick one. -->

*A prudent question is one half of wisdom.* - Francis Bacon
*The power to question is the basis of all human progress.* - Indira Gandhi
*The important thing is not to stop questioning.* - Albert Einstein
*It is not the answer that enlightens, but the question.* - Eugene Ionesco

<!-- Both a causal effect and a prediction are much fuzzier notions than you might think because their are so many, depending on AGGREGATION. -->

<!-- If you don't care what Joe would have done in a counter-factual world in which we got a different treatment, if all you care about is predicting what Joe does *given the treatment he received*, then you just need a predictive model. -->

### Exercise 1

Load **tidyverse**.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

<!-- XX. Give some background on the data we will be using. Students need to understand the data if they are going to make progress in formulating The Question. -->

<!-- XX. If the data comes from a package (and it usually will, often from primer.data), then we will have a couple questions like this. Of course, if the data does not come from primer.data, than adjust accordingly. -->

### Exercise 2

Load the **primer.data** package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from XX is available in the `XX` tibble.

### Exercise 3

After loading **primer.data** in your Console, type `?XX` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX. More information about the data. One example would be a copy/paste of the abstract if the data is from a paper. Or perhaps a quote from the website on which the data can be found. -->

<!-- XX: In terms of picking a variable to use in the causal and predictive discussions below, I think it is best to use the actual treatment if this is going to be a causal model. With the predictive model, I am less sure. -->

### Exercise 4

XX is the broad topic of this tutorial. Given that topic, which variable in `XX` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "XX: A sentence about the outcome variable which we will be using.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

<!-- XX: The best knowledge drop is a plot, even a simple histogram or density plot of the output variable. You can never look at the data too much. Do not use any code chunk labels for this code chunk. The subtitle should highlight some aspect of the data. Plot does not need to be fancy. -->

### Exercise 5

Let's imagine a brand new variable which **does not exists** in the data. This variable should be binary, meaning that it only takes on one of two values. It should also, at least in theory, by manipulable. In other words, if the value of the variable is "X," or whatever, then it generates one potential outcome and if it is "Y," or whatever, it generates another potential outcome.

Describe this variable and how might we manipulate its value?


```{r the-question-5}

# XX: There is nothing wrong with naming an imaginary variable which is not in
# the data set if there is not a natural one. For example, if `height` is our
# outcome and `nhanes` is our tibble, then maybe there isn't a good candidate
# treatment variable. In that case, just assume the existence of a `vitamin`
# binary variable for which `1` means that the individual ate vitamins growing
# up and `0` means they did not. Using the words "treatment group" and "control
# group" as part of your answer is often helpful since it reinforces the fact
# that we are using the Rubin Causal Model.

question_text(NULL,
	message = "Imagine a variable called `XX`. We can manipulate the value of `XX`, at least in theory, by XX to the treatment group while not XX to the control group.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. 

 


### Exercise 6

Given our choice of (likely imaginary) treatment variable XX, how many potential outcomes are there for each [XX: unit]? Explain why.


```{r the-question-6}
question_text(NULL,
	message = "There are XX potential outcomes because the treatment variable `XX` takes on XX posible values: list-the-values-here, i.e., exposure to Spanish-speakers on a train paltform versus no such exposure.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Any data set can be used to construct a predictive model. 

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. All of this stuff is a *conceptual* framework we apply to the data. It is never inherent in the data itself.


### Exercise 7

Write a sentence which speculates as to value of the XX different potential outcomes which we might observe in `XX: outcome variable` for each [XX: unit] when we change the value of the treatment variable `XX`. 


```{r the-question-7}
question_text(NULL,
	message = "XX.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The point of the Rubin Causal Models is that the definition of a causal effect is the difference between potential outcomes. So, there must be two (or more) potential outcomes for any causal model to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. But, if the treatment variable is continuous, (like income) then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. 

### Exercise 8

Write a few sentences which specify two different values for the treatment variable, for a single unit, and then guesses at the potential outcomes which would result, and then calculates the causal effect for that unit given those guesses.


```{r the-question-8}

# XX: Replace [XX: unit] with a better word below given the actual data set we
# are using. Replace all the XX terms as appropriate.

# For a given individual, assume that the value of the treatment variables might
# be 'exposure to Spanish-speakers' or 'no exposure'. If the individual gets
# 'exposure to Spanish-speakers', then her attitude toward immigration would be
# 10. If the individual gets 'no exposure', then her attitude would be 8. The
# causal effect on the outcome of a treatment of exposure to Spanish-speakers
# versus no exposure is 10 - 8 --- i.e., the difference between two potential
# outcomes --- which equals 2, which is the causal effect.

question_text(NULL,
	message = "For a given [XX: unit], assume that the value of the treatment variables might be [XX: treatment] or [XX: control]. If the [XX: unit] gets [XX: treatment], then [XX: the outcome] would be [XX: a number]. If the [XX: unit] gets [XX: control], then [XX: the outcome] would be [XX: a different number]. The causal effect on the outcome of a treatment of [XX: treatment] versus [XX: control] is [XX: a number] - [XX: a different number] --- i.e., the difference between two potential outcomes --- which equals [XX: the causal effect], which is the causal effect.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The the definition of a causal effect as the difference between two potential outcomes. Of course, you can't just say that the causal effect is 10. The exact value depends on which potential outcome comes first in the subtraction and which second. There is, perhaps, a default sense in which the causal effect is defined as treatment minus control. 

Any causal connection means exploring the *within row* different between two potential outcomes. We don't need to look at any other rows to have that conversation.

### Exercise 9

<!-- Replace stuff like `[XX: the tibble]` with just the name of the tibble, i.e., `trains`. -->

Let's consider a *predictive* model. Which variable in `[XX: the tibble]` do you think might have an important connection to `XX: the outcome variable`? 


```{r the-question-9}
question_text(NULL,
	message = "XX: Describe the (or one of) the key covariate whose connection to the outcome variable we most want to explore.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

The key point is that, with a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be treatment variables. We assuming that all covariates are "fixed." 

### Exercise 10

Write a few sentences which specify two different groups of [XX: units] with different values for [XX: covariate]. Explain that the average value of the outcome variable might differ between these two groups.

```{r the-question-10}
question_text(NULL,
	message = "XX: Some [XX: units] might have a value for [XX: covariate] of [XX: a value]. Others might have a value of [XX: a different value]. Those two groups will, on average, have different values for the outcome variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In predictive models, do not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for the covariate of interest.

### Exercise 11

Write a [XX: choose causal or predictive] question which connects the outcome variable `XX` to `XXZ`, the covariate of interest. 

```{r the-question-11}
question_text(NULL,
	message = "XX: Give your question and, in the next sentence, report that we will use this question for the tutorial.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You can only use causal language --- like "affect," "influence," "be associated with," "cause,", "causal effect," et cetera --- in your question if you are creating a causal model, one with a treatment variable which you might, at least in theory, manipulate and with at least two potential outcomes.

With a predictive model, your question should focus on a comparison between different rows, or groups of rows, in the Preceptor Table.


### Exercise 12

What is a Quantity of Interest which might help us to answer our question?

<!-- XX: In general, our initial question does not include any specific numbers. It just uses words. For precision, we need to specify a Quantity of Interest that we are interested in. This is harder than it might look! It also helps to set the stage of Temperance. In all cases, the quantity of interest involves the outcome variable. (How could it not?) It also involves specific values of the covariates.  -->

<!-- XX: For predictive models, the specific question is generally of two types. First, what is the *expected* value of the outcome for various values of the independent variables? Second, what is the comparison in the expected outcome between two different groups? We are *not* simply interested in predicting the outcome variable for one unit. (In fact, of course, we might ultimately be interested in just one unit, but we need to *pretend* to be interested in lots of units in order to motivate the creation of a model.) -->

<!-- XX: For causal models, we are almost always interested in the average causal effect of treatment versus control. We are *not* simply interested in the causal effect for one specific unit. (In fact, of course, we might ultimately be interested in just one unit, but we need to *pretend* to be interested in lots of units in order to motivate the creation of a model.) -->


```{r the-question-12}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers which we are interested in, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.


## Wisdom
### 

<!-- XX: Pick one. -->

*The only true wisdom is in knowing you know nothing.* - Socrates
*Patience is the companion of wisdom.* - Saint Augustine
*Wonder is the beginning of wisdom.* - Socrates
*Wisdom begins in wonder.* - Plato
*The doorstep to the temple of wisdom is a knowledge of our own ignorance.* - Benjamin Franklin
*It is the province of knowledge to speak, and it is the privilege of wisdom to listen.* - Oliver Wendell Holmes Sr.
*All we can know is that we know nothing. And that’s the height of human wisdom.* - Leo Tolstoy

<!-- The Wisdom introduction is this section. It always includes a quote. Then it asks the specific question, indented and italicized. This is exactly the way the Primer works. There might also be some explanatory sentences around that, and the use of triple hashes to force a "Continue" button. If this is unclear, you need to read https://ppbds.github.io/primer/cardinal-virtues.html#question more closely. -->

Our question:

> *XX: Repeat the question with which you ended The Question topic.*

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: You have the opportunity, in this and the next few questions, to drop a lot of knowledge about the data and the overall topic. Do so! But, remember, students won't read more than 2 or so sentences in a knowledge drop. -->

<!-- Not only are you discussing the data, but you are also discussing potential problems with the data, problems which will be more fully fleshed out in the Justice section. You want to pick 5 to 10 interesting facts about the data. (You may need to go to the original source, not simply relying on the chapter. ) 

It is always a good idea to knowledge drop a link to the actual data and to any articles/books/websites related to it.

You won't be drawing any conclusions or discussing the explicit violation of any assumptions. That discussion is saved until Justice and the specific questions about stability, representativeness, and (with causal models) unconfoundedness. You are, however, providing the details which you and the students can then use later. -->

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually including in your model. It only includes covariates which you need to answer your question.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will considered a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX. Insert questions for setting up repo/project/.gitignore. In later tutorials, this might all be accomplished in one question. In earlier tutorials, you would want to break this up into different questions. But, you must set up a Github repo (with a sensible name like `tutorial-x`), connect it to an R project of the same name, edit the .gitignore to include `*Rproj` and then commit/push everything. A reasonable last question is show_file(".gitignore"). CP/CR. -->

### Exercise 4

What are the units for this problem?

```{r wisdom-4}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: A good knowledge drop for this exercise might involve other units which might be useful for related questions. For example, if the units for an presidential election are individual voters than, with a slightly different question, the units might be the 50 states. We want to show them the interplay between the exact question and which units define the Preceptor Table. -->

<!-- XX: A good knowledge drop for this exercise might involve other outcomes which might be useful for related questions. For example, if the outcome for a presidential election are votes cast than, with a slightly different question, the outcomes might be the electoral votes. We want to show them the interplay between the exact question and which outcomes define the Preceptor Table. -->

### Exercise 5

What is/are the outcome/outcomes for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question with which we started. No data science project follows a single direction. We always backtrack. There is always dialogue.

### Exercise 6

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

```{r wisdom-6}
question_text(NULL,
	message = "XX. Answer should be some sensible variables which are plausibly connected to the outcome. Some should be in the data but some shouldn't. You might also add that `You need to have variable X` if the question itself mentions that variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables for which we have data. Third, it is the set of covariates in the data which we end up using in the model.

### Exercise 7

What are the treatments, if any, for this problem?

```{r wisdom-7}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Again, we dialogue. Any question, or broad topic, will use words. And words are not precise! Lots of possible treatments, each different from the other, are close to the original words. Drop some knowledge, or even speculation, about what sorts of treatments might be relevant in similar problems.  -->


### Exercise 8

What moment in time does the Preceptor Table refer to?

```{r wisdom-8}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Add question: Explain why you want to use a predictive model or a causal model. Answer is almost always, you care about what happens to the same unit under two different treatments or you don't care. Often uses words like "causal," or "effect" or "affect" or "influence" or "impact" or . . . Actually, this should now be handled in The Question section. -->


### Exercise 9

Define causal effect.

```{r wisdom-9}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Drop some knowledge making it clear how this definition even applies, or might have applied, in the current problem. Note that we keep these causal questions even with a predictive model. We want to highlight that we could, if we chose, use this same data to explore a different question which required a causal model. -->

### Exercise 10

What is the fundamental problem of causal inference?

```{r wisdom-10}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: More discussion about potential outcomes. Counter-factuals are hard to think about. Help students by providing discussion of the ones under consideration here, or which might be under consideration with a different question. Are they plausible? What would make them more plausible? -->

### Exercise 11

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-11}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: With tutorial which uses a predictive model, it is fair for your answer to this question to be. "The motto does not apply because this is a predictive, not causal, model." -->

<!-- XX: For a causal model, can you really manipulate the treatments? In reality or in theory? How? What details would need to change to make this more or less plausible? -->

### Exercise 12

Describe in words the Preceptor Table for this problem.

```{r wisdom-12}
question_text(NULL,
	message = "XX. Make sure your words given an excellent description of the Preceptor Table which you are about to show the student.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

<!-- XX: Here are two examples which might help you to create your own. In general, your question will only specify the outcome and one covariate, so the Preceptor Table is actually fairly small. -->

<!-- First, for a predictive model: -->

<!-- ```{r} -->
<!-- tibble(ID = c("1", "2", "...", "10", "11", "...", "103,754,865"), -->
<!--        vote = c("Democrat", "Third Party", "...", "Republican", "Democrat", "...", "Republican"), -->
<!--        sex = c("M", "F", "...", "F", "F", "...", "M")) |> -->

<!--   gt() |> -->
<!--   tab_header(title = "Preceptor Table") |>  -->
<!--   cols_label(ID = md("ID"), -->
<!--              vote = md("Vote"), -->
<!--              sex = md("Sex")) |> -->
<!--   tab_style(cell_borders(sides = "right"), -->
<!--             location = cells_body(columns = c(ID))) |> -->
<!--   tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"),  -->
<!--             locations = cells_column_labels(columns = c(ID))) |> -->
<!--   cols_align(align = "center", columns = everything()) |> -->
<!--   cols_align(align = "left", columns = c(ID)) |> -->
<!--   fmt_markdown(columns = everything()) |> -->
<!--   tab_spanner(label = "Outcome", columns = c(vote)) |> -->
<!--   tab_spanner(label = "Covariate", columns = c(sex)) -->
<!-- ``` -->

<!-- Second, for a causal model: -->

<!-- ```{r} -->
<!-- tibble(ID = c("1", "2", "...", "10", "11", "...", "N"), -->
<!--        voting_after_treated = c("1", "1", "...", "1", "0", "...", "1"), -->
<!--        voting_after_control = c("1", "0", "...", "1", "1", "...", "0"), -->
<!--        treatment = c("Yes", "No", "...", "Yes", "Yes", "...", "No"), -->
<!--        engagement = c("1", "3", "...", "6", "2", "...", "2")) |> -->

<!--   gt() |> -->
<!--   tab_header(title = "Preceptor Table") |>  -->
<!--   cols_label(ID = md("ID"), -->
<!--              voting_after_treated = md("Voting After Treatment"), -->
<!--              voting_after_control = md("Voting After Control"), -->
<!--              treatment = md("Treatment"), -->
<!--              engagement = md("Engagement")) |> -->
<!--   tab_style(cell_borders(sides = "right"), -->
<!--             location = cells_body(columns = c(ID))) |> -->
<!--   tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"),  -->
<!--             locations = cells_column_labels(columns = c(ID))) |> -->
<!--   cols_align(align = "center", columns = everything()) |> -->
<!--   cols_align(align = "left", columns = c(ID)) |> -->
<!--   fmt_markdown(columns = everything()) |> -->
<!--   tab_spanner(label = "Covariates", columns = c(treatment, engagement)) |> -->
<!--   tab_spanner(label = "Outcomes", columns = c(voting_after_control, voting_after_treated)) -->
<!-- ``` -->


Like all aspects of a data science problem, the Preceptor Table evolves as we work on the problem. For example, at the start, we aren't sure what right-hand side variables will be included in the model, so we are not yet sure which covariates must be in the Preceptor Table.


### Exercise 13

<!-- XX: It is a feature that this question almost forces students to go to the chapter (or other sources) and read about the data. This entire sentence will not be included in your summary at the end of Wisdom, but bits of it will be mentioned. -->

Write one sentence describing the data you have to answer your question.

```{r wisdom-13}
question_text(NULL,
	message = "XX. Make sure that your example sentence is a good one. Obviously, the date that the data was gathered is important, as well as the person/organization doing the gathering. The number of observations might also be useful, along with an indication as to the sort of variables included. But no need to include all of that! Use your best judgement.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX. Insert a question or two which accomplishes the second chunk of QMD work. This begins with the creation of an `analysis.qmd` file (although you can use any name for it), its rendering to ensure that your computer setup is correct. The addition of *_files to the .gitignore so that we do not commit those junk files. It ends with a commit and push. show_file(".gitignore", start = -5) is not a bad last question. -->

### Exercise 14

Load the **tidyverse** package.

```{r wisdom-14, exercise = TRUE}

```

```{r wisdom-14-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-14-test, include = FALSE}
library(tidyverse)
```

### 

<!-- XX: Insert comments about the data. This continues to be the primary type of knowledge drop. These comments can also be sophisticated, especially in the way that they connect the data to the Preceptor Table and to the population. -->

<!-- XX: Load any other packages that are needed, one package per question. (But make sure that they are also included in the setup chunk.) primer.data, for example, is often needed. But save brms and tidybayes for the Courage section. -->

<!-- XX: It is now time for the third set of QMD edits. Add a new code chunk, the setup chunk, to the QMD. Copy/paste all the library commands to it. Render. Note all the ugliness. Add #| message: false. Add execute: echo: false to the YAML header. Add #| label: setup. Render again. Everything looks nice. Again, these could be several questions in the earlier tutorials or just one long question later. Ends with show_file("analysis.qmd", start = -5). This will be the most common ending question in QMD-editing exercises to come. -->

<!-- XX: Add code questions about EDA with your data. In particular, add at least one question about the dependent variable in the model along with one or more questions about covariates. If there is a treatment variable, you must include a question about it. -->

<!-- XX: Variable questions come in two types. First there are questions which require the student to run, say, summary() on the variable. Then, knowledge about the variable can be dropped. Second, there are questions which ask for a one sentence summary about the variable, something which could be used in our summary of the project. For example, it would be nice to ask a question which generated this answer:  "Civility is measured on a 1 through 7 scale with higher values corresponding to greater civility." -->

<!-- XX: If necessary, provide code exercises which, line-by-line, create the pipeline which creates the cleaned data that will be used in modeling. For many tutorials, this is unnecessary since we can just use the raw tibble that is available in whatever package. But we sometimes need some code like

nes |> 
  filter(year == 1992) |> 
  drop_na()

We have three code exercises, each adding one line to the pipeline, explaining what we are doing and why. It is nice that, for each exercise, something is spat out.
-->

<!-- XX: If such a pipeline was built, there is one QMD question which requires that you add a new code chunk to the QMD, copy/paste the pipeline and assign the result to some object like `model_data` or whatever:

nes_92 <- nes |> 
  filter(year == 1992) |> 
  drop_na()

`Command/ctrl + Shift + K` follows, perhaps with a show_file("analysis.qmd", start = -5)
-->

<!-- Every EDA should show a scatter plot of the outcome variable on the y-axis and one of (probably the most important or the treatment) covariates on the x-axis. There is no need for titles, axis labels or other prettiness. This could also just be a knowledge drop in which you just show the scatterplot to students, as we should the distribution of the outcome variable as a knowledge drop in The Question topic. -->


### Exercise 15

In your own words, define "validity" as we use the term.

```{r wisdom-15}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 16

<!-- XX: For the validity questions, specifics matter. There is always a reason why the outcome column in the data is not the same as the outcome columns in the Preceptor Table, even in the case of simple sampling. For example, consider a historical question connecting sex with presidential vote. Our data is a subset of our Preceptor Table. We have information on a few thousand voters and want to draw inferences about millions of other voters in the same election. But, even in this case, the outcome columns are different. The data is who people told a survey who they voted for. The Preceptor Table is who people actually did vote for. Those are not the same things. If they, in your view, are different enough than validity is violated. -->

Provide one reason why the assumption of validity might not hold for the outcome variable: `XX`. Use the words "column" or "columns" in your answer.

```{r wisdom-16}
question_text(NULL,
	message = "XX: Answers to validity question should always use the word 'column(s)'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

### Exercise 17

<!-- XX: Pick the most important covariate or at least one that you know/suspect will be used in the model. This is similar to the previous question, but we want to ensure that students understand that validity is about comparing the columns in the data set with the columns in the Preceptor Table. -->

Provide one reason why the assumption of validity might not hold for the covariate: `XX`. Use the words "column" or "columns" in your answer.

```{r wisdom-17}
question_text(NULL,
	message = "XX: Don't forget the word 'column'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Because we control the Preceptor Table and, to a lesser extent, the original question, we can adjust those variables to be “closer” to the data that we actually have. This is another example of the iterative nature of data science. If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.

### Exercise 18

<!-- XX: In creating your own answer to questions like this, check with the chapter. One might already be provided! If not, it is often useful to revisit the relevant section of the Key Concepts chapter in the Primer. -->

<!-- Example: *Using data from a 2012 survey of Boston-area commuters, we seek to understand the relationship between income and political ideology in Chicago and similar cities in 2020. In particular, what percentage of individuals who make more than $100,000 per year are liberal?* -->

<!-- It is very difficult to craft a question which causes students to give a sentence that is good. Do your best. -->

Summarize the state of your work so far in one sentence. Make reference to the data you have and to the specific question you are trying to answer. 


```{r wisdom-18}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit you answer as you see fit, but do not copy/paste our answer exactly. Add this summary to `XX.qmd`, `Command/Ctrl + Shift + K`, and then commit/push.

<!-- XX: As always, we like to do something in the tutorial before we do it in the QMD. But, in this case, we can just include the directions in the knowledge drop for the last question. -->


## Justice
### 

<!-- XX: Choose one. -->

*Justice is truth in action.* - Benjamin Disraeli
*The arc of the moral universe is long, but it bends toward justice.* - Theodore Parker
*Justice delayed is justice denied.* - William E. Gladstone
*It is in justice that the ordering of society is centered.* - Aristotle
*Charity is no substitute for justice withheld.* - Saint Augustine

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Select one of these two knowledge drops. -->

<!-- Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time referenced by the Preceptor Table. -->

<!-- *The longer the time period covered by the Preceptor Table (and the data), the more suspect the assumption of stability becomes.*  -->

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "XX. Again, students read these 'official' answers as closely as anything else you will write. Make your example precise and excellent.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A change in time or the distribution of the data does not, in and of itself, demonstrate a violation of stability. Stability is about the parameters: $\beta_1$, $\beta_1$ and so on. Stability means these parameters are the same in the data as they are in the population as they are in the Preceptor Table.

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.




### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case. 

```{r justice-6}
# XX: In your answer, try not use of the concept time, even though, in theory,
# it is a perfectly reasonable to do so. Instead, focus on why the data might
# not be representative of the population at that moment in time.

question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The reason that representativeness is important is because, when it is violated, the estimates for the model parameters might be biased. 


### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-7}
# XX: Again, try not use of the concept time. We want to save examples of
# changes caused by time for the discussio about stability. Instead, focus on
# why the Preceptor might not be representative of the population at that moment
# in time.

question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods.


### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. The easiest way to ensure unconfoundedness is to assign treatment randomly.

### Exercise 9

<!-- XX: Delete this question for non-causal models. -->

Provide one reason why the assumption of unconfoundedness might not be true (or relevant) in this case.

```{r justice-9}
question_text(NULL,
	message = "XX. There is nothing harder for students than coming up with examples of possible confounds. So, your example should be a good one, should specify precisely how treatment assignment is correlated with the potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Most of our simple examples use random assignment. So, if fact, confoundedness is not a concern. But this knowledge drop, and perhaps the couple before, should address this topic, by pondering what we would worry about if treatment assignment had not been random.  -->

### Exercise 10

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention one specific problem which casts doubt on your approach. 


```{r justice-10}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `XX.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.


## Courage
### 

<!-- XX: Choose one. -->

*Courage is found in unlikely places.* - J.R.R. Tolkien
*Courage is being scared to death, but saddling up anyway.* - John Wayne
*Courage is going from failure to failure without losing enthusiasm.* - Winston Churchill
*Courage is the commitment to begin without any guarantee of success.* - Johann Wolfgang von Goethe


<!-- XX: Insert a sentence or two which reminds the student about the outcome variable and the key covariate(s), if any. Remind them of the variable type of the outcome variable. This sets the stage, in Exercise 2, for the discussion of the probability family. Also, remind them of the key covariate. Of course, in more advanced tutorials, we might consider including this material (and the probability family and link function knowledge drops below) as fodder for Exercises. But that is a step too far for now. -->

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

<!-- XX: Give the probability family of your model. Explain how that choice is dictated by the values of your outcome variable. Give the mathematical formula, using your actual outcome variable. The examples below should be followed word-for-word. But the "Comment" gives you some material to include, after the math, but in your own words and at your discretion, with whatever level of complexity you think appropriate.

1) Because `biden` is a binary variable, we assume that the outcome of voting for Biden (or not) is produced from a Bernoulli distribution.

$$ biden_i  \sim Bernoulli(\rho) $$
Comment: Mention that "binomial" is another, more common, word for Bernoulli.

2) Because `att_end` is a continuous variable, we assume that an individual's attitude toward immigration is produced from a Normal distribution.

$$ att\_end_i \sim Normal(\mu, \sigma^2)$$

Comment:

Because `vote` is a categorical variable, we assume that an individual's vote is produced from a Categorical distribution.

$$ vote_i  \sim Categorical(\rho_{bush}, \rho_{clinton}, \rho_{perot}) $$

Because `approval` is an ordinal variable, we assume that an individual's approval is produced from a Cumulative distribution.

$$ approval_i  \sim Cumulative(\rho_{strongly_positive}, \rho_{positive}, \rho_{neutral}, \rho_{negative}, \rho_{strongly_negative}) $$

-->


### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

<!-- XX: Discuss the link function. This is a "generic" link function which does not mention any of the variables in our actual problem. Examples:

Because we are using a Bernoulli (or Categorical or Cumulative) distribution, the link function is logit. That is:

$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 x_1 + \dots)}}$$

Because we are using a Normal distribution, the link function is the identity. That is:

$$ \mu =  \beta_0 + \beta_1 x_1 + \dots $$

-->

<!-- DK: What knowledge do we drop after giving the link formula? -->


### Exercise 4

Add `library(brms)` and `library(tidybayes)` to the `setup` code chunk in `XX.qmd`. Copy and paste the below code for the mathematical structure of the model to the body of `XX.qmd`. `Command/Ctrl + Shift + K`. 


```
XX: Give them the math within these triple backticks so that they can just copy and paste it into their QMD. Use double dollar signs so that each formula is on its own line. Example:

XX: $$ att\_end_i \sim Normal(\mu)$$
XX: $$ \mu =  \beta_0 + \beta_1 x_1 + \dots $$
```

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", pattern = "brms|tidybayes|\\$\\$")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Of course, our model must make use of the variables we actually have. Consider:

<!-- XX: Give an example of the actual math by replacing the x variables in the generic link function with actual variables. If the formula is short, you can include all of them. If it is short, you can include just a few and then end with $\ldots$. Use your best judgment. Examples:  

$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 sexmale + \dots)}}$$

$$ \mu =  \beta_0 + \beta_1 att_start + \beta_2 sexmale $$

$$\rho_{clinton} = \frac{1}{1 + e^{-(\beta_{0, clinton} + \beta_{1, clinton} male)}}$$

-->

<!-- XX: Keep in mind that students always forget and/or are confused about how a categorical covariate is handled. We can't have words in math formulas. So, a variable like sex is turned into a 0/1 variable which is then renamed sexmale. And similar for categorical covariates with N values. Such cases produce N-1 dummy 0/1 variables. -->

<!-- XX: Mention other important details here. For example, in a categorical or ordinal models, the probabilities must sum to 1. Also, we might only give the formula for one $\rho$. Mention that the other formulas would be the same, but with different parameters. -->

### Exercise 5

Create a model using `brm()` from the **brms** package. Your arguments should be XX. 

<!-- Search and replace "fit_XX" as appropriate. As a convention, the name of a fitted model object should always start with `fit_`. -->

<!-- Don't forget to create this model yourself in the setup chunk. Do this once, save the object, comment out that code and then just read_rds to create the object for his tutorial. -->


```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}

```

<!-- XX: Note how there is no test case. If there were one, then a student would fit the model each time she hit "Run Tutorial." That takes too much time. -->

### 

In data science, we deal with words, math, and code, but the most important of these is code. We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters.

### Exercise 6

Behind the scenes, we have assigned the result of the `brm()` call to an object named `fit_XX`. Type `fit_XX` and hit "Run Code." This generates the same results as using `print(fit_XX)`.


```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
fit_XX
```

```{r courage-6-test, include = FALSE}
# fit_XX
```

### 

<!-- XX Say some general words about the object. Note that we are about to go through the top 4 rows. -->


### Exercise 7

Run `family()` on `fit_XX`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
family(...)
```

```{r courage-7-test, include = FALSE}
# family(fit_XX)
```

### 

<!-- XX: This is a great location for explanations which get much more detailed in later chapters. That is, we want students to have a more sophisticated understanding of probability distributions, and there use in modeling, as we move through the Primer.

But, at a minimum, you would comment about how the family that is shown --- which is either gaussian, bernoulli or categorical --- is determined by the family argument which you passed in to the brm() call, and that you determined that by looking at the distribution of the output variable. Continuous means gaussian, 2 possible values means bernoullu, and 2+ possible values means categorical.

-->

In this case, XX . . .

### Exercise 8

Run `formula()` on `fit_XX`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
formula(...)
```

```{r courage-8-test, include = FALSE}
# formula(fit_XX)
```

### 

In this case, XX . . .

### Exercise 9

Run `nobs()` on `fit_XX`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-9-test, include = FALSE}
# nobs(fit_XX)
```

### 

In this case, XX


### Exercise 10

Create a new code chunk in `XX.qmd`. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model using `brm()` into the code chunk, assigning the result to `fit_XX`. 

`Command/Ctrl + Shift + K`. It may take some time to render `XX.qmd`, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render `XX.qmd`, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r courage-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 11

<!-- XX: Note that, in my advanced models, there are some subtle differences between what fixef() and posterior_interval() do. But we won't worry about that here. -->

Run `posterior_interval()` on `fit_XX`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-11-test, include = FALSE}
# posterior_interval(fit_XX)
```

### 

In this case, XX . . .


### Exercise 12

Run `fixef()` on `fit_XX`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-12-test, include = FALSE}
# fixef(fit_XX)
```

### 

In this case, XX . . .

<!-- XX: Add at least three questions which require the student to interpret the meanings of a parameter estimate and/or its associated confidence interval. This is something that students are very bad at! And so we need to give them practice, both by asking them to do it and by providing excellent answers. These questions also feature good opportunities to knowledge drop about the meaning of intervals (credible versus confidence versus uncertainty) and about Frequentist versus Bayesian interpretations. See https://ppbds.github.io/primer/cardinal-virtues.html#confidencecredibleuncertainty-intervals-->

<!-- XX: The key point is that predictive models involve comparisons *between different rows* in the Preceptor Table while causal models involve subtraction between two potential outcomes *within the same row*. -->

<!-- Consider some example questions and answers, along with comments about the larger picture, all based on this display. This is good for linear (meaning the Gaussian family) models. For other models, see the comments below. -->

<!-- fit_obj <- brm(formula = att_end ~ sex + treatment + age, data = trains) -->

<!-- Note to authors: I use round() below to make the table easier for you to read. You do not need to make students use round(), unless you think doing so is a good idea. -->

<!-- > round(fixef(fit_obj), 2) -->
<!--                  Estimate Est.Error  Q2.5 Q97.5 -->
<!-- Intercept           10.99      0.95  9.17 12.83 -->
<!-- sexMale             -0.83      0.54 -1.88  0.22 -->
<!-- treatmentControl    -1.42      0.54 -2.45 -0.32 -->
<!-- age                 -0.01      0.02 -0.06  0.03 -->

<!-- Q: Write a sentence interpreting the -0.83 estimate for sexMale. -->

<!-- A: When comparing men with women, men have a 0.83 lower value for att_end, meaning that they are more liberal about immigration, relative to women, conditional on the other variables in the model. -->

<!-- Comment 1: Note how, whenever we consider non-treatment variables, we must never use terms like "cause," "impact" and so on. We can't make any statement which implies the existence of more than one potential outcome based on changes in non-treatment variables. We can't make any claims about within row effects. Instead, we can only compare across rows. Always use the phrase "when comparing X and Y" or something very similar. -->

<!-- Comment 2: The phrase "conditional on the other variables in the model" is important. It could be shorted to "conditional on the model." This phrase acknowledges that there are many, many possible models, just considering all the different combinations of independent variables we might include. Each one would produce a different coefficient for sexmale. None of these is the *true* coefficient. Any claim we make about  -0.83, or any specific number, is always conditional on the fact that we assume that this model is true, that these covariates, and no others, belong in the regression. Does that mean that we always use the phrase? No. We leave it out all the time. But it is always understood to be there by knowledgeable readers. Still, this is probably a point worth making in various knowledge drops. -->

<!-- Q: Write a sentence interpreting the confidence interval for sexMale. -->

<!-- A: We do not know the true value for the coefficient for sexMale, but we can be 95% confident that it lies somewhere between -1.88  and 0.22.  -->

<!-- Comment 1: Because we are Bayesians, we believe that there is a true value and that the confidence or credible pr uncertainty interval includes it at the stated level. These questions provide an occasion in the knowledge drop to compare/contrast the Frequenist interpretation. See: https://ppbds.github.io/primer/cardinal-virtues.html#confidencecredibleuncertainty-intervals -->

<!-- Comment 2: Most of the time parameters in a model have no direct relationship with any population parameter which we might be interested. This is especially true in complex and/or non-linear models. That is, in those cases, a coefficient like $\beta_1$ does not "mean" anything. But, in simple, small, linear models, it sometimes happens that a parameter does correspond to something real. In this case, the coefficient of sexmale does correspond to the difference between the population average of att_end between men and women, adjusting for the other variables in the model. Should we discuss this more? -->

<!-- Q: Write a sentence interpreting the -1.42  estimate for treatmentControl. -->

<!-- A: If this is a causal model, then the average causal effect of receiving the treatment of hearing Spanish-speakers on the train platform, relative to the control, is to have a 1.42  higher value for att_end, meaning that the treatment, relative to the control, makes one more conservative about immigration. (Note that you need to keep track of signs and of which 0/1 variable is being used.) -->

<!-- A 2: If this is a predictive model, then, if we compare people who receive the treatment with people who receive the control, the treated people have, on average, a 1.42 more conservative attitude toward immigration, adjusting for other individual characteristics. -->

<!-- Comment 1: The interpretation of a treatment variable is very different than the interpretation of a standard covariate. Whenever your model includes a treatment variable, you must always have a question about it and about the associated confidence interval. -->

<!-- Comment 2: The key point is that there is no such thing as a causal (versus preditive) data set nor a causal (versus predictive) R code formula. You can use the same data set (and the same R code!) for both causal and predictive models. The difference lies in the assumptions you make.  -->

<!-- Q: Write one sentence interpreting the -2.45 to -0.32 interval for the treatmentControl coefficient. -->

<!-- A: Our best estimate for the average causal effect is -1.42, meaning that being treated makes someone 1.42 units more conservative about immigration. Yet, the true value could be lower or higher. We are 95% certain that the true effect is somewhere between -2.45 to -0.32.  -->

<!-- Comment: It is OK if our answers are slightly longer than what we might expect from students, as long as those answers are *tight*, meaning that no word is wasted. In this case, the first two sentences are an attempt to ensure that the student understands what is going on. The last sentence is what we might expect students to write.  -->

<!-- Q: Write a sentence interpreting the -0.1 estimate for age.  -->

<!-- A: If we compare one group of people ten years older than another, the older group will, on average, have an attitude toward immigration 1 unit lower, i.e., less conservative. -->

<!-- Comment 1: Numeric variables are harder than binary variables because there are no longer just two well-defined groups to compare with each other. We must make those two groups ourselves. Fortunately, as long as there are no interaction terms, we can just pick two groups with any values for the variable. The most common two groups differ by one unit of the variable. But it is quite common to use groups which differ by more/less if doing so seems sensible and/or if it makes the math easier. In this case, two groups which differ by 10 years makes sense for both reasons. -->

<!-- Comment 2: With a linear model, all these interpretations are fairly straightforward. With any other type of model, the math is too difficult to do in your head. You can't just look at a coefficient of 5 and know what it means in magnitude. But you can tell the direction, that a positive 5 means that higher values of the variable are associated with higher values of the outcome variable. So, with anything other than linear models, we restrict ourselves to direction and significance interpretations. -->

### Exercise 13

Run `pp_check()` on `fit_XX`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-13-test, include = FALSE}
# pp_check(fit_XX)
```

### 

In this case, XX

<!-- If the fake data had looked very different from the real data, we have had a problem. But, for the most part, we conclude that, although not perfect, pp_check() shows that the fake outcomes generated by our model are like the actual outcome data. -->


### Exercise 14

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-14-test, include = FALSE}
library(gtsummary)
```

### 

<!-- Drop some knowledge about gtsummary. Or say something more about your DGM. -->

### Exercise 15

<!-- XX: This can be just one question or several, especially if you want to teach some more gtsummary or gt tricks. Make any adjustments to this question, like `intercept = TRUE`, so that this question works. -->

Pipe `fit_XX` to `tbl_regression()`.


```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
fit_XX |> 
  tbl_...()
```

```{r courage-15-test, include = FALSE}
# fit_XX |> 
#   tbl_regression()
```

### 

<!-- XX: Drop some knowledge about what you have learned by looking at the resulting table. Of course, you could have learned the same thing when you first took a look at fit_XX. But the table makes it easier to see the relationships between the variables and the outcome. With luck, students will take the hint when they answer the next question. -->

<!-- https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html -->


### Exercise 16

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add one sentence which describes the modelling approach which you are using, specifying the functional form and the dependent variable. Add one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-16}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 17

Update `XX.qmd`. First, add `library(gtsummary)` to the `setup` code chunk,. Second, add the mathematical formula, in $\LaTeX$ and surrounded by double dollar signs, for your model. Third, add a new code chunk which creates the table of model parameters. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r courage-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

## Temperance
### 

<!-- XX: Choose one. -->

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha
*Temperance is the greatest of all virtues. It subdues every passion and emotion, and almost creates a Heaven upon Earth.* - Joseph Smith Jr.
*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton
*Temperance is the firm and moderate dominion of reason over passion and other unrighteous impulses of the mind.* - Marcus Tullius Cicero
*Temperance to be a virtue must be free, and not forced.* - Philip Massinger
*Temperance is simply a disposition of the mind which binds the passion.* - Thomas Aquinas


### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the Data Generating Mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Data Generating Mechanism is our model of the world. If you are a genius, you can just look at the math and know what it means. Normal people need more. They need you to display, graphically, what the model means. This graphic display will almost always be a collection of posteriors.


### Exercise 2

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-2}
question_text(NULL,
	message = "XX: Should be exactly how you started the Wisdom section.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 3

To answer our question, we need to create an object --- call it `ndata` --- which we will pass in as a value to the `newdata` argument in to `add_epred_draws()` or to whichever **tidybayes** function we use. Which variables (e.g., which columns) do we need to include in this object?

```{r temperance-3}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Must be all the right hand side variables in fit_XX. And note that the type must (maybe not always . . .) match, like if `treatment` is a factor in the original data used to create fit_XX then it must (?) be a factor in ndata. -->

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.


### Exercise 4

<!-- XX: Sometimes useful to think about this question and the number of posterior questions together, or event to reverse them. -->

Which values do you want the variables in your `ndata` object to have? This is not easy! At the very least, one or more of the rows should have values which allow you to answer your original question. But, now that you have a model, there are many questions which you might want to answer, the better to get a fuller understanding.

```{r temperance-4}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- At this stage, we really don't care about the original question.  -->


<!-- XX: Chapter 10 is a great example of this in its full complexity. We want to know how "different" units behave, where the very definition of "different" is that they do not have identical values for all the variables used in fit_XX. -->

<!-- For example, one row in ndata will generally represent the answer to the specific question we started with. But that is just the posterior for one sort of unit. There are lots of different units! Which others might we be interested in? We can generate posteriors for each of them, and then, in some cool graphic, display all those posteriors together. -->

<!-- Note that, previously, this document claimed that the number of rows in ndata corresponded to the number of posteriors you wanted to calculate. But that is not true! -->

### Exercise 5

Here is the R code which creates the `ndata` object: `[XX: tibble(whatever) code here]`. Type it into the code exercise block and hit "Run Code."

<!-- Asking students to create this object --- even after you help them figure out the columns, rows and values --- is too hard, at least until they get more experiences. Your knowledge drop, for this question and the next, should give them advice on the broad topic of how they can create newdata objects themselves. -->

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}

```

```{r temperance-5-test, include = FALSE}

```

### 

### Exercise 6

Behind the scenes, we have created the `ndata` object using this code. To confirm, type `ndata` and hit "Run Code."

<!-- Of course, you need to have added the code to create `ndata` in the setup chunk at the top of the file. -->

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}

```

```{r temperance-6-test, include = FALSE}

```

### 

Note that, when you add Temperance-related code to your QMD, you will need to also add code which creates the `ndata` object.


### Exercise 7

Create a new code chunk in `XX.qmd` which creates the `ndata` object. `Command/Ctrtl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", pattern = "ndata")
```

CP/CR.


```{r temperance-7}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 8

Now that we have the `ndata` object, we can create a pipe which uses our fitted model to answer our question. Begin by typing `fit_XX` and clicking "Run Code."

```{r temperance-8, exercise = TRUE}

```

```{r temperance-8-hint-1, eval = FALSE}
fit_XX
```

```{r temperance-8-test, include = FALSE}
# fit_XX
```

### 

<!-- XX: Again, the main point of knowledge drops is this area is to explain to students why the ndata object looks the way it does and what it will produce. A great way to teach is via example. That is, explaining that if we had another way with these values, then we would get this posterior. Or, explaining what would be produced if we used add_epred instead of add_predict, and vice verse. -->


### Exercise 9

Pipe `fit_XX` to [XX: either `add_epred_draws()` or `add_predicted_draws()`] with the argument `newdata = ndata`. 



```{r temperance-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-9-hint-1, eval = FALSE}

```

```{r temperance-9-test, include = FALSE}

```

### 

<!-- XX: How do students know whether to use add_epred_draws or add_predicted_draws? This is non-trivial. On some level, we just tell them with the above command. (We don't make them guess.) But we also address this issue explicitly in various knowledg drops, especially this one. -->

<!-- XX: Insert as many questions as necessary to build a nice-looking example of your final plot. In early chapters, this is simple since our questions are simple. They are just one posterior. In later chapters, they become more complex, with the inclusion of several posteriors, as well as manipulation of them to calculate causal effects and whatnot. See the voting postcard example. -->

### Exercise 10

Create a new code chunk in `XX.qmd`. Label it with `label: plot`. Copy/paste the code which creates your graphic. Don't forget that, at the top of this chunk, you must include code which creates the `ndata` object.

`Command/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", start = -8)
```

CP/CR.

```{r temperance-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 11

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) and which provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

<!-- XX: Most of the time, there will be some measure of uncertainty associated with your QoI. But not always! The most common counter-example involves a question which asks about the odds or probability of something happening. We would answer such a question by simulating the event with `add_predicted_draws()`. We would then calculate the odds/probability of something happening by seeing how many of the 4,000 draws met the criteria for the event. Assume that was 40%. So, we think that there is a 40% chance that event A will happen. Yet there is no uncertainty associated with that estimate because it, itself, is an expression of uncertainty. But, the vast majority of projects are not concerned with individual prediction. Instead, they focus on expected/average values. -->

```{r temperance-11}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `XX.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.


<!-- XX: Again, spend time to make your recommended paragraph perfect. Study the examples in https://ppbds.github.io/primer/cardinal-virtues.html closely. -->

### Exercise 12

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-12}
question_text(NULL,
	message = "XX: This is another example in which the quality of your answer is important. You might or might not suggest an alternate estimate. I always adjust the estimate toward my own subjective sense of a long-run average and/or typical value and/or zero. But that is not necessary. However, you should always increase the confidence interval since the assumptions of your model are always false.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 13

Rearrange the material in `XX.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd")
```

CP/CR.

```{r temperance-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

### Exercise 14

Publish `XX.qmd` to Rpubs. Choose a sensible slug. Copy/paste the url below.

```{r temperance-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

## Summary
### 

This tutorial covered [Chapter XX: XX](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
