### Assignments
Sharav Joshi
Tanay: Tutorial 12!

Mihir: Tutorial 11! Revisit primer.data construction of cces.

Khang: Add The Question section to tutorial 5. Read about Git in Happy. Read about branching in SCM. Why can't you see the tut-5 branch? Once you can, start a new branch, called like "the-question" Add just the header: 

## The Question 
###

to that branch. Then, submit a pr_push() which is a pr for making a change in the tut-5 branch, not that master branch. I should receive that and accept it. Once I do, continue to edit the the tutorial in the-question branch, just like you normally.

Still need to figure out. First, how do we get changes from the master branch into the tut-5 branch. Second, once we are done with all the changes, how do we merge tut-5 back into master.


Sanaka:  r4ds.tutorials (rewrite Cardinal Virtues section of Tutorial 2)

Satvika: 

### Projects to Consider

* Rationalize the data project and the model project tutorials.

* Need 5 more tutorials, each like n-parameters.

* Update 4 parameters so it does not produce these warning messages by default: https://rpubs.com/lelasengupta/four-parameters

* Explore gradetools: https://federicazoe.github.io/gradetools/index.html

* Seems like you can't include LaTeX math in a R exercise message. Generates an error under R CMD check. Example of something which fails:

Add the formula to `model.qmd`, `$$ biden_i =  \mu + \epsilon_i $$`. `Command/Ctrl + Shift + K`. Ensure that the formula is looks correct. 

<!-- # ```{r courage-12} -->
<!-- # question_text(NULL, -->
<!-- # 	message = "$$ biden_i =  \mu + \epsilon_i $$", -->
<!-- # 	answer(NULL, correct = TRUE), -->
<!-- # 	allow_retry = FALSE, -->
<!-- # 	incorrect = NULL, -->
<!-- # 	rows = 6) -->
<!-- # ``` -->

* Deal with katex. Seems like all (?) Windows users are getting an error about needing the katex package. But nothing for Mac users. So, I added katex as an import, which is an absurd hack. Better approach?

* We have a couple of packages in imports in DESCRIPTION because having them there ensures that they get installed automatically. And, it seems that various students have gotten hard to diagnose errors that were solved once those packages were installed. What is going on? We don't like hard to diagnose errors! 

https://discord.com/channels/1066524559240597595/1066524726278762608/1262875853780418669

But we also don't want to import a dozen packages.


* Fix primer.data for two topics: governor and shaming.

* Animation. Use the DGM to create one complete Preceptor Table. In that draw, Joe is a 6 for `att_end`. Then, do another draw. Joe is a 5. Do a thousand draws. You then have a thousand Preceptor Tables. Calculate the Quantity of Interest for each Preceptor Table. The 1,000 values are the posterior for your QoI. Would be great to make a cool animation of this, perhaps with a simple example. Would be fun to have a similar animation for each chapter. Great summer project!

* Add tutorials to tidycensus.tutorials for chapters 3, 4, 5 and 6.

* Make the Primer better and more connected to the tutorials. (This might be something that everyone ends up working on.) - Sanaka

* r4ds.tutorials is good, but there are some weaker chapters. Clean the whole thing up. - Sanaka, Tanay

* Positron is the IDE of the future. Create Getting Started and RStudio Code/Github tutorials which use it. - Sanaka

* I hope to have hundreds of students next summer. I need to work on tools now for managing that. See PraireLearn, Moodle, Google sheets and so on. - Sanaka, Tanay

  + 1) Where should students upload files? We currently use Google forms which puts stuff in a Google drive folder. This works pretty well! But I need to download the resulting folder by hand, which is no good. Surely, we can automate this. But can we automate it for all TFs. (We want TFs to be able to see and analyze the homeworks submitted by their students.) A second option would be DropBox. Others?
  
  + 2) Where do we keep track of the students in the class and key information associated with them? That information would be name, email, TF, breakout room, presentation room. Maybe only me and the head TFs need to edit it. I think that this might just be a Google sheet. We would want all staff to be able to access it since doing so would provide the info to allow scripts to just return a given TF's students' work.
  
  + 3) Where do we populate information about work completed? That is, we want to be able to report who has submitted each homework, perhaps also with the number of answers. We need to put that information somewhere, update it with scripts, and then allow TFs to be able to access it. 
  
  + 4) As a one-off, it would be nice to allow staff to save: Give me all the answers to this question for my students. Or for me to say the same about all students. Most common is to gather all the Rpub locations for student work. Even cooler would be to automatically open up a tab for each, with the tab given the name of the student.

* tutorial.helpers works well. But it could do a lot more! This might be a good project for someone with some coding experience. See https://github.com/PPBDS/tutorial.helpers/blob/main/TODO.txt

* https://datalorax.github.io/equatiomatic/ does not work with objects of class brmsfit. Create a PR which adds that functionality.






## Priorities

Create Final Project to go along with the Data Project.


## Other Stuff

Talk about saving models and then reloading them in the template_tutorial.

Once we get rough drafts of all the tutorials done, we can revisit the questions by type. For example, there will be a "define the Population Table" and a "run fixef()" question in each tutorial. We can then edit the knowledge drops on those questions so that they go well together, increasing the sophistication of the commentary as the tutorial number increases. We can even, in later tutorials, make reference to the discussion of earlier tutorials.


Add an Introduction and Summary section to each tutorial. It should follow the pattern from R4DS in terms of always linking to the relevant chapter and to the Primer as whole.

Update Overview tutorial for chapter 5 to cover new material about random variables.

Include somewhere:

There will often be several tutorials associated with a given chapter. The first is an "Overview" tutorial which follows closely along with the words and examples in the chapter itself. Someday, we will [put those exercises directly](https://github.com/tinystats/teacups-giraffes-and-statistics) into the *Primer* itself, so keeping the two in sync makes sense. We can group other tutorials into three broad categories. First, some tutorials go into more detail about certain aspects of the chapter. Second, some tutorials provide further examples/extensions of the main theme of the chapter as a whole. Third, the remaining tutorials cover a topic --- like Quarto Websites or Tables --- which has no necessary connection to the chapter itself.

## Some notes on branching.

* There is no simple way to do branching from the Console. Even with **usethis**, there isn't much.

* Not sure what the usethis::git_default_branch* family of functions do.

* I started a new branch from the Terminal with

Davids-MBP:primer.tutorials dkane$ git checkout -b data-overview
Switched to a new branch 'data-overview'
Davids-MBP:primer.tutorials dkane$

* Refreshing the Git pane switches us over. Pushing/pulling no longer work. Why?

* Once we are done with a branch, we can merge it back with:

git checkout master
git merge data-overview -m "some message"

I think.

## Utilities

In the tutorial.Rmd YAML header should:

progressive:  true
    allow_skip::  true

Replace the "yes" with TRUE. I bet it does not matter.


### Questions

I want to push the branch so that, if my computer blows up, I don't lose all this work. How?

## To-Do


Check out PraireLearn. Looks really cool!


Add PDF tiny_tex() to which tutorial? RStudio and code?

Advanced: Get Format Code Chunk Labels add-in to catch the case in which a non-question code chunk is duplicated.

Update Tables tutorial. Does it include all the stuff from Making Tables section Tools chapter in Primer?

## Later

Fix gh pages creation error.

Investigate this install message:

> remotes::install_github("PPBDS/primer.tutorials")
Downloading GitHub repo PPBDS/primer.tutorials@HEAD
Skipping 1 packages ahead of CRAN: stars


Testing for prep_rstudio_settings.

r-universe for making primer.tutorials easier to install.



Maybe r2u is as good or better than caching. https://eddelbuettel.github.io/r2u/

https://github.com/eddelbuettel/r2u/blob/master/inst/scripts/add_cranapt_jammy.sh



https://github.com/eddelbuettel/tidycpp/blob/master/.github/workflows/ci.yaml

https://community.rstudio.com/t/output-directory-in-quarto-cli-not-respected/143762/3

We should ensure that everything which can be tested is tested. For example, anytime we tell students to run X in the Console, we should silently run X as well, just to make sure it works. Failure to do so caused a bug when we told students to run `ggx:gghelp("Turn text 90 degrees")` which caused an error because there was only 1 colon in the command. There needs to be two colons. We especially need this testing in tutorials like RStudio and Code/Github because there are so many commands we require students to issue.



Fix the caching in R CMD check Github Action:

  https://github.com/r-lib/actions/tree/v2/examples#quickstart-ci-workflow

  https://docs.github.com/en/actions/using-workflows/caching-dependencies-to-speed-up-workflows#example-using-the-cache-action

  https://stackoverflow.com/questions/63521430/clear-cache-in-github-actions



## To discuss

https://stackoverflow.com/questions/63521430/clear-cache-in-github-actions

3) Automating tutorial workflow? Interested in connecting R with Google tools.


## Other stuff


### Visualization Links

These are handy links and ideas for the tutorials, mainly in week 1 and 2, which make plots. Many of the current plots are not that impressive.

http://r-statistics.co/Top50-Ggplot2-Visualizations-MasterList-R-Code.html
https://cran.r-project.org/web/packages/ggside/vignettes/ggside_basic_usage.html

https://ggplot2.tidyverse.org/articles/

[A Gentle Guide to the Grammar of Graphics](https://pkg.garrickadenbuie.com/gentle-ggplot2) or https://moderndive.com/2-viz.html#grammarofgraphics

Tidy Tuesday: https://github.com/rfordatascience/tidytuesday

gghighlights, ggsides, ggrepel

Overview of the tutorial at the start. What functions are we covering? How do the sections related to each other? How many sections are there? How do they relate to each other? How does this tutorial relate to the other tutorials this week's?

Start providing the titles and subtitles in the question so that students could copy/paste them.

Put at the start and in the middle how long the tutorial is.


## Chapter 5 and Associated Tutorials

* Discuss tutorial which would simulate the NCAA basketball tournment. What are the odds of a 5th seed winning the whole thing? Follow the 538 approach of just simulating the whole tournament a lot. Or maybe something similar but simpler?

* Discuss simulating craps. Win with 7 or 11. Lose with 2, 3, or 12. Then roll until you make your "point" and win or "crap out" by rolling  a 7.

* Review new notation in chapter.

* Give the formula for the coin and President and height examples. The mathematical distribution is one, by definition, with a formula.


Notes on Permutation Tests

* Use "There is only one test" as one of the knowledge drops, perhaps in multiple parts. Include the graphic and link to the original. http://allendowney.blogspot.com/2016/06/there-is-still-only-one-test.html

* Work through the entire simple example with N = 5. That makes things simple. Then, we do a second example, perhaps using something from primer.data, or from elsewhere. This is the approach we are currently following.





### Tutorials to add

Let's discuss the six broad categories of tutorials which we might add, especially to chapters 5 through 11.

First, we can just do more examples. Use different data with a different question, but all the same steps as in the chapter itself. Such examples will generally, like 082, do two analyses: one with all the data (to show the truth) and one in which representativeness fails in a way which we define, thereby showing how we can be led astray. Last step is to compare the answers from these two approaches, thus emphasizing the importance of humility.

Second, stand-alone tutorials on useful topics, like text modeling or networks or rtweet or whatever. These could go in any chapter and would not be restricted to having X number of parameters.

Third, we could cover many other model families, again perhaps not worrying too much about whether or not they have the "right" number of parameters. Simplest here would be other stan_glm families. That is, show a weird data set in which the outcome variable is something that should be fit with poisson or something, and then use family = poisson. Goal would be to emphasize that there are many possible models.

Fourth, expanding on the above, we might have some machine learning examples. After all, a machine-learning model is just a different kind of black box, not different conceptually than a linear or logistic model. We could fit a machine learning model on chapter 8 scenarios. Even though there are way more than three parameters in such models, they still can (I think!) be made to work in cases with just one input variable.

Fifth, real world data science examples which do not hide the messy complexity of the world. I guess that these would be a lot like the overview tutorials, but with 30 minutes of data cleaning first. These might also explicitly assume that you have done all the other tutorials in the chapter and that, therefore, we do not need to walk you through how to estimate a stan_glm() with five baby questions. Instead, the questions would be, not really harder, but messier.

Sixth, tutorials about interpreting parameters. We could have one of these in every chapter from 6 onward. These could be short! They would only cover parameter interpretation, perhaps only using the models which were used in the chapter. Or maybe a single big tutorial, for doing around chapter 10 or 11, which would cover all the messy details of interpreting parameters and also explaining why we should not spend much time on it.

Obviously, we could also combine these in various ways. Upon reflction, we should save the machine learning examples for later chapters in which we have several righhand side variables. Indeed, we could have three machine learning tutorials in chapter 11.

* Compare results from rstanarm model to an approach, like we learned in Chapter 5, in which we do the analysis "by hand," creating the joint distribution and then the posterior distribution. This is easiest to do for Chapter 6. Indeed, you can just take the code from Chapter 5, make it continuous by sampling lots of possible values, and then compare to rstanarm. Should work fine. More ambitiously, we could do this for Chapter 7. This requires a three dimensional joint distribution because there are two unknown parameters and then a two dimensional posterior, with one dimension for mu and one for sigma. This is cool! But perhaps over kill.

* Expand the Getting Started tutorial and make it better connected to the Primer chapter. Students read the chapter and then do the tutorial. The tutorial ought to confirm that they have done everything that the chapter told them to do. Even though it is done in class, it could be a bit longer, so 10 or 15 questions.


* A "models" which would be a full dry run of their final projects. Download some data (maybe lots of little data files) with an R script. Clean the data in other R script. Make the model (a simple two parameter model) in another R script. Then, make a quarto website which uses the model to make pretty pictures which answer a couple of questions. Should show results using gtsummary to make pretty tables of model results. Might even show how stan_glm() models differ from lm() models. Or maybe run stan_glm() with option to get the lm() results. Example usage: https://ipums.github.io/pma-data-hub/posts/2021-07-01-covid-tables/

* Advanced plotting, ideally focussed on all a variety of different plotting approaches designed for modeling-type questions and answers. Maybe https://feddelegrand7.github.io/ddplot/.

* Would it be possible to have tutorials in the last few weeks which were, more or less, final project check-ins . . .

* A tutorial about working with textual data. Perhaps based on tidytext book. Also: https://datavizs21.classes.andrewheiss.com/example/13-example/

* Regression to the mean

* The garden of forking paths

* M/S errors


* An rtweet tutorial: https://github.com/ropensci/rtweet

* A Python tutorial. See the new features in learnr: "Added a new polyglot tutorial to learnr. This tutorial displays mixing R, python, and sql exercises. See run_tutorial("polyglot", "learnr") for a an example. (#397)"


### To discuss

* Another example set: https://openintrostat.github.io/ims-tutorials/

* Specify which versions of learnr (and other Github packages?) we want. Otherwise, you always get the head, which may not be desirable. Do we really still need to be using the development version of learnr? That makes me nervous! And why haven't they updated the version on CRAN for more than 15 months?

* Best single summary of tutorial tools/approaches: https://damien-datasci-blog.netlify.app/post/how-to-make-an-interactive-tutorial-to-teach-r-an-overview/


* Another way to host the tutorials: https://higgi13425.github.io/medical_r/posts/2020-12-27-creating-mini-learnr-apps-and-hosting-on-a-server/


* mention iter = 10000

### To explore later

* Powerful approach for hosting cool looking tutorials: https://github.com/ines/course-starter-r. One example of a tutorial using this approach:  https://github.com/noamross/gams-in-r-course

* Should our tutorials look more like this one? https://minecr.shinyapps.io/dsbox-05-moneyinpolitics/. I don't think so. Too many words, not enough typing.

* Explore the use of setup chunks that are referenced by name, rather than requiring that the code chunk names match up. Example: exercise.setup = "setupA"

* Put the number of exercises in the group header so that students know how long? Or maybe put in in the exercise header in exercise 5, 10 and so on.

* Can we give students a search box in the tutorial so that they can find answers to questions they have already done?


* Interesting discussion and some plausible claims: http://laderast.github.io/2020/09/15/getting-learnr-tutorials-to-run-on-mybinder-org/. Claims that "the .Rmd file containing the tutorial should be named the same as the directory it is in." But why?

* https://github.com/karthik/holepunch is interesting. But it also hasn't been updated in more than 7 months.





### Allison Horst interview

The main question was: How do we incorporate tutorial questions directly into the chapter itself? Allison is the world expert on this topic.

* She is concerned about user loads for published Shiny apps - would recommend that we use the basic or higher plan.

* She thinks using Desiree's method of embedding one exercise at a time might get unreasonable for a book of our size, but suggested that we could host 12 different ShinyApps corresponding to each chapter, and then link to each chapter in one central location. (Kind of like the combined tutorials app Evelyn created via HMDC.)

* How did you decide which exercises were going to be "tutorials" and which would be "exercises"? She wanted the exercises to be incremental, so a lot of the code was already pre-populated. The exercises that were blank built directly off of code that was already shown before, so that students could have an "easy win" by just copying the previous code and tweaking a variable name. Allison thinks that this incremental process is important for beginner R students.

* How much memory does the ShinyApp consume? Do you know of any tricks to make learnr tutorials smaller? She recommends that we contact the team at RStudio Education - this is not her area of expertise. Allison says that the RStudio Education team is super eager to hear about learnr use cases, would be happy to talk to us, and would even ask us to write a blog post. She also mentioned that the team would know the most about cutting-edge learnr stuff, including things like a "completion rate" bar that shows students how far they are through a tutorial.

* Any tips for remote teaching or learning? Using learnr at all is a big step. Allison also pre-records short versions of her lectures for her students to stream at a later time,  and holds smaller discussion sections in class where they do activities.

* Allison's #1 Recommendation to remote teachers of R: Having students start out with RStudio Cloud and then transitioning to Desktop. You can set up workspaces so the necessary packages are already loaded and installed, any script is already pre-loaded, and all students need to do is log in. It looks exactly the same as RStudio Desktop except folks don't have to worry about installing R or RStudio. You can push/pull from git in RStudio Cloud as well (link to a Rstudio cloud tutorial/article: https://rstudio.com/resources/webinars/teaching-r-online-with-rstudio-cloud/)

## Videos Worth Looking At?

Data Science Mini Projects: https://www.youtube.com/playlist?list=PLpdmBGJ6ELUJM6_vKQbpi9vGc65Sn0uPr
Draw Multiple Time Series in Same Plot: https://www.youtube.com/watch?v=FNXnJ_zT1gE
Barplot in R: https://www.youtube.com/watch?v=pYbuWU77QkU&feature=youtu.be

# Interestin approach for next summer

## Material from JSM 2021

Education section: https://matackett.github.io/open-stat-ds-ed/



Interesting discussion of using art to bring students into data science.

Consider the use of ggirl package for encouraging students to send someone an actual postcard.

Mine's discussion of how to make html and pdf versions of knitted R markdown look the same. Use fenced div blocks and then special CSS and LaTeX code chunks. Details: https://speakerdeck.com/minecr/openintro-building-sustaining-supporting-and-growing-open-source-educational-resources?slide=13

## Discussion of Tutorials

Let's discuss the six broad categories of tutorials which we might add, especially to chapters 5 through 11.

First, we can just do more examples. Use different data with a different question, but all the same steps as in the chapter itself. Such examples will generally, like 082, do two analyses: one with all the data (to show the truth) and one in which representativeness fails in a way which we define, thereby showing how we can be led astray. Last step is to compare the answers from these two approaches, thus emphasizing the importance of humility.

Second, stand-alone tutorials on useful topics, like text modeling or networks or rtweet or whatever. These could go in any chapter and would not be restricted to having X number of parameters.

Third, we could cover many other model families, again perhaps not worrying too much about whether or not they have the "right" number of parameters. Simplest here would be other stan_glm families. That is, show a weird data set in which the outcome variable is something that should be fit with poisson or something, and then use family = poisson. Goal would be to emphasize that there are many possible models.

Fourth, expanding on the above, we might have some machine learning examples. After all, a machine-learning model is just a different kind of black box, not different conceptually than a linear or logistic model. We could fit a machine learning model on chapter 8 scenarios. Even though there are way more than three parameters in such models, they still can (I think!) be made to work in cases with just one input variable.

Fifth, real world data science examples which do not hide the messy complexity of the world. I guess that these would be a lot like the overview tutorials, but with 30 minutes of data cleaning first. These might also explicitly assume that you have done all the other tutorials in the chapter and that, therefore, we do not need to walk you through how to estimate a `stan_glm()` with five baby questions. Instead, the questions would be, not really harder, but messier.

Sixth, tutorials about interpreting parameters. We could have one of these in every chapter from 6 onward. These could be short! They would only cover parameter interpretation, perhaps only using the models which were used in the chapter.

Obviously, we could also combine these in various ways. Upon reflection, we should save the machine learning examples for later chapters in which we have several righthand side variables. Indeed, we could have three machine learning tutorials in chapter 11.

### Later tutorials in later chapters

The first tutorial for each of the later chapters is easy. Just do more or less exactly what the chapter does. Recall that, one day, we expect to incorporate those questions directly into the chapter itself. So, the more that it just forces students to type in the same commands as in the chapter, the better. But, for the most part, the chapters are not that long! There is only about one tutorial worth of material.

What do we do for the other 5 or so tutorials for each chapter? Good question! Honestly, I am not sure. Here are some ideas:

* The second tutorial could be very similar to the first -- and, therefore, to the chapter. Just use a different variable(s) and/or a different tibble, but answer the same sorts of questions in the same way.

* Don't be repetitive in the written questions. It is fine, in the first tutorial for each chapter, to ask students to write a definition of the Preceptor Table. Indeed, we should always have that question in each first tutorial. But, we don't want that question in each of the 5 tutorials for a single chapter.

* Use written questions which do require different answers depending in the data/variable used. We can't resuse "Define a Preceptor Table" because that question has the same answer every time. Consider a different question:

> Write a paragraph which explores reasons why we should **not** consider the Preceptor Table and our data set as being drawn from the same population?

That is a good question, not least because it needs a different answer for each data science problem we confront. Another good example:

> Write a paragraph explaining why, even though the data is not a random sample, we may still consider it to be "respsentative" enough to move forward?

Again, this requires a different answer for each new tibble.

* We don't usually (ever?) ask questions about the four Cardinal Virtues directly. They are simply a pedagogical device we use to help students organize their work. But we do ask written questions about the key concepts (population, representativeness, validity) in each and every tutorial. These are difficult concepts with no "right" answers. We need to wrestle with them every week.

* A tutorial after the first might do a very similar exercise but with three differences. First, it can go faster, given that students have already seen the basics fairly slowly in the first tutorial. Second, it can add some complexity, make the modeling problem just a little more difficult than the basic case. Third, it can add some new magic. Perhaps it grabs data using a new package instead of just using another boring data set from **primer.data**. Perhaps it creates a nicer plot with some geoms we have not used before.

* I will distribute the problem sets we used last semester. Turning them into tutorials might work well. But always remember that tutorials are easy, while problem sets are hard. So, we need to split up a big problem set question into 15 exercises and then walk the students slowly (and with hints) through those 10 exercises.

* Maybe there are easy ways, in tutorial 2 or 3, to take the problem we solved in tutorial 1 and have it loosen the assumption that the data we have is representative of the population. This is a nice assumption to loosen since it is never true. I am not sure how one would do this . . .

* If the main example is the chapter is one which uses a linear model, then tutorial 2 could use a logistic model and then tutorial 3 could use the third kind of model (which we have not chosen yet). Similarly, if the chapter (and first tutorial) does a predictive mode, then tutorial 3 should do a causal model.

* The last tutorial might, in some sense, try to set the stage for the next chapter, provide a teaser for what we are learning next.

* Another type of tutorial is one which uses fake data which has been manipulated to violate the assumptions which students are making. Show them Preceptor's Posterior and compare it to their own.
