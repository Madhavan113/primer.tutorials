---
title: Cumulative
author: David Kane and Mihir Kaushal
tutorial:
  id: cumulative
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Tutorial: Cumulative'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)

library(tidyverse)
library(primer.data)
library(brms)
library(tidybayes)
library(gtsummary)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

x <- ces |>
  filter(year == 2020) |>
  select(faminc, ideology, approval, education) |>
  drop_na() |> 
  slice_sample(n = 2000)


# Adjust/remove the cores argument depending on your machine, without a lot of
# cores, this can take a while.

# fit_approve <- brm(formula = approval ~ ideology + faminc + education,
#                    data = x,
#                    family = cumulative(),
#                    refresh = 0,
#                    silent = 2,
#                    seed = 19)
# write_rds(fit_approve, "data/fit_approve.rds")
 
fit_approve <- read_rds("data/fit_approve.rds")


ndata <-
  expand_grid(ideology = c("Very Liberal",
                           "Liberal",
                           "Moderate",
                           "Conservative",
                           "Very Conservative"),
              education = unique(x$education),
              faminc = unique(x$faminc))
```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Sometimes brm() takes very long because the data is very large. In order to combat this problem, we can randomly choose a set amount from the data using slice_sample(). When we used slice_sample(n = 2000) and compared the outcome of the brm to the brm with the whole data, the results of the estimation were very similar. The key difference was the confidence interval; the confidence interval for the model with the larger data was smaller than the confidence interval for the smaller data. For our purposes, the data with only 2,000 observations was accurate enough for us to use. This might be different for different types of models. -->

## Introduction
### 

This tutorial is best understood when done after reading [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

## The Question
### 

*The power to question is the basis of all human progress.* - Indira Gandhi

### Exercise 1

Load **tidyverse**.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The data we will be looking at for this tutorial comes form a study where people rate how much they approve the current president.

The [Cooperative Election Study](https://cces.gov.harvard.edu/) (CES) is one of the largest political surveys in the United States.

### Exercise 2

Load the **primer.data** package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from the Cooperative Congressional Election Study is available in the `ces` tibble.

### Exercise 3

After loading **primer.data** in your Console, type `?ces` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The data has `r scales::comma(nrow(ces))` observations and `r scales::comma(ncol(ces))` variables.

### Exercise 4

Approval of the president is the broad topic of this tutorial. Given that topic, which variable in `ces` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "The `approval` variable shows the approval of the president.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

`approval` is an ordered factor variable and takes values of "Strongly Approve", "Approve / Somewhat Approve", "Neither Approve Nor Disapprove", "Disapprove / Somewhat Disapprove", and "Never Heard / Not Sure".

### Exercise 5

Pick a variable in the data which might have a connection to the outcome variable and which we might consider to be, at least in theory, a treatment. (If you don't see a reasonable variable in the data, you can just name an imaginary variable which *might have been* included in the data.) How might we manipulate this variable?

```{r the-question-5}
question_text(NULL,
	message = "Consider positive Facebook ads as a treatment. We might expose some people to those ads and not others. Then, we could measure the causal effect of ads on presidential approval.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Such a variable does not exist in our data. There are several variables we can think of that could impact the `approval`, but there is no treatment variable in our data. 

We could look at the predictive relationship between `approval` and one of the many covariates in our data. 

### Exercise 6

Let's consider a *predictive* model. Which variable in `ces` do you think might have an important connection to `approval`? 

```{r the-question-6}
question_text(NULL,
	message = "The ideology of an individual could be connected to their approval of the president. If the president is a Republican, we might expect more conservative individuals to have stronger measured approval.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

There is no right answer! The `ces` tibble has 17 variables. For the rest of this tutorial, we will be focusing on `ideology` as the main explanatory variable, but our model will certainly include other variables. 

### Exercise 7

Write a few sentences which specify two different groups of people with different values for `ideology`. Explain that the outcome variable might differ between these two groups.

```{r the-question-7}
question_text(NULL,
	message = "Some people might have a value for ideology of Very Liberal. Others might have a value of Very Conservative. Those two groups might, on average, have different values for pesidential approval, our outcome variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The survey consists of two waves in election years. In the pre-election wave, respondents answer two-thirds of the questionnaire from late September to late October. In the post-election wave, respondents answer the other third of the questionnaire in November.

### Exercise 8

Write a predictive question which connects the outcome variable `approval` to covariates of interest. 

```{r the-question-8}
question_text(NULL,
	message = "What is the relationship between the approval of the president and an individual's ideology?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The phrasing of the survey when asking for the individual's approval of the president matters because if someone was first asked questions about the economy, and the economy was doing good, then that person might be more likely to approve of the president. The people conducting the survey have to be careful of the way they phrase their questions because people could respond differently depending on the phrasing.

Fortunately, the study is being operated by several professionals that know what they are doing, so they will have an appropriate phrasing of the questions. 

### Exercise 9

What is the Quantity of Interest which might help us to explore the answer to our question?

```{r the-question-9}
question_text(NULL,
	message = "One quantity of interest might be the difference in Strong Approval for the President between Very Conservative and Very Liberal people.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The quantity of interest for this question is more complex because we have five numbers. Our outcome variable, `approval`, has five values. Each of those values becomes a quantity of interest. 

## Wisdom
### 

*The doorstep to the temple of wisdom is a knowledge of our own ignorance.* - Benjamin Franklin

Our question:

> *What is the relationship between the approval of the president and an individual's ideology?*

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The ces is an online survey. The total amount of time for both waves of the survey take around 30 minutes. Respondents are compensated by points for taking each survey which can be exchanged for giftcards and other prizes.

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The CES is designed to be representative of all national adults, even those who do not vote.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This problem is not causal so there is no treatment. In order to make causal relationships, the data needs to be manipulated. In `ces`, the data is observed, there was no manipulated variables.

### Exercise 4

Create a Github repo called `cumulative`. Make sure to click the "Add a README file" check box.

Connect the `cumulative` Github repo to an R project on your computer. Name the R project `cumulative` also.

Select `File -> New File -> Quarto Document ...`. Provide a title (`"Cumulative"`) and an author (you). Render the document and save it as `analysis.qmd`.

Edit the `.gitignore` by adding `*Rproj`. Save and commit this in the Git tab. Push the commit.

In the Console, run:

```         
show_file(".gitignore")
```

CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Remove everything below the YAML header from `analysis.qmd` and render the file. `Command/Ctrl + Shift + K` renders the file, this automatically saves the file as well.

### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "Adults in the United States of America.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If our question was different, we could have different units. For example, if our question was focused only on people who were Conservative, then our units would only be adults in the United States of America who were also Conservative.

### Exercise 6

What is/are the outcome/outcomes for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "approval has the approval rating of the president.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Again, `approval` has five values: "Strongly Approve", "Approve / Somewhat Approve", "Neither Approve Nor Disapprove", "Disapprove / Somewhat Disapprove", and "Never Heard / Not Sure". These five values give us five numbers. If there were only two values, approve or not approve, then there would only be two numbers we would care about.

### Exercise 7

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

```{r wisdom-7}
question_text(NULL,
	message = "Sex and race could have a relationship with the approval of the president.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There are variables outside the data we have that could have a meaningful relationship with `approval`. Whether or not the individual comes from an immigrant family could have a relationship with their approval of the president.

### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "There are no treatments.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Because this is a predictive model, none of the covariates are considered to be treatments. Recall that a "treatment" is just a covariate which we can, at least in theory, manipulate and which, since we have decided we want a causal model, we are assuming creates two (or more) potential outcomes.

### Exercise 9

What moment in time does the Preceptor Table refer to?

```{r wisdom-9}
question_text(NULL,
	message = "2020",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Each president will have different approval rates. We will be focusing on only the year 2020.

### Exercise 10

Define causal effect.

```{r wisdom-10}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This is a predictive model, not because of anything intrinsic in the data. We make a predictive model because we are asking a predictive question. We want to *compare* approval between groups of people who differ in their ideology. We don't want to estimate the causal effect on approval of changes, within a single individual, in ideology.

### Exercise 11

What is the fundamental problem of causal inference?

```{r wisdom-11}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Since our question is not causal, this dilemma does not have a major impact on us. 

### Exercise 12

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-12}
question_text(NULL,
	message = "Since the data is only a survey, without any manipulation, we cannot make any causal inferences.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The motto does not apply because this is a predictive, not causal, model.

### Exercise 13

Describe in words the Preceptor Table for this problem.

```{r wisdom-13}
question_text(NULL,
	message = "The Preceptor Table has 3 columns. There is a column for the ID, and one for the outcome. There will be a column for ideology Each row represents one individual.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
#| echo: false
tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       approval = c("Neither Approve Nor Disapprove", "Disapprove / Somewhat Disapprove", "...", "Strongly Approve", "Never Heard / Not Sure", "...", "Neither Approve Nor Disapprove"),
       ideology = c("Moderate", "Very Liberal", "...", "Moderate", "Not Sure", "...", "Conservative")) |>
  
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             approval = md("Approval of the President"),
             ideology = md("Political Ideology")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Covariates", columns = c(ideology)) |>
  tab_spanner(label = "Outcomes", columns = c(approval))
```

### Exercise 14

In `analysis.qmd`, delete everything past the YAML heading and load the **tidyverse** and the **primer.data** packages in a new code chunk. Label it the set up by adding `#| label: setup`. Render the file.

Notice that the file does not look good because it is has code that is showing and it also has messages. To take care of this, add `#| message: false` to remove all the messages in the setup chunk. Also add the following to the YAML header to remove all echo from the whole file:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.

### Exercise 15

Write one sentence describing the data you have to answer your question.

```{r wisdom-15}
question_text(NULL,
	message = "The Cooperative Congressional Election Study is one of the largest political surveys in the United States and was started in 2006. The data has how much people approve of the president as well as other useful variables such as ideology.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Of course, when doing the analysis, you don’t know when you start what you will be using at the end. Data analysis is a circular process. We mess with the data. We do some modeling. We mess with the data on the basis of what we learned from the models. With this new data, we do some more modeling. And so on.

### Exercise 16

Run `glimpse()` on `ces`.

```{r wisdom-16, exercise = TRUE}

```

```{r wisdom-16-hint-1, eval = FALSE}
glimpse(...)
```

```{r wisdom-16-test, include = FALSE}
glimpse(ces)
```

### 

`glimpse()` gives us a look at the raw data contained within the `ces` data set. At the very top of the output, we can see the number of rows and columns, or observations and variables, respectively. We see that there are 617,455 observations, with each row corresponding to a unique respondent.

### Exercise 17

Pipe `ces` to `filter()` with `year` set to `2020` inside of it using `==`.

```{r wisdom-17, exercise = TRUE}

```

```{r wisdom-17-hint-1, eval = FALSE}
ces |> filter(...)
```

```{r wisdom-17-test, include = FALSE}
ces |> filter(year == 2020)
```

### 

We will be focusing on the year 2020 so that we have fewer number of rows to work with. 

### Exercise 18

Continue the pipe to `select()` and have `approval`, `education`, `faminc`, and `ideology` inside.

```{r wisdom-18, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>
```{r wisdom-18-hint-1, eval = FALSE}
... |> select(...)
```

```{r wisdom-18-test, include = FALSE}
ces |> filter(year == 2020) |> select(approval, education, faminc, ideology)
```

### 

We are selecting only the rows we will use in the future. Of course, we could choose any of the other variables, but we will be focusing on only these four for this tutorial. 

### Exercise 19

Finish the pipe with `drop_na()`. Add `slice_sample(n = 2000)` at the very end to only select 2,000 observations from the data. 

```{r wisdom-19, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>
```{r wisdom-19-hint-1, eval = FALSE}
... |> drop_na() |>
  slice_sample(...)
```

```{r wisdom-19-test, include = FALSE}
ces |> filter(year == 2020) |> select(approval, education, faminc, ideology) |>
  drop_na() |>
  slice_sample(n = 2000)
```

### 

Behind the scenes of this tutorial, we have created an object called `x` using the previous code. 

### Exercise 20

To see the object that was created in the background, run `x`.

```{r wisdom-20, exercise = TRUE}

```

```{r wisdom-20-hint-1, eval = FALSE}
x
```

### 

There are now only 54,839 rows which is significantly fewer than the whole `ces` data. Having more manageable data will make it easier for us to create models.

### Exercise 21

In `analysis.qmd`, add a new code chunk. Copy the code from two exercises ago which prepares the data and paste it in the code chunk. Set the code to an object called `x`. 

Render the file. In the Console, run:

```         
show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r wisdom-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The CES is a 50,000+ person national stratified sample survey administered by YouGov. Half of the questionnaire consists of Common Content asked of all 50,000+ people, and half of the questionnaire consists of Team Content designed by each individual participating team and asked of a subset of 1,000 people.

### Exercise 22

Pipe `x` to `summary()`.

```{r wisdom-22, exercise = TRUE}

```

```{r wisdom-22-hint-1, eval = FALSE}
summary(...)
```

```{r wisdom-22-test, include = FALSE}
summary(x)
```

### 

We can see some information about our data. Most people have a family income between 20k and 30k. Most people are moderate in terms of political ideology. Most people strongly disapprove the president, the second biggest group for that variable is strongly approve. Most people only have a high school as their highest education. 

### Exercise 23

Pipe `x` to `ggplot()` with `x` set to `ideology` and `fill` set to `approval`. Then add a layer of `geom_bar`.

```{r wisdom-23, exercise = TRUE}

```

```{r wisdom-23-hint-1, eval = FALSE}
x |>
  ggplot(aes(...)) +
  geom_bar()
```

```{r wisdom-23-test, include = FALSE}
x |>
  ggplot(aes(x = ideology, fill = approval)) +
  geom_bar()
```

### 

This graphs shows that most liberals strongly disapprove the 2020 president and most conservatives strongly support the 2020 president. 

### Exercise 24

Using the previous code, add `labs()`.

```{r wisdom-24, exercise = TRUE}

```

<button onclick="transfer_code(this)">Copy previous code</button>
```{r wisdom-24-hint-1, eval = FALSE}
... +
  labs(...)
```

```{r wisdom-24-test, include = FALSE}
x |>
  ggplot(aes(x = ideology, fill = approval)) +
  geom_bar() +
  labs(title = "Relationship Between President Approval and Political Ideology in 2020",
       subtitle = "Most people strongly disapprove.",
       x = "Political Ideology",
       y = "Count",
       fill = "Approval of the President",
       caption = "Data from CES.")
```

### 

The graph should look like this:

```{r}
#| echo: false

x |>
  ggplot(aes(x = ideology, fill = approval)) +
  geom_bar() +
  labs(title = "Relationship Between President Approval and Political Ideology",
       subtitle = "Most people strongly disapprove.",
       x = "Political Ideology",
       y = "Count",
       fill = "Approval of the President",
       caption = "Data from CES.")
```

### Exercise 25

In `analysis.qmd`, add the code the previous exercise to add the graph in the file.

Render the file. In the Console, run:

 ```         
show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r wisdom-25}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

This graph is useful but we still need to create an actual model with this data in order to answer our questions.

### Exercise 26

In your own words, define "validity" as we use the term.

```{r wisdom-26}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the two data sets to be drawn from the same population, the columns from one must have a valid correspondence with the columns in the other.

### Exercise 27

Provide one reason why the assumption of validity might not hold for the outcome variable: `approval`.

```{r wisdom-27}
question_text(NULL,
	message = "Both the colums in the data we have and the Preceptor Table have a variable called approval, but the Preceptor Table is the true approval of the president where as the data only has the self reported approval of the president. People could lie about their approval of the president.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

These two columns have the same name but they might not be similar enough because the self reported approval of the president might be different from their true approval of the president. 

### Exercise 28

Provide one reason why the assumption of validity might not hold for the covariate: `ideology`.

```{r wisdom-28}
question_text(NULL,
	message = "There is a column in the Preceptor Table for ideology, and a column in our data for idology. People might misidentify themselves if they do not know the difference between the ideologies or they have a different definition for the ideologies. This might create a difference between their true identity and their self claimed identity.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Again, validity is all about columns. We have to make sure that the columns in our data fully match the columns in the Preceptor Table. Both of the columns talk about ideologies, but key difference is the true political identity vs their self claimed political identity.

### Exercise 29

Summarize the state of your work so far in one sentence. Make reference to the data you have and to the specific question you are trying to answer. 

```{r wisdom-29}
question_text(NULL,
	message = "Using the CES, which is one of the largest political surveys in the United States, we seek to make a predictive model which could help us see a relationship between approval of the president and an individual's political ideology.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit you answer as you see fit, but do not copy/paste our answer exactly. Add this summary to `analysis.qmd`, `Command/Ctrl + Shift + K`, and then commit/push.

## Justice
### 

*The arc of the moral universe is long, but it bends toward justice.* - Theodore Parker

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

No data is perfect, we have to look for reasons why the model we will create might not work as well as we hope. An important skill to have as a data scientist is to know the limitations of the model. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "We are concerned about the year 2020 and the data we have has information for 2020, so their is no danger to stability. The time the data was gathered is the same as the time refered to in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If we wanted to make a predictive model for this year, then we might have a major stability problem because the relationship between presidential approval and ideology depends a great deal on the ideology of the president whose approval we are measuring.

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case. 

### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "The CES website claims that they designed the study to be representative of all adults. But, they could make mistakes while executing the study would make the sample not representative of the larger population. For example, the way they select people for the survey might be flawed.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A large portion of the CES respondents are YouGov panelists. This group might not representative of the whole population because they might be more politically active and care more about politics than other people do.

### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "Because the Preceptor Table includes the entire population, there is no problem with representativeness in using the population to draw inferences about the Precetor Table. They are one and the same.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Since the units in the Preceptor Table and the units in the population are both adults in the United States of America, they are representative.

### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true. 

### Exercise 9

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention one specific problem which casts doubt on your approach. 

```{r justice-9}
question_text(NULL,
	message = "Using the CES, which is one of the largest political surveys in the United States, we seek to understand the relationship between presidential approval and political ideology in 2020. One concern is that survey respondents might be systematically different from other Americans.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `analysis.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.

## Courage
### 

*Courage is going from failure to failure without losing enthusiasm.* - Winston Churchill

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

Because `approval` is an ordinal variable, we assume that an individual's approval is produced from a Cumulative distribution.

$$ approval_i  \sim Cumulative(\rho_{strongly\_positive}, \rho_{positive}, \rho_{neutral}, \rho_{negative}, \rho_{strongly\_negative}) $$

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

Because we are using a Cumulative distribution, the link function is logit. That is:

$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 x_1 + \dots)}}$$
Of course, the probabilities for each of the different levels of approval need to add to 1, by definition.

$$\rho_{strongly\_positive} + \rho_{positive} + \rho_{neutral} + \rho_{negative} + \rho_{strongly\_negative} = 1$$

### Exercise 4

Add `library(brms)` and `library(tidybayes)` to the `setup` code chunk in `analysis.qmd`. Copy and paste the below code for the mathematical structure of the model to the body of `analysis.qmd`. `Command/Ctrl + Shift + K`. 

```
$$ approval_i  \sim Cumulative(\rho_{strongly\_positive}, \rho_{positive}, \rho_{neutral}, \rho_{negative}, \rho_{strongly\_negative})$$
$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 x_1 + \dots)}}$$
```

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", pattern = "brms|tidybayes|\\$\\$")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Of course, our model must make use of the variables we actually have. Consider:

$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 ideologyLiberal+\beta_2 ideologyModerate + \dots)}}$$

### Exercise 5

Create a model using `brm()` from the **brms** package. Your arguments should be `formula = approval ~ ideology + faminc + education`, `data = brm_data`, `family = cumulative()`, `refresh = 0`, `silent = 2`, and `seed = 19`. 

```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
brm(...)
```

### 

The cumulative family leads to ordinal regression.

### Exercise 6

Behind the scenes, we have used `brm()` to create an object named `fit_approve`. This version was created using `x` so it has more rows than the one you created in the previous exercise.

Type `fit_approve` and hit "Run Code." This generates the same results as using `print(fit_approve)`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
fit_approve
```

```{r courage-6-test, include = FALSE}
fit_approve
```

### 

Using 2,000 observations from the data instead of the whole data should not make a huge difference in the model because we chose a random sample and because 2,000 rows should be enough to make an accurate model for our purposes. 

### Exercise 7

Run `family()` on `fit_approve`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
family(...)
```

```{r courage-7-test, include = FALSE}
family(fit_approve)
```

### 

In this case, the family is cumulative which can be used to create ordinal regression. The family is determined by the left side variable in the formula. 

### Exercise 8

Run `formula()` on `fit_approve`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
formula(...)
```

```{r courage-8-test, include = FALSE}
formula(fit_approve)
```

### 

In this case, the formula is `approval ~ ideology + faminc + education`.

### Exercise 9

Run `nobs()` on `fit_approve`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-9-test, include = FALSE}
nobs(fit_approve)
```

### 

In this case, there should be 2,000 observations because we used `slice_sample()` to only select 2,000 random observations.

### Exercise 10

Create a new code chunk in `analysis.qmd`. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model using `brm()` into the code chunk, assigning the result to `fit_approve`. 

`Command/Ctrl + Shift + K`. It may take some time to render `analysis.qmd`. 

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r courage-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

By including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render `analysis.qmd`, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

### Exercise 11

Run `posterior_interval()` on `fit_approve`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-11-test, include = FALSE}
posterior_interval(fit_approve)
```

### 

In this case, `faminc` has 0 included inside the 95% confidence interval, this means that we are not sure if family income has a positive or negative relationship with presidential approval. 

### Exercise 12

Run `fixef()` on `fit_approve`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-12-test, include = FALSE}
fixef(fit_approve)
```

### 

In this case, we can again see that family income has no correlation with presidential approval. 

### Exercise 13

Write a sentence interpreting the `-0.34` estimate for `educationHighSchoolGraduate`.

```{r courage-13}
question_text(NULL,
	message = "When comparing (only) high school graduates with people who didn't go to high school, high school graduates have a 0.34 lower value for approval, meaning that they are less likely to have more approval for the president.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Positive coefficients suggest that higher values of the predictor increase the likelihood of higher approval categories.

Negative coefficients suggest that higher values of the predictor decrease the likelihood of higher approval categories.

Larger coefficients (either positive or negative) indicate a stronger relationship between the predictor and the latent approval score.

### Exercise 14

Write a sentence interpreting the `-0.86` to `0.17` confidence interval for `educationHighSchoolGraduate`. 

```{r courage-14}
question_text(NULL,
	message = "We do not know the true value for the coefficient for educationHighSchoolGraduate, but we can be 95% confident that it lies somewhere between -0.86 and 0.17.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If the credible interval includes zero, the effect is less likely to be significant. 

The intercept is always the first value for any variable. For example, the intercept for `education` is `No HS`, and intercept for `ideology` is `Very Liberal`. This is why these values do not show up with `fixef(fit_approve)`. 

### Exercise 15

Write a sentence interpreting the `5.57` estimate for `ideologyVeryConservative`.

```{r courage-15}
question_text(NULL,
	message = "If we compare people who are very conservative with people who are very liberal (the base category which is included in the intercept), the very conservative people approve the president more. Because of the complexity of the mathematics of the model, 5.57 does not have a natural interpretation in terms of its magnitude.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

`Intercept[1]`, `Intercept[2]`, and so on are intercepts that are used as cut points or thresholds that separate the different levels of the ordinal outcome variable (`approval`). 

In ordinal regression, these intercepts define the points on the latent variable scale at which the response variable transitions from one category to the next.The probability of falling into a specific category is determined by the relationship between these intercepts and the predictors.

### Exercise 16

Run `pp_check()` on `fit_approve`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-16-test, include = FALSE}
pp_check(fit_approve)
```

This might take some time.

### 

In this case, there is a peak at when the x-axis is at 1. 

### Exercise 17

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-17, exercise = TRUE}

```

```{r courage-17-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-17-test, include = FALSE}
library(gtsummary)
```

### 

The *gtsummary* package provides an elegant and flexible way to create publication-ready analytical and summary tables using the R programming language. The *gtsummary* package summarizes data sets, regression models, and more, using sensible defaults with highly customizable capabilities.

### Exercise 18

Pipe `fit_approve` to `tbl_regression()`.

```{r courage-18, exercise = TRUE}

```

```{r courage-18-hint-1, eval = FALSE}
fit_approve |> 
  tbl_...()
```

```{r courage-18-test, include = FALSE}
fit_approve |>
  tbl_regression()
```

There will be a warning message which says: Unable to identify the list of variables. You can ignore this. 

### 

Beta for very conservative is 5.6 but it is 0.84 for liberal. This makes sense when taking into consideration what we noticed during the EDA: in 2020, conservatives supported the president more than liberals.  

### Exercise 19

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add one sentence which describes the modelling approach which you are using, specifying the functional form and the dependent variable. Add one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-19}
question_text(NULL,
	message = "Using the CES, which is one of the largest political surveys in the United States, we seek to understand the relationship between presidential approval and political ideology in 2020. One concern is that survey respondents might be systematically different from other Americans. We are using a cumulative model for ordinal regression.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

One relationship we have noticed is that conservatives tend to support the 2020 president more than liberals. 

### Exercise 20

Update `analysis.qmd`. First, add `library(gtsummary)` to the `setup` code chunk,. Second, add the mathematical formula, in $\LaTeX$ and surrounded by double dollar signs, for your model. Third, add a new code chunk which creates the table of model parameters. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r courage-20}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

## Temperance
### 

*Temperance is the greatest of all virtues. It subdues every passion and emotion, and almost creates a Heaven upon Earth.* - Joseph Smith Jr.

### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the Data Generating Mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage gave us the data generating mechanism. Temperance guides us in the use of the DGM — or the “model” — we have created to answer the questions with which we began. We create posteriors for the quantities of interest. We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 2

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-2}
question_text(NULL,
	message = "What is the relationship between the approval of the president and an individual's ideology?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 3

To answer our question, we need to create an object --- call it `ndata` --- which we will pass in as a value to the `newdata` argument in to `add_predicted_draws()` or to whichever **tidybayes** function we use. Which variables (e.g., which columns) do we need to include in this object?

```{r temperance-3}
question_text(NULL,
	message = "We will inclue ideology, education and faminc.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 4

Which values do you want the variables in your `newdata` object to have? This is not easy! At the very least, one of the rows should have values which allow you to answer your original question. But, now that you have a model, there are many questions which you might want to answer, the better to get a fuller understanding.

```{r temperance-4}
question_text(NULL,
	message = "The ideology would have most of the political ideologies listed in the data, this is Very Liberal, Liberal, Moderate, Conservative, and Very Conservative, we will not include not sure because it is not important. Education will have all of the education leves: No HS, High School Graduate, Some College, 2-Year, 4-Year, and Post-Grad. Faminc will have all ranges of family income: Less than 10k, 10k - 20k, 20k - 30k, 30k - 40k, 40k - 50k, 50k - 60k, 60k - 70k, 70k - 80k, 80k - 100k, 100k - 120k, 120k - 150k, and 150k+",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We can choose any value for `faminc` and that would not change our estimates of the predictions as there is no relationship between `faminc` and `approval`. It would be interesting to see two opposite sides for `faminc`, for example looking at `Less than 10k` vs `150k+`.

### Exercise 5

Here is the R code which creates the `newdata` object: `expand_grid(ideology = c("Very Liberal", "Liberal", "Moderate", "Conservative", "Very Conservative"), education = unique(x$education), faminc = unique(x$faminc))`. Type it into the code exercise block and hit "Run Code."

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}
expand_grid(...)
```

```{r temperance-5-test, include = FALSE}
expand_grid(ideology = c("Very Liberal",
                           "Liberal",
                           "Moderate",
                           "Conservative",
                           "Very Conservative"),
            education = unique(x$education),
            faminc = unique(x$faminc))
```

### 

It is best to ensure that the variable types in `ndata` match the variable types on `x`. The easiest way to ensure that is by using `x` itself in the creation `ndata`.

### Exercise 6

Behind the scenes, we have created the `ndata` object using this code. To confirm, type `ndata` and hit "Run Code."

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}
ndata
```

```{r temperance-6-test, include = FALSE}
ndata
```

### 

Functions like `unique()` --- to grab all the possible values in a variable --- and `expand_grid()` --- to create all possible combinations of different variables --- are often useful in creating `ndata`.

### Exercise 7

Create a new code chunk in `analysis.qmd` which creates the `ndata` object. `Command/Ctrtl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", pattern = "ndata")
```

CP/CR.

```{r temperance-7}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The `ndata` tibble has 432 rows. There are 12 values for `faminc`, 6 values for `ideology`, and 6 values for `education`. The number of values for each of them multiplied together gives us 432. 

### Exercise 8

Now that we have the `newdata` object, we can create a pipe which uses out fitted model to answer our question. Begin by typing `fit_approve` and clicking "Run Code."

```{r temperance-8, exercise = TRUE}

```

```{r temperance-8-hint-1, eval = FALSE}
fit_approve
```

```{r temperance-8-test, include = FALSE}
fit_approve
```

### 

Our `ndata` object includes `faminc` but we do not have to include it in our graph. As we previously discovered, family income does not have any significant relationship with `approval`.

### Exercise 9

Pipe `fit_approve` to `add_predicted_draws()` with the argument `newdata = ndata`. 

```{r temperance-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-9-hint-1, eval = FALSE}
fit_approve |>
  add_predicted_draws(...)
```

```{r temperance-9-test, include = FALSE}
fit_approve |>
  add_predicted_draws(newdata = ndata)
```

### 

We use `add_epred_draws()` for expected values: we are not interested in any specific individual, the individual value is irrelevant. 

We use `add_predicted_draws()` for predicted values: we care, not about the average, but about this specific person.

Both functions return draws from a posterior probability distribution, but the unknown number which underlies the posterior are very different.

<!-- XX: Insert as many questions as necessary to build a nice-looking example of your final plot. In early chapters, this is simple since our questions are simple. They are just one posterior. In later chapters, they become more complex, with the inclusion of several posteriors, as well as manipulation of them to calculate causal effects and whatnot. See the voting postcard example. -->

### Exercise 10

Finish the graph with `labs()`. 

```{r temperance-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-10-hint-1, eval = FALSE}
... +
  labs(...)
```

```{r temperance-10-test, include = FALSE}
fit_approve |>
  add_predicted_draws(newdata = ndata)
```

### 

The graph should look like this: 

```{r}
#| echo: false

fit_approve |>
   add_predicted_draws(newdata = ndata) |>
   filter(.prediction %in% c("Strongly Approve", "Strongly Disapprove")) |> 
   ggplot(aes(x = education, fill = ideology)) +
   geom_bar(aes(y = after_stat(prop), group = ideology), position = "dodge") +
   facet_wrap(~ .prediction, nrow = 2,
              labeller = labeller(c("Strongly Approve",
                                       "Strongly Disapprove"))) +
   scale_x_discrete(labels = c("No HS" = "No HS",
                               "High School Graduate" = "HS",
                               "Some College" = "Some College",
                               "2-Year" = "2_Year",
                               "4-Year" = "4-Year",
                               "Post-Grad" = "Post-Grad")) +
   scale_y_continuous(labels = scales::percent_format()) +
   theme_minimal() +
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
   labs(title = "Ideology by Education, Faceted by Approval",
        x = "Education", fill = "Ideology", y = "Probability")


```

### Exercise 11

Create a new code chunk in `analysis.qmd`. Label it with `label: plot`. Copy/paste the code which creates your graphic. Don't forget that, at the top of this chunk, you must include code which creates the `ndata` object.

`Command/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r temperance-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We could have made many graphs with this data to highlight different things. It is important to only keep information in that is useful and has relationships with the outcome variable. 

### Exercise 12

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI.

```{r temperance-12}
question_text(NULL,
	message = "Using the CES, which is one of the largest political surveys in the United States, we seek to understand the relationship between presidential approval and political ideology in 2020. One concern is that survey respondents might be systematically different from other Americans. We are using a cumulative model for ordinal regression. People who are very conservative are more likely to approve the president higher by about 5.6 compared to people who are very liberal. We are 95% confident that the true value is between 4.9 and 6.2.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `analysis.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.

### Exercise 13

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted. 

```{r temperance-13}
question_text(NULL,
	message = "Our estimates and confidence intervals might not be wrong because the data is not perfect. We have noticed some potential problems such as in validity; people could be lying about thier approval of the president or misidentifying their ideology. These concerns can cause our findings to be inaccurate. The true estimate and confidence interval might be different. The interval would be bigger because we have uncertainties about the data.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There is almost always uncertainty associated with our conclusions. It is important to notice and acknowledge the potential problems with the data. 

### Exercise 14

Rearrange the material in `analysis.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r temperance-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

### Exercise 15

Publish `analysis.qmd` to Rpubs. Choose a sensible slug. Copy/paste the url below.

```{r temperance-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

## Summary
### 

This tutorial covered topics that were not explicitly in [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
