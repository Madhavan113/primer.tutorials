---
title: 'Three Parameters: Causal'
author: David Kane and Gia Khang
tutorial:
  id: three-parameters-causal
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Chapter 6 Tutorial: Three Parameters: Causal'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(tidyverse)
library(brms)
library(tidybayes)
library(gtsummary)
library(primer.data)
library(gt)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

#fit_gauss <- brm(formula = att_end ~ treatment,
#             data = trains,
#             family = gaussian(),
#             silent = 2,
#             refresh = 0,
#             seed = 9)
#write_rds(fit_gauss, "data/fit_gauss.rds")

fit_gauss <- read_rds("data/fit_gauss.rds")

ndata <- tibble(treatment = c("Treated", "Control"))

att_end_plot <- trains |> 
  ggplot(aes(x = att_end, fill = treatment)) +
    geom_bar(aes(y = after_stat(count/sum(count))),
                   position = "dodge") +
    labs(title = "Ending Attitude Toward Immigration",
         subtitle = "Treated Individuals Are More Conservative",
         x = "Attitude",
         y = "Probability",
         fill = NULL) +
    scale_y_continuous(labels = scales::percent_format()) + 
    theme_classic()


```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

## Introduction
### 

This tutorial covers [Chapter 6: Three Parameters: Causal](https://ppbds.github.io/primer/three-parameters-causal.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

## The Question
### 

### Exercise 1

Load the **tidyverse** package.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(...)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

### Exercise 2

Load the **primer.data** package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(...)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

Often, the units we can plausibly study are determined by the data which we have. Therefore, the very first step in every data science project is to load up and look at the data.

### Exercise 3

After loading **primer.data** in your Console, type `?trains` in the Console, and paste in the Description below. 

```{r the-question-3}
question_text(NULL,
	message = "Data for attitudes toward immigration-related policies, both before and after an experiment which randomly exposed a treated group to Spanish-speakers on a Boston commuter train platform. See Enos (2014) for background and details (pdf). Individuals with a treatment value of 'Treated' were exposed to two Spanish-speakers on their regular commute. 'Control' individuals were not.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The data we have were collected from commuters on nine train platforms around Boston, Massachusetts. However, were the people on the trains in Boston similar to people at Chicago? And, were the people who took the train that day and those who will take it tomorrow similar? We do not know. 

### Exercise 4

Attitude toward immigration is the broad topic of this tutorial. Given that topic, which variable in `trains` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "att_end",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Considering where and when our data was collected is important since most of the cases, the data we have might not be relevant to answer our question. Imagine how irrelevant it is to answer question about French's people attitude towards immigration using data collected from Boston commuters. 

### Exercise 5

Referring to the help page, type down the location where the data was collected and when.

```{r the-question-5}
question_text(NULL,
	message = "Data was collected on nine train platforms around Boston, Massachusetts in 2014.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The data was collected on train platforms in Boston, would it be the same in New York, Chicago, or anywhere else? We do not know. And, was the data collected in 2014 would be the same as now? Probably not.

### Exercise 6

Referring to the help page and/or the original paper, identify the subject of this data set. 

```{r the-question-6}
question_text(NULL,
	message = "The subject of this data set is about immigration.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Subject are often very broad: conquest, war, famine, marriage, birth,... or simply whatever you are genuinely interested. Thinking about a subject often helps to clarify three topics: the outcome, the units and the important covariate/treatment.

### Exercise 7

Define the units in this data set. 

```{r the-question-7}
question_text(NULL,
	message = "The units are each individual in the train platforms at Boston that participated in the experiment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The units are the level at which we measure the outcome. The general subject of income can be studied at many levels: individual, family, business, town, state and country, to name just a few.

### Exercise 8

Identify the outcome variable in the data set. 

```{r the-question-8}
question_text(NULL,
	message = "The outcome variable is the attitude towards immigration at the end of the experiment, denoted as `att_end` in the data set.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- GK: Typo in the Cardinal virtues, should be "left-hand side" variable -->
The outcome is the variable which we are trying to understand/explain/predict/control. It is the “left-hand side” variable in the statistical model which we will construct.

### Exercise 9

Identify the key covariates in the data set. 

```{r the-question-9}
question_text(NULL,
	message = "The key covariates can be sex, race, treatment, party.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The covariate/treatment is the variable which we are most interested in, the one whose connection, if any, to the outcome is at center of our project. If are task is mere prediction, then there may not be a central covariate/treatment.

### Exercise 10

Once we have a subject, with the outcome, units, and covariates, ask a broad question. Note that there is no right or wrong question. (Hint: A broad question means that they not yet require a numerical answer)

```{r the-question-10}
question_text(NULL,
	message = "What factor influence an individual's attitude towards immigration.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The broad question might, or might not, mention the units.  The outcome variable is often mentioned first. After all, it is at the center of our project. The most important covariate/treatment is mentioned second. 

### Exercise 11

Now we had a broad question, let's drill down to a more specific question, which require a numerical answer. Think and write down a predictive question.

```{r the-question-11}
question_text(NULL,
	message = "If a person is exposed to Spanish-speakers, what would be their attitude towards immigration?.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- GK: Not sure how to illustrate the point that the point that predictive questions always make sense. Causal questions are sometimes nonsense -->
In a predictive question, we merely want to **predict** an outcome without claiming any causal effect between variables. Therefore, the predictive models only have one outcome column.

### Exercise 12

Given our suggested question, what quantity of interest might you be interested in?

```{r the-question-12}
question_text(NULL,
	message = "The attitude towards immigration of people in the treated group at the end of the experiment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Quantity of Interest is the number which you want to estimate. It is the answer to a specific question.

### Exercise 13

Using the same the outcome, units, and covariates, think and write down a causal question this time.

```{r the-question-13}
question_text(NULL,
	message = "What is effect of exposing people towards Spanish-speakers on their attitudes towards immigration at the end of the experiment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Causal models have more than one (potential) outcome column because we need more than one potential outcome in order to estimate a causal effect. The first step in a data science problem is to determine if your QoI requires a causal or a predictive model.

### Exercise 14

Given our suggested question, what quantity of interest might you be interested in?

```{r the-question-14}
question_text(NULL,
	message = "The quantity of interest for this case is the difference between the attitudes towards immigration of the treated group versus control group at the end of the experiment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You will almost always calculate a posterior probability distribution for your Quantity of Interest since, in the real world, you will never know your QoI precisely.

### 

This is the question we will be answer: 
> *What is the effect, of exposing people to Spanish-speakers, on their attitudes toward immigration?*

To answer that specific question, here is the quantity of interest that we will estimate: 
> Difference between the attitudes towards immigration of the treated group versus control group at the end of the experiment (the treatment effect).

Once we have our specific question, we can start with the Cardinal Virtues.

## Wisdom
### 

*Wisdom begins in wonder.* - Plato

We begin our data science project with a general question. Imagine we are designing an immigration policy for the government, we wonder how people, those who affected most by the policy, would respond. In other words, 

> *We are interested in the attitudes of people toward immigration.*

### 

We decide to narrow down our question to a specific location, let's say adult people in Chicago, Illinois. We wonder how these people would feel when being near foreigners, let's say people who only speak Spanish.

> *What is the effect, of exposing people to Spanish-speakers, on their attitudes toward immigration?*

### Exercise 1

In your own words, describe the key components of Wisdom for working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If it is not *valid* to consider the data you have and the (theoretical) data from the Preceptor Table to have arisen out of the same population, your attempt to estimate your quantity of interest ends at the first stage. 

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, it is easy to calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table in this case contains each person's attitude toward immigration when they get exposed to Spanish-speakers, and when they don't so that we can easily calculate the average treatment effect.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem.

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

As we are considering *causal model*, our Preceptor Table will have two columns for the potential outcomes. In any causal model, there is at least one covariate which is defined as the “treatment,” something which we can manipulate, at least in theory, so that some units receive one version and other units get a different version.

### Exercise 4

What are the units for this problem?

```{r wisdom-4}
question_text(NULL,
	message = "Our units for this scenario would be individuals because the questions are about the attributes of unique people at the station. The question does not specify which individuals we are interested in, so assume it is adults in Chicago.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that the units and the quantity of interest are two different things. Quantity of interest is the number we want to estimate to answer our question, which is the effect of exposing people to Spanish-speakers on attitude toward immigration.

### Exercise 5

What is/are the outcome/outcomes for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "A person’s attitude toward immigration is the outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A person's attitude toward immigration is measured based on the three questions, each measuring agreement on a 1 to 5 integer scale, with 1 being liberal and 5 being conservative. For each person, the three answers were summed, generating an overall measure of attitude toward immigration which ranged from 3 (very liberal) to 15 (very conservative).

### Exercise 6

What are the covariates for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "Possible covariates include, but are not limited to, sex, age, political party and almost everything else which might be associated with attitudes toward immigration.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

**Covariates** can be any variable that can influence the outcome. Be careful that  **covariates** may have different meanings depending on the problems so it's best to consider specific context when discussing this term. For more detailed explanation, visit [Cardinal Virtues](https://ppbds.github.io/primer/cardinal-virtues.html) section.

### Exercise 7

What are the treatments, if any, for this problem?

```{r wisdom-7}
question_text(NULL,
	message = "In this case, the treatment is exposure to Spanish-speakers. Units can either be exposed, i.e., they receive the 'treatment', or they can not be exposed, i.e., they receive the 'control'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In any causal model, there is at least one covariate which is defined as the “treatment,” something which we can manipulate, in theory, so that some units receive one version and other units get a different version. A “treatment” is just a covariate which we *could* manipulate, at least in theory. 

### Exercise 8

What moment in time does the Preceptor Table refer to?

```{r wisdom-8}
question_text(NULL,
	message = "We are interested in the causal effect today, in the year 2024.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The notion of time is important, both in our Preceptor Table and in our data. Our data comes from some point in the past, even if it was collected yesterday or just minutes prior, while our questions usually refer to now or to an indeterminate moment in the future.

### Exercise 9

Define causal effect.

```{r wisdom-9}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In most circumstances, we are interested in comparing two experimental manipulations, one generally termed “treatment” and the other “control.” According to the [Rubin Causal Model (RCM)](https://ppbds.github.io/primer/rubin-causal-model.html), the causal effect of being on the platform with Spanish-speakers is the difference between what your attitude would have been under “treatment” (with Spanish-speakers) and under “control” (no Spanish-speakers).

### Exercise 10

What is the **Fundamental Problem of Causal Inference**?

```{r wisdom-10}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In our experiment, it is impossible to observe both potential outcomes at once. One of the potential outcomes is always missing, since a person cannot travel back in time, and experience both treatments. 

### Exercise 11

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-11}
question_text(NULL,
	message = "The causal effect of exposure to Spanish-speakers is well defined because it is the simple difference of two potential outcomes, both of which might happen. In this case, we (or something else) can manipulate the world, at least conceptually, so that it is possible that one thing or a different thing might happen.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The question of what can and cannot be manipulated are very complex when it comes to race, sex, or genetics and should be considered with care. For instance, we cannot increase a person's height so it makes no sense to investigate the causal effect of height on weight, hence the slogan: *No Causation without manipulation*.

### Exercise 12

Describe in words the Preceptor Table for this problem.

```{r wisdom-12}
question_text(NULL,
	message = "The Preceptor Table has one row for every adult in Chicago in 2024, two columns for people's attitude towards immigration when exposed to Spanish-speakers and when not, and one column indicating whether they belong to 'treatment' or 'control' group.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
#| echo: false
tibble(ID = c("1", "2", "...", "10", "11", "...", "N"),
       attitude_after_control = c("5*", "7", "...", "3*", "10*", "...", "6"),
       attitude_after_treated = c("8", "4*", "...", "5", "7", "...", "13*"),
       treatment = c("Yes", "No", "...", "Yes", "Yes", "...", "No")) |>
  
  gt() |>
  tab_header(title = "Preceptor Table") |> 
  cols_label(ID = md("ID"),
             attitude_after_control = md("Control Ending Attitude"),
             attitude_after_treated = md("Treated Ending Attitude"),
             treatment = md("Treatment")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(ID))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(ID))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Potential Outcomes", columns = c(attitude_after_control, attitude_after_treated)) |>
  tab_spanner(label = "Covariate", columns = c(treatment))
```

### Exercise 13

Write one sentence describing the data you have to answer your question.

```{r wisdom-13}
question_text(NULL,
	message = "The data include information about each respondent’s sex, political affiliations, age, income and so on. 'treatment' indicates whether a subject was in the control or treatment group. The key outcome is their attitude toward immigration after the experiment: 'att_end'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In this data set, in each row, we can only have either the outcome for **treated** or **control**, not both, since the respondent cannot be in both groups --- recall the **Fundamental Problem of Causal Inference**. 

### Exercise 14

Let's practice creating and publishing a quarto document to answer the question we have in a professional way. Create a Github repo called `causal-effect`. Make sure to click the "Add a README file" check box. Copy/paste the URL for its Github location.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Professional data scientists always do and store their work on Github, or a similar "source control" tool. If your computer blows up, you don't want to lose your work.

### Exercise 15

Connect the `causal-effect` Github repo to an R project on your computer. Name the R project `causal-effect` also. 

In the Console, run:

````
list.files()
````

CP/CR.

```{r wisdom-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Perhaps one of the most important things when working with data is always questioning what we have been told. In this case, it's worth asking questions such as how the participants were selected, what time and where the experiment took place.

### Exercise 16

Select `File -> New File -> Quarto Document ...`. Provide a title ("Causal Effect") and an author (you). Save the document as `analysis.qmd`. 

In the Console, run:

````
list.files(all.files = TRUE)
````

CP/CR.

The `all.files = TRUE` argument for `list.files()` generates all the files/directories, including the "hidden" ones whose names begin with a period, `.`. 

```{r wisdom-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- AC: Uhm, "people who were not originally here" might not be the best way to phrase it.  -->

If the experiment took place in rush hours when the trains are crowded and everyone is busy, people may get frustrated when having to share public spaces with people who were not originally here. In that case, rush hour is the covariate that might affect the outcome, which is the effect of exposing people to Spanish-speakers on their attitude towards immigration. 

### Exercise 17

Edit the `.gitignore` by adding `*Rproj` and `*_files`.

In the Console, run:

````
tutorial.helpers::show_file(".gitignore")
````

CP/CR.

```{r wisdom-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Consider the same case, if we are aware of this potential factor which may affect the outcome and decide to record the rush hour when collecting the data. In that case, `rush hour`, like `treatment` is a covariate which is measured but is not the outcome.  

### Exercise 18

Remove everything below the YAML header from `analysis.qmd` and save the file. In the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
````

CP/CR.

```{r wisdom-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

With the same case again, when putting variables into our DGM, we decide to only include `treatment`, but not `rush hour`, then only `treatment` is considered a covariate.

### Exercise 19

Add a new code chunk, load the **tidyverse** and **primer.data** packages. Save the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r wisdom-19}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Note that the three above examples represent three different contexts in which we might use the term covariates. The second usage is, obviously, a subset of the first, and the third usage is a subset of the second.

### Exercise 20

On top of that code chunk, add `#| message: FALSE` to prevent messages that are generated when we load up the packages. Save the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd")
```

```{r wisdom-20}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Discussing covariates in the context of the Preceptor Table is different than discussing covariates in the context of the data. Recall that the Preceptor Table is the smallest possible table, so we don’t need to include every relevant variable, we only need the ones that are necessary to answer the question.

### Exercise 21

As we render the file, it also shows the code we did to load up the packages in our document. Add `#| echo: FALSE` to prevent the code from appearing in our rendered document. Save and render the file again and the code will go away.

In the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r wisdom-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The data we have may not allow us to answer that question, but it may be enough to answer a related question. Is that good enough for the boss/client/colleague who asked the original question? Maybe? You won’t know until you ask.

### Exercise 22

Always load up the data to see what we have to answer our question. Type `trains` and hit "Run Code".

```{r wisdom-22, exercise = TRUE}

```

```{r wisdom-22-hint-1, eval = FALSE}
trains
```

```{r wisdom-22-test, include = FALSE}
trains
```

### 

If the data is not close enough to the question, then we check with our boss/colleague/customer to see if we can modify the question in order to make the match between the data and the Preceptor Table close enough for validity to hold.

### Exercise 23

Pipe `trains` to `select(att_end, treatment)` and then to `summary()`.

```{r wisdom-23, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-23-hint-1, eval = FALSE}
trains |>
  select(..., treatment) |>
  ...()
```

```{r wisdom-23-test, include = FALSE}
trains |>
  select(att_end, treatment) |>
  summary()
```

### 

The attitude towards immigration after the experiment (att_end) ranges from 3 to 15, with a median of 9 and a mean of 9.139. Notice that there are 51 people in the **treatment** group and 64 people in the **control** group, which is a reasonable distribution for comparing the effects of the treatment.

<!-- XX: Insert comments about the data. -->


<!-- Variable questions come in two types. First there are questions which require the student to run, say, summary() on the variable. Then, knowledge about the variable can be dropped. Second, there are questions which ask for a one sentence summary about the variable, something which could be used in our summary of the project. -->

### Exercise 24

Turning to our `analysis.qmd`, add a new code chunk. In this code chunk, type `trains` to load the data set. In the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
````

```{r wisdom-24}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Recall the key components in **Wisdom**, we first start a with a question, determine our Preceptor Table. Next, we load up the data we have and examine our data using the concept of "validity". 

### Exercise 25

Within that code chunk, pipe `trains` to `select(att_end, treatment)` and then assign the result to an object called ``ch6``. In the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
````

```{r wisdom-25}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

As the outcome we care about is the attitude toward immigration at the end of the experiment for both the **treatment** and the **control** group, we only need to keep these two variables. 

### Exercise 26

As we render the file, the code shows up again. To prevent adding `#| echo: FALSE` in every code chunk, in the YAML header, add: 

```
execute: 
  echo: false
```

You can delete `#| echo: FALSE` in the libraries code chunk as it is no longer needed. Save the file and in the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
````

CP/CR.

```{r wisdom-26}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The central point to remember is that we have two (potentially!) completely different things: the Preceptor Table (what we need to answer our question) and the data (what we have). Both data sets may have the same columns (e.g. attitudes towards immigration), but it does not mean that they are the same thing. They will often be quite different!

### Exercise 27

In your own words, define "validity" as we use the term.

```{r wisdom-27}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

In order to consider the two data sets to be drawn from the same population, the columns from one must have a valid correspondence with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.

### Exercise 28

What can't we do if the assumption of validity is not true?

```{r wisdom-28}
question_text(NULL,
	message = "We can't combine the Preceptor Table and the data in order to construct the Population Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We can either give up on the analysis — and this is often the correct decision! — or we can adjust the meaning of the columns in the Preceptor Table so that they are “close enough” to the data that validity holds. You won’t be surprised to see that we choose the option behind Door #2!

### Exercise 29

Provide one reason why the assumption of validity might not hold for this problem.

```{r wisdom-29}
question_text(NULL,
	message = "Consider the outcome measure in our data, which involves one's attitude toward immigration. The phrases used in the 2012 survey do not mean the same thing today as they meant then, as the aspects of immigration policy which we are most interested in have changed. ",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In a conflict between the data and the Preceptor Table, the latter must adjust because we can’t (easily) change the data.


### Exercise 30

Summarize the state of your work so far in one or two sentences. Make reference to the data you have and to the question you are trying to answer. 


```{r wisdom-30}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Going back to `analysis.qmd`, at the end of the file, type your adjusted answer to this question based on our suggestion. Don't forget to save the file. 

## Justice
### 

*Justice is truth in action.* - Benjamin Disraeli

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

**Stability** looks across time periods, **Representativeness** looks within time periods, allowing us to make connection between the data we have and the population, and the population to the Preceptor Table. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table can only be constructed if the *validity* assumption is (mostly) true. Besides incorporating the rows from the Preceptor table and the dataset, it usually has other rows as well, rows which represent unit/time combinations from other parts of the population. 

The Population Table looks like this: 

```{r}
#| echo: false
tibble(source = c("...", "Data", "Data", "...", 
                  "...", "Preceptor Table", "Preceptor Table", "..."),
       att_treat = c("...", "7*", "6", "...",
                     "...", "...", "...", "..."),
       att_control = c("...", "2", "10*", "...", 
                       "...", "...", "...", "..."),
       city = c("...", "Boston, MA", "Boston, MA", "...", 
                "...", "Chicago, IL", "Chicago, IL", "..."),
       year = c("...", "2012", "2012", "...", 
                "...", "2024", "2024", "..."),
       treatment = c("...", "No", "Yes", "...", 
                     "...", "...", "...", "...")) |>
  
  gt() |>
  tab_header(title = "Population Table") |> 
  cols_label(source = md("Source"),
             att_treat = md("Treated"),
             att_control = md("Controlled"),
             treatment = md("Treatment"),
             city = md("City"),
             year = md("Year")) |>
  tab_style(cell_borders(sides = "right"),
            location = cells_body(columns = c(source))) |>
  tab_style(style = cell_text(align = "left", v_align = "middle", size = "large"), 
            locations = cells_column_labels(columns = c(source))) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(source)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Potential Outcomes", columns = c(att_control, att_treat)) |>
  tab_spanner(label = "Covariates", columns = c(treatment, year, city))
```

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references of the Preceptor Table. 

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "In this case, the US politics has changed so much since 2012, especially in regard to immigration. Immigration is much more salient now then it was then, so it is likely that the effect of the treatment might be very different today.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

However, if we don’t assume stability then we can’t use data from 2012 to inform our inferences about 2024. So, we assume it.

### Exercise 5

In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case. 

### Exercise 6

Provide one reason why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Our Preceptor Table is not a random draw from the underlying population today as we only care about Chicago (and not any other city).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A similar set of issues apply to our data as it is not a random draw from the underlying population in 2012. Instead, we only have data from Boston, and not any other city. 

### Exercise 7

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-7}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. A model is *confounded* if this is not true.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The easiest way to ensure unconfoundedness is to assign treatment randomly. In our experiment, this may involve giving each person a number and then randomly picking a number to assign the treatment. 

### Exercise 8

Provide one reason why the assumption of unconfoundedness might not be true (or relevant) in this case.

```{r justice-8}
question_text(NULL,
	message = "In this case, the assumption of unconfoundedness might not be true if the participants in the treatment and control group are not truly randomly selected, but selected by a person choosing 'randomly' (which is likely not truly random).",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Since treatment was assigned at random, we can be fairly confident that treatment assignment is independent of everything. This is the beauty of randomization and the key reason why randomized control trials are the gold standard in statistics for drawing conclusions about causal effects.

### Exercise 9

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention at least one specific problem which casts doubt on your approach. 


```{r justice-9}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024. There is some concern that the relationship has changed since our data was collected.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Update `analysis.qmd` paragraph accordingly. Do not just copy/paste our example answer, obviously!  

## Courage
### 

*Courage is going from failure to failure without losing enthusiasm.* - Winston Churchill

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

Because `att_end` is a continuous variable, we assume that an individual's attitude toward immigration is produced from a Normal distribution.

$$att\_end_i \sim Normal(\mu, \sigma^2)$$


### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

Because we are using a Normal distribution, the link function is the identity. That is:

$$ \mu =  \beta_0 + \beta_1 x_1 + \dots $$

### Exercise 4

Add `library(brms)` and `library(tidybayes)` to the `setup` code chunk in `XX.qmd`. Copy and paste the below code for the mathematical structure of the model to the body of `XX.qmd`. `Command/Ctrl + Shift + K`. 


```
$$ att\_end_i \sim Normal(\mu, \sigma^2)$$
$$ \mu =  \beta_0 + \beta_1 x_1 + \dots $$
```

At the Console, run:

```
tutorial.helpers::show_file("XX.qmd", pattern = "brms|tidybayes|\\$\\$")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Of course, our model must make use of the variables we actually have. Consider:

$$ \mu =  \beta_0 + \beta_1 att\_start + \beta_2 sexmale $$
<!-- DK: Knowledge -->


### Exercise 5

Type `?tidybayes` in the Console and copy paste the description. CP/CR.

```{r courage-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- XX: Some comments about this problem. -->
Always stick to the question we are trying to answer:

> What is the average treatment effect, of exposing people to Spanish-speakers, on their attitudes toward immigration? 

We need to provide a mathematical formula for our model to work on, using the two variables that are necessary to answer this question: `att_end` and `treatment`.

### Exercise 6

Type `trains` and hit "Run Code." This will generate the data set about US commuters toward immigration, which will be used to construct the model.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
trains
```

```{r courage-6-test, include = FALSE}
trains
```

### 

The `treatment` can either be “Treated” or “Control” which are the two factors that may influence `att_end`. Participants were asked three questions about immigration issues, each of which allowed for an answer indicating strength of agreement on a scale form 1 to 5, with higher values for `att_end` indicating more agreement with conservative viewpoints.

### Exercise 7

Create a model using `brm()` from the **brms**. Use the argument `formula = att_end ~ treatment`, `data = trains`, `family = gaussian()`, `refresh = 0`, `silent = 2`, and `seed = 9`.

Assign the result to an object called `fit_gauss`.


```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
fit_gauss <- brm(formula = ...,
                ... = trains,
                family = gaussian(),
                ... = 0,
                silent = ...,
                ... = 9)
```

```{r courage-7-test, include = FALSE}
fit_gauss
```

This will take a little while to run. It won't produce anything because of the `refresh` and `silent` arguments. 

### 

Note that other numbers assigned to the `seed` argument will not affect the result since it is only for the purpose of eliminating the effect of randomness in the modeling fitting process. If you and your friend are running the above code in your own computers and want to cross-check the result, remember to set the same value for `seed`. 

### Exercise 8

In the `analysis.qmd`, add a new code chunk copy paste your answer above, remember to change the argument `data` to `ch6`. 

Save the file and in the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
```` 

```{r courage-8}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Selecting a model sometimes can feel like a trial and error process in which we first come up with a model to estimate our quantities of interest, test the model and try a different one until we find the most suitable model to answer our problem. 

### Exercise 9

As the model takes a while to run, it will be time-consuming when rendering the document many times along our work. On the top of the model setup, type `#| cache: TRUE`. Save and render the file again, you will see that it renders faster. 

In the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd", pattern = "cache")
```` 

```{r courage-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Running `#| cache: TRUE` will save the results of the code chunk the first time it is run, and subsequent runs will use the cached results instead of re-executing the code. 

### Exercise 10

Type `fit_gauss` and hit "Run Code." This generates the same results as using `print(fit_gauss)`.


```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
print(...)
```

```{r courage-10-test, include = FALSE}
print(fit_gauss)
```

### 

The top 4 rows (`Family`, `Link`, `Formula`, `Data`) are the setup of the models, you want to check this to make sure you did not make a mistake in the call to `brm()`. Next, we will go deeper into each of these rows.

### Exercise 11

Run `family()` on `fit_gauss`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
family(...)
```

```{r courage-11-test, include = FALSE}
family(fit_gauss)
```

### 

In this case, the "Family" is `gaussian`, which is the default value for the `family` argument in `brm()`. Gaussian is another term for the normal distribution. 

### Exercise 12

Run `formula()` on `fit_gauss`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
formula(...)
```

```{r courage-12-test, include = FALSE}
formula(fit_gauss)
```

### 

In this case, the "Formula" is `att_end ~ treatment`, which is what we passed in to the formula argument when we called `brm()`. 

### Exercise 13

Run `nobs()` on `fit_gauss`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-13-test, include = FALSE}
nobs(fit_gauss)
```

### 

In this case, the "number of observations" is `r scales::comma(nobs(fit_gauss))`. These are the people for whom we have the data.

### Exercise 14

Recall the definition of `Posterior Distribution` from [Chapter 2](https://ppbds.github.io/primer/probability.html#probability-distributions), which is a type of `Probability Distribution` that is based on our beliefs and expectations.

Run `posterior_interval()` on `fit_gauss`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-14-test, include = FALSE}
posterior_interval(fit_gauss)
```

### 

We are 95% confident that the true value of each parameter lies within its associated confidence interval. Note that we might also use the term "uncertainty interval" to describe this range.

### Exercise 15

Run `fixef()` on `fit_gauss`. The `fixef()` returns information about the **fix**ed **ef**fects in the model, meaning the estimated values for certain parameters.

```{r courage-15, exercise = TRUE}

```

```{r courage-15-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-15-test, include = FALSE}
fixef(fit_gauss)
```

### 

The precise definition of "fixed effects" is beyond the scope of this tutorial. See [here](https://statmodeling.stat.columbia.edu/2005/01/25/why_i_dont_use/) for extended discussion.


### Exercise 16

In order to check whether we have selected the right model, we can compare our model's prediction with our actual data. The **bayesplot** package includes the `pp_check()` function for that purpose.

Run `pp_check()` on `fit_gauss`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-16-test, include = FALSE}
pp_check(fit_gauss)
```

### 

If we run this code again we will get a (very slightly) different answer because the fitting process is **random**, but if the fake data had looked very different from the real data, that means that we have had a problem. However, for the most part, we conclude that, although not perfect, `pp_check()` shows that the fake outcomes generated by our model are like the actual outcome data. 

### Exercise 17

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package, which helps create professional summaries and analytical tables. 

```{r courage-17, exercise = TRUE}

```

```{r courage-17-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-17-test, include = FALSE}
library(gtsummary)
```

### 

Recall that choosing a model is a trial and error process, if the model we use generates an outcome that is very different from the data, it might be because of the assumption we use. We assume the default value of `family = gaussian()` in our model, perhaps changing the value for `family` might have. 

<!-- AC: The previous sentence is unfinished (?) -->

### Exercise 18

In the `analysis.qmd`, load the **gtsummary** package in the library setup code chunk. Save the file and in the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
````

CP/CR.

```{r courage-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

With the help of the data generating mechanism that we have created from our fitted model, we can fill in the missing values to the Preceptor Table. We use the data generating mechanism as the last step of Courage as it allows us to analyze and view our fitted model’s data.

### Exercise 19

It is also possible to summarize the regression results using the function provided by the **gtsummary** package. 

### 

Run `tbl_regression()` on `fit_gauss`. 


```{r courage-19, exercise = TRUE}

```

```{r courage-19-hint-1, eval = FALSE}
tbl_regression(...)
```

```{r courage-19-test, include = FALSE}
tbl_regression(fit_gauss)
```

### 

The posterior, or the coefficient of $Control$ is centered around $-1.5$ with a $95\%$ Confidence Interval between $-2.5$ and $-0.5$. 

### Exercise 20

In the `analysis.qmd`, add a new code chunk and type `tbl_regression(fit_gauss)`. Below that code chunk, add a sentence to describe the results provided by the command. Save the file and in the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd")
````

```{r courage-20}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Note that the phrase "confidence interval" is usually given a "Frequentist" interpretation: if we were to apply the procedure we used in an infinite number of future situations like this, we would expect the true value to fall within the calculated confidence intervals 95% of the time. However, at the end, both interpretations refer to our degree of uncertainty in a sample statistic, and thus we have the general term which is "uncertainty interval."

### Exercise 21

<!-- AC: Copying the previous code doesn't work here since it copies the answer to 20 rather than the code from 19. Possibly rearrange the two? -->

You can also customize your table by adding more arguments into the function and setting them equal to `TRUE/FALSE`. Refer to the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package for further instruction.

Copy the previous code. Add `intercept` equal to `TRUE` in the argument. 

```{r courage-21, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-21-hint-1, eval = FALSE}
tbl_regression(fit_gauss, ... = TRUE)
```

```{r courage-21-test, include = FALSE}
tbl_regression(fit_gauss, intercept = TRUE)
```

### 

The key parameter in our model is the `Intercept`, which is in this case, estimates the attitude toward immigration among the Treated group in the population. The posterior of the `Intercept` is centered around `10` with a $95\%$ Confidence Interval between $9.2$ and $11$.

### Exercise 22

Write a few sentences which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add at least one sentence which describes the modelling approach which you are using, specifying at least the functional form and the dependent variable. Add at least one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-22}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024. There is some concern that the relationship has changed since our data was collected. We modeled att_end, a summary measure of attitude toward immigration measured on a 3 to 15 integer scale, as a linear function of treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Update the `analysis.qmd` paragraph accordingly. Do not just copy/paste our example answer, obviously!  

## Temperance
### 

*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton

### Exercise 1

In your own words, describe the use of Temperance in finishing your data science project.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the Data Generating Mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that the posteriors we create are never the “truth.” and the assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 2

Recall the question with which we began:

> What is the average treatment effect, of exposing people to Spanish-speakers, on their attitudes toward immigration?

We will be using the `add_epred_draws()` from the **tidybayes** package to generate our prediction on the distribution of the average treatment effect. But first, type `fit_gauss` and hit "Run Code". 

```{r temperance-2, exercise = TRUE}

```

```{r temperance-2-hint-1, eval = FALSE}
fit_gauss 
```

```{r temperance-2-test, include = FALSE}
fit_gauss 
```

### 

We want to examine the behavior of our model with new data sets, data which was not used in model estimation. Therefore, the `add_epred_draws()` requires a `newdata` argument.

### Exercise 3

Run the command `tibble()` with the argument `treatment = c("Treated", "Control")`. 

```{r temperance-3, exercise = TRUE}

```

```{r temperance-3-hint-1, eval = FALSE}
tibble(... = c(..., ...))
```

```{r temperance-3-test, include = FALSE}
tibble(treatment = c("Treated", "Control"))
```

### 

This will return a column named "Treatment" and two rows named "Treated" and "Control". We will use this new tibble to generate our model predictions.

### Exercise 4

Behind the scene, we have created that tibble for you and stored it in an object called `ndata`. Type `ndata` and hit "Run Code".

```{r temperance-4, exercise = TRUE}

```

```{r temperance-4-hint-1, eval = FALSE}
ndata
```

```{r temperance-4-test, include = FALSE}
ndata
```

### 

Creating the value for the `newdata` argument is tricky since we need to construct the treatment variable by hand. Even though treatment is a factor variable within `trains`, we can get away with using a simple character variable since either version would be transformed into a 0/1 variable by `add_epred_draws()`.

### Exercise 5

In the `analysis.qmd`, type the command `tibble()` with the argument `treatment = c("Treated", "Control")` and assign it to `ndata`. Save the file and in the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd", pattern = "ndata")
````

CP/CR. 


```{r temperance-5}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We need to do the same here because the **qmd** is a different world in which we have not assigned anything to `ndata`. 

### Exercise 6

Pipe `fit_gauss` to `add_epred_draws()`. Set the `newdata` argument equals `ndata`.

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}
... |> 
  add_epred_draws(
    ... = ndata
  )
```

```{r temperance-6-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata)
```

### 

The first four thousand rows are draws from the first row of `ndata`, meaning `treatment` equals "Treated". The next four thousand rows are draws for `treatment` equals "Control".

### Exercise 7

Continue the pipe with the command `select()` with `treatment`, `.draw`, and `.epred` as argument. 

```{r temperance-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-7-hint-1, eval = FALSE}
... |> 
  select(..., ..., ...)
```

```{r temperance-7-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  select(treatment, .draw, .epred)
```

### 

The key variable here is `.epred`, which gives us a draw from the posterior distribution for `att_end`, or in other words Immigration Attitude post experiment. The “e” in `.epred` stands for expected value. 

### Exercise 8

In the output of the pipe, the "Treated" and "Control" posteriors are stacked up on each other, which makes it difficult for us to calculate the average treatment effect. Continue the pipe with `pivot_wider()`, with the `id_cols = .draw, names_from = treatment, values_from = .epred` arguments. 

```{r temperance-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-8-hint-1, eval = FALSE}
... |> 
  pivot_wider(...= .draw, names_from = ..., ... = .epred)
```

```{r temperance-8-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred)
```

### 

The resulting table has only 4,000 rows because we have put `Treated` and `Control` next to each other. The easiest way to calculate the causal effect is to subtract the outcome under `Control` from the outcome under `Treatment`.

### Exercise 9

Continue the pipe with `mutate()`, and set `causal_effect = Treated - Control` as an argument.

```{r temperance-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-9-hint-1, eval = FALSE}
... |>
  mutate(causal_effect = ... - ...)
```

```{r temperance-9-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control)
```

### 

Recall that we created our Data Generating Mechanism (DGM), or model, to help us "fill in" all the missing elements of the Preceptor Table. However, we will never know the **true** outcome at the end of the experiment, but a posterior for it, which can be used to make a draw. 

### Exercise 10

Continue the pipe with `select(- .draw)` to drop the `.draw` columns.

```{r temperance-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-10-hint-1, eval = FALSE}
... |> 
  select(...)
```

```{r temperance-10-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  select(- .draw)
```

### 

Each row in the output table represents a draw (or a Preceptor Table with complete information) from the posterior for the attitude post treatment of the **treated** and the **control** group. With 4,000 `causal_effect`s for 4,000 Preceptor Tables, we have a posterior for this value. 

<!-- AC: This paragraph is a bit hard to understand.  -->

### Exercise 11

Continue the pipe with `ggplot()`, mapping `x` to `causal_effect` in the `aes()` argument. This will return a graph with nothing in it as we have not mapped the data on. 

```{r temperance-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-11-hint-1, eval = FALSE}
... |> 
  ggplot(...(x = ...))
```

```{r temperance-11-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect))
```

### 

We want to know what the **average causal effect** of exposing people to Spanish speakers on their attitude toward immigration is, our model has generated 4,000 `causal_effect`s for 4,000 Preceptor table. Mapping these values on the graph helps us spot out our quantity of interest by looking at where the distribution is centered. 

### Exercise 12

Add `geom_histogram()`, setting `y` equal `after_stat(count / sum(count))` within the `aes()` argument as we want to display the probability distribution of the causal effect.

```{r temperance-12, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-12-hint-1, eval = FALSE}
... |> 
  ggplot(aes(x = ...)) + 
    geom_histogram(...(y = ...))
```

```{r temperance-12-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count / sum(count))))
```

### 

Note that the shape of the distribution follows the "bell curve" shape of a normal distribution. We have this "bell curve" distribution because we set the `family()` argument in our `fit_gauss` model to be `gaussian()`, a variable, which is the `causal_effect` in this case, with a **Gaussian** distribution is said to be normally distributed. 


### Exercise 13

Adjust the bin width by adding `bins = 100` to the `geom_histogram()` function.

```{r temperance-13, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-13-hint-1, eval = FALSE}
... |> 
  ggplot(...) + 
    geom_histogram(aes(...), bins = ...)
```

```{r temperance-13-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100)
```

### 

Each bin represents a different range of value of the `causal_effect`, the graph after we adjusted the bin width does not look as nice as before since we divided the bins into smaller intervals. However, the shape and the range of the distribution remains the same.

### Exercise 14

Change the y-axis into the percentage format. Add `scale_y_continuous()`, setting the `labels` argument to `scales::percent_format()`.

```{r temperance-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-14-hint-1, eval = FALSE}
... + 
  geom_histogram(...) + 
  scale_y_continuous(labels = ...)
```

```{r temperance-14-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100) + 
  scale_y_continuous(labels = scales::percent_format())
```

### 

Given that the distribution is normal, the mean (the average value of the total draws), the median (the middle value in the total draws), and the mode (the most frequently appeared values in the total draws) are all approximately equal. In our graph, a value of `causal_effect` around $1.5$ appears the most and in the middle of the distribution and is thus the **average causal effect**.

### Exercise 15

Change the theme of the graph by adding `theme_classic()`.

```{r temperance-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-15-hint-1, eval = FALSE}
... + 
  theme_classic()
```

```{r temperance-15-test, include = FALSE}
fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  theme_classic()
```

### 

The range from $0.5$ to $2.5$ is the $95\%$ Confidence Interval, meaning that we are $95\%$ confident that the true **average causal effect** lies within this range. 

### Exercise 16

Lastly, add `title`, `subtitle`, labels for `x` and `y`. 

```{r temperance-16, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-16-hint-1, eval = FALSE}
... + 
  labs(title = ...,
       subtitle = ...,
       x = ...,
       y = ...)
```

Remember that this is what your graph should look like: 

```{r}
#| echo: false

fit_gauss |> 
  add_epred_draws(
    newdata = ndata) |> 
  pivot_wider(id_cols = .draw, names_from = treatment, values_from = .epred) |> 
  mutate(causal_effect = Treated - Control) |> 
  ggplot(aes(x = causal_effect)) +
    geom_histogram(aes(y = after_stat(count/sum(count))), 
                   bins = 100) + 
  scale_y_continuous(labels = scales::percent_format()) + 
  theme_classic() + 
  labs(title = "Posterior for Average Treatment Effect",
         subtitle = "Exposure to Spanish-speakers shifts immigration attitudes rightward",
         x = "Difference in Attitude",
         y = "Probability")
```

### 

The posterior of the average causal effect is centered around $1.5$, with a $95\%$ Confidence Interval from about $0.5$ to $2.5$. 

### Exercise 17

In the `analysis.qmd`, create a code chunk and copy paste your answer from the above exercise. Save the file and in the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd", chunk = "Last")
````

```{r temperance-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

This is correct, as far as it goes, but we have no idea if $1.5$ is a “big” or “small” change. We need some perspective.

### Exercise 18

Let's see how big the average causal effect is. Pipe `trains` to the `filter()` function with `treatment == "Control"` as an argument. 

```{r temperance-18, exercise = TRUE}

```

```{r temperance-18-hint-1, eval = FALSE}
... |> 
  filter(treatment == ...)
```

```{r temperance-18-test, include = FALSE}
trains |> 
  filter(treatment == "Control")
```

### 

One way to determine the size of the causal effect of exposing people to Spanish-speakers on their attitude toward immigration is by comparing with the group that did not get exposed, the Control group. In other words, we want to see how people's attitude towards immigration would have been when there was no exposure to Spanish speakers and see how much this exposure could affect the outcome.

### Exercise 19

Continue the pipe with `summarize()`, with the argument `ave` equal to  `mean(att_end)` and `.by` equal to `party`. 

```{r temperance-19, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-19-hint-1, eval = FALSE}
... |> 
  summarize(ave = ..., ... = party)
```

```{r temperance-19-test, include = FALSE}
trains |> 
  filter(treatment == "Control") |> 
  summarize(ave = mean(att_end), .by = party)
```

### 

After separating the people in the Control group by their party, we find that the difference in attitude towards immigration between Democrats and Republicans is about 1.7, meaning that Democrats are typically more conservative than Republicans. Meanwhile, our estimated average causal effect is 1.5, which can almost fulfill the gap between people from these two parties, making a treated Republican almost as conservative as a typical Democrat.

### Exercise 20

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI. 

```{r temperance-20}
question_text(NULL,
	message = "Using data from a 2012 survey of Boston-area commuters, we seek to measure the causal effect of exposure to Spanish-speakers on attitudes toward immigration among adults in Chicago and similar cities in 2024. There is some concern that the relationship has changed since our data was collected. We modeled attitude toward immigration, measured on a 3 to 15 integer scale, as a linear function of treatment. The average causal effect of treatment was about 1.5, with a 95% confidence interval of 0.5 to 2.5. For context, the difference in attitude between Democrats and Republicans is about 1.7. So, the causal effect of 1.5 means that we would expect a treated Democrat to become almost as conservative on immigration as a typical Republican.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 21

In `analysis.qmd`, continue the paragraph with your adjusted answer to this question based on our suggestion. Save the file and in the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd", start = -1)
````

CP/CR. 

```{r temperance-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

And with that you have a complete answer for a question as a professional data scientist! However, we are not done yet!

### 

Recall the three primary levels of possible knowledge in [Chapter 5](https://ppbds.github.io/primer/two-parameters.html#temperance). Our model was built up from a lot of assumptions which are certainly not true in reality, so the actual average treatment effect is always more or less than our estimate. 

### Exercise 22

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval.

```{r temperance-22}
question_text(NULL,
	message = "In our model we assumed the effect of exposing people to Spanish-speakers on their attitude toward immigration in 2012 is the same in 2024, which is certainly false, the estimates for this value might be wrong. A better estimate would be about 1.2 that represent the reduction of effect overtime, with a wider confidence interval of 0 to 3.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

“The world is always more uncertain than our models would have us believe.”

## Summary
### 

This tutorial covered [Chapter 6: Three Parameters: Causal](https://ppbds.github.io/primer/three-parameters-causal.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
