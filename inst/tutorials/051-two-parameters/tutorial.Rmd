---
title: Two Parameters
author: David Kane and Mihir Kaushal
tutorial:
  id: two-parameters
output:
  learnr::tutorial:
    progressive: yes
    allow_skip:: yes
runtime: shiny_prerendered
description: 'Chapter 5 Tutorial: Two Parameters'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)

library(tidyverse)
library(primer.data)
library(skimr)
library(brms)
library(tidybayes)
library(gtsummary)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

ch5 <- nhanes |>
  filter(sex == "Male", age >= 18) |>
  select(height) |>
  drop_na()

# fit_male_height <- brm(formula = height ~ 1,
#              data = ch5,
#              family = gaussian(),
#              silent = 2,
#              refresh = 0,
#              seed = 12)
# 
# write_rds(fit_male_height, "data/fit_male_height.rds")

fit_male_height <- read_rds("data/fit_male_height.rds")

ndata <- tibble(.rows = 1)

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

## Introduction
### 

This tutorial covers [Chapter 5: Two Parameters](https://ppbds.github.io/primer/two-parameters.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/).

In this chapter, we have *two* unknown parameters: the mean $\mu$ height in the US and the standard deviation, $\sigma$, of the normally distributed error term.

The reason for making models is not, primarily, that making models is fun --- although it is! The reason is that the world confronts us. Make decisions we must. We must decide between options X or Y. We must choose from actions A, B and C. Confronted by a choice, we need to make a model of the world to help us choose wisely.

In the real world, data scientists usually do not start with a specific question. They first have a general question or idea which they want to learn more about. In our case, this general question is: 

* What is the average height?

To answer our general question, we would need to create a model of height. In order to make progress, we need to drill down to a more specific question. Specifics help you to fix ideas as you start to work on a project. Just because you start looking for this number does not mean that we can’t consider other questions. Our specific question is:

* What is the probability that the next man we meet will be taller than 180 centimeters?

Before answering our specific question, we will need to find the answer to the general question first. 

The hope for this tutorial is that, by answering this question, we'll gain a better and more thorough understanding of how professionals do data science.

## The Question
###


## Wisdom
### 

*The only true wisdom is in knowing you know nothing.* - Socrates

### Exercise 1

In your own words, describe the key components of Wisdom for working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Wisdom begins with the Preceptor Table. What data would we, ideally, require to answer our questions? We then explore the data that we actually have. We apply the concept of validity to ensure that the data we want and the data we have are similar enough to allow the latter to inform us about the former.

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, it is easy to calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A Preceptor Table has rows and columns of data such that, if you had them all, the calculation of the quantity of interest would be trivial.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem.

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- AC: The sentence below sounds a bit clunky. I tried rewording it to fit it a bit better, however it may warrant a complete rewording.  -->

For the Preceptor Table we must consider: Units, Outcome(s), Treatment, Causal or predictive model, Covariates, and Moment in Time (This is often implicit in the question itself).

### Exercise 4

What are the units for this problem?

```{r wisdom-4}
question_text(NULL,
	message = "All the men in the world, one row per man.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The rows of the Preceptor Table are the units, the objects on which the outcome is measured.

### Exercise 5

What is the outcome for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "This is the variable which we are trying to explain/understand/predict. This is not the same thing as the answer to the question we have been asked. The question might, as above, be about the probability that the next man we meet will be taller than 180 centimeters. But the concepts of 100 do not appear in the Preceptor Table. Instead, height is our outcome variable. But, if we can build a model which explains/understands/predicts height, we can use that model to answer our questions.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The outcome is the variable we are trying to predict/understand/influence.

### Exercise 6

What are the covariates for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "There are no (explicit) covariates in this model, although we will need to make use of variables like age and sex to construct our sample data.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

When we are looking at a “category” of units we call this a covariate. Possible covariates include, but are not limited to, sex, age, political party and almost everything else which might be associated with our data.

### Exercise 7

What are the treatments, if any, for this problem?

```{r wisdom-7}
question_text(NULL,
	message = "There are not treatment variables.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Treatment is the thing that we are trying to see the effect of. This data has no treatment which means we cannot create a causal inference. 

### Exercise 8

What moment in time does the Preceptor Table refer to?

```{r wisdom-8}
question_text(NULL,
	message = "Now.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This is often implicit in the question itself. One of our key roles as data scientists is to clarify the questions which we are asked. In this case, it seems clear that the questions refer to now, the present moment.

Before we continue questioning our data, let's practice creating and publishing a quarto document to answer the question we have in a professional way. Professional data scientists always store their work somewhere safe. This is so you don't lose your code even if something happens to your computer.

### Exercise 9

Create a Github repo called `two-parameters`. Make sure to click the "Add a README file" check box. 

Connect the `two-parameters` Github repo to an R project on your computer. Name the R project `two-parameters` also. 

Select `File -> New File -> Quarto Document ...`. Provide a title ("Two Parameters") and an author (you). Save the document as `analysis.qmd`. 

In the Console, run:

```
list.files(all.files = TRUE)
```

CP/CR.

```{r wisdom-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The `all.files = TRUE` argument for `list.files()` generates all the files/directories, including the "hidden" ones whose names begin with a period, `.`. 

### Exercise 10

Edit the `.gitignore` by adding `*Rproj`. Save and commit this in the Git tab. Push the commit. 

In the Console, run:

```
tutorial.helpers::show_file(".gitignore", pattern = "*Rproj")
```

CP/CR.

```{r wisdom-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Render the document with `Command/Control + Shift + K` to ensure everything works. This automatically saves the file as well. After ensuring everything works, remove everything below the YAML header from `analysis.qmd` and render the file again.

### Exercise 11

Write one sentence describing the data you have to answer your question.

```{r wisdom-11}
question_text(NULL,
	message = "The nhanes data set from the National Health and Nutrition Examination Survey conducted from 2009 to 2011 by the Centers for Disease Control and Prevention includes 15 variables, including physical attributes like weight and height.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Some variables of interest are age, sex and height. We will look at these more in depth later on.

### Exercise 12

Let's load the important packages.

Load the **tidyverse** package.

```{r wisdom-12, exercise = TRUE}

```

```{r wisdom-12-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-12-test, include = FALSE}
library(tidyverse)
```

### 

So, what does our Preceptor Table look like? Assuming we are predicting height for every adult male on Earth at this moment in time, we would have height data for every male at least 18 years of age. This means that we would have about 4 billion rows, one for each male, along with a column for each individual’s height.

### Exercise 13

Load the **primer.data** package.

```{r wisdom-13, exercise = TRUE}

```

```{r wisdom-13-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-13-test, include = FALSE}
library(primer.data)
```

### 

This Preceptor Table would extend all the way until person 4 billion-and-something. If we had this table, all of our questions could be answered with simple math and/or simulations. No inference is necessary if we have a Preceptor Table.

### Exercise 14

Load the **skimr** package.

```{r wisdom-14, exercise = TRUE}

```

```{r wisdom-14-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-14-test, include = FALSE}
library(skimr)
```

### 

We have loaded all the libraries in the tutorial, and we will need to do the same thing in the `analysis.qmd` except for the **skimr** package. This package is used for exploring our data which can be useful in the tutorial, but we will not be using this package in `analysis.qmd` so there is no need to load it there. 

### Exercise 15

In `analysis.qmd`, add a new code chunk and load the **tidyverse** and **primer.data** packages. Render the file.

Previously, we have added `#| echo: FALSE` to prevent repeating the code. Instead of adding this in every code chunk, we can add this in the YAML header: 

```
execute: 
  echo: false
```

To get rid of the message, add `#| message: FALSE` at the beginning of the code chunk.

Render the file again and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", pattern = "tidyverse|primer.data")
```

CP/CR.

```{r wisdom-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The `pattern = "tidyverse|primer.data"` will only return lines that have `tidyverse` or `primer.data` in `analysis.qmd`. The operator `|` works as *or*, so that if either `tidyverse` *or* `primer.data` are present, then that line will be returned by this code.

### Exercise 16

Edit the `.gitignore` by adding `*_files`. This will cause git to ignore any files that end with "_files". We do not need these in our github repository because these are not important. 

In the Console, run:

```
tutorial.helpers::show_file(".gitignore", pattern = "*_files")
```

CP/CR.

```{r wisdom-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The Preceptor Table will look like this:

```{r}
#| echo: false

tibble(ID = c("Person 1", "Person 2", "...", "Person 45,000", "Person 45,001", "..."),
       height = c("150", "172", "...", "160", "142", "...")) |>
  gt() |> cols_label(ID = md("ID"), height = "Height (cm)") 
```

This is just a small portion of the actual Preceptor Table, the real one would be much larger.

### Exercise 17

Run `glimpse()` on `nhanes`.

```{r wisdom-17, exercise = TRUE}
    
```

```{r wisdom-17-hint-1, eval = FALSE}
glimpse(nhanes)
```

```{r wisdom-17-test, include = FALSE}
glimpse(nhanes)
```

### 

The `nhanes` data set includes 15 variables, including physical attributes like weight and height. We do not care about most of these variables for our question. 

### Exercise 18

Pipe `nhanes` to `select()` with `age`, `sex`, and `height` as parameters.

```{r wisdom-18, exercise = TRUE}
    
```

```{r wisdom-18-hint-1, eval = FALSE}
nhanes |> 
  select(...)
```

```{r wisdom-18-test, include = FALSE}
nhanes |> 
  select(age, sex, height)
```

### 

We can notice some observations about the data. A noticeable pattern is that children generally have shorter heights than adults. Again, we only care about adult men for our purpose. 

### Exercise 19

Continue the pipe and examine a random sample using `slice_sample()` and setting `n = 5`.

```{r wisdom-19, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-19-hint-1, eval = FALSE}
... |> 
  slice_sample(...)
```

```{r wisdom-19-test, include = FALSE}
nhanes |> 
  select(age, sex, height) |> 
  slice_sample(n = 5)
```

### 

We think of both age and height as numbers. And they are numbers! But R distinguishes between “integers” and “doubles,” only the second of which allow for decimal values. In the `nhanes` data, age is an integer and height is a double.

### Exercise 20

Delete `slice_sample()` and instead use `glimpse()`.

```{r wisdom-20, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-20-hint-1, eval = FALSE}
... |> 
  glimpse()
```

```{r wisdom-20-test, include = FALSE}
nhanes |> 
  select(age, sex, height) |> 
  glimpse()
```

### 

Be on the lookout for anything suspicious. Most data sets have some NA values, we have to get rid of these so that we can use the data. 

### Exercise 21

In addition to `glimpse()`, we can run `skim()`, from the `skimr()` package, to calculate summary statistics. Delete `glimpse()` and instead use `skim()`.

```{r wisdom-21, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-21-hint-1, eval = FALSE}
... |> 
  skim()
```

```{r wisdom-21-test, include = FALSE}
nhanes |> 
  select(age, sex, height) |> 
  skim()
```

### 

Interesting! There are 353 missing values of height in our subset of data. Just using `glimpse()` does not show us that. Let’s filter out the NA’s using `drop_na()`. This will delete the rows in which the value of any variable is missing. 

### Exercise 22

Pipe `nhanes` to `filter()`, making sure to only have *adult men*. This means that `filter()` will have `sex` equal to `"Male"` and `age` is greater than or equal to `18`. Then, continue the pipe to `select()` to only the `height` and then finally drop the NA's using `drop_na()`.

```{r wisdom-22, exercise = TRUE}
    
```

```{r wisdom-22-hint-1, eval = FALSE}
nhanes |> 
  filter(sex == "Male", age >= 18) |> 
  select(...) |> 
  drop_na()
```

```{r wisdom-22-test, include = FALSE}
nhanes |> 
  filter(sex == "Male", age >= 18) |> 
  select(height) |> 
  drop_na()
```

### 

We have to clean the data so we can focus on the specific numbers to answer our question. Our question focuses on adult males so we have to narrow down our data to only ones that meed the requirements.

### Exercise 23

Pipe the previous code to `ggplot()`, with `height` in `x` axis in the `aes()`. Add `geom_histogram()` with `bins = 50` and then finally add `labs()` layer with the `title`, `x` and `y` axis title, and a `caption`.

```{r wisdom-23, exercise = TRUE}
    
```

<button onclick="transfer_code(this)">Copy previous code</button>

```{r wisdom-23-hint-1, eval = FALSE}
... |>
  ggplot(aes(...)) + 
    geom_histogram(...) +
    labs(...)
```

This is what the finished graph should look like:

```{r}
#| echo: false

nhanes |> 
  filter(sex == "Male", age >= 18) |> 
  select(height) |> 
  drop_na() |>
  ggplot(aes(x = height)) + 
    geom_histogram(bins = 50) +
    labs(title = "Male Adult Height in the US in 2010",
         x = "Height (cm)",
         y = "Count",
         caption = "Source: National Health and Nutrition Examination Survey"
         ) 
```

### 

Will the data we have --- which is only for a sample of adult American men more than a decade ago —-- allow us to answer our questions, however roughly? Only if the assumption of validity makes sense.

### Exercise 24

Copy your code from above and put it in a new code chunk in the `analysis.qmd` file and render the file. In the Console, run: 

````
tutorial.helpers::show_file("analysis.qmd", start = -5)
````

```{r wisdom-24}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Eyeballing, seems like there is a 1 out of 3 chance that the next man we meet, or any randomly chosen man, is taller than 180 cm.

There are still some more questions to be answered about the data.

### Exercise 25

In your own words, define "validity" as we use the term.

```{r wisdom-25}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the two data sets to be drawn from the same population, the columns from one must have a valid correspondence with the columns in the other.

### Exercise 26

What can't we do if the assumption of validity is not true?

```{r wisdom-26}
question_text(NULL,
	message = "We can't combine the Preceptor Table and the data in order to construct the Population Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity, if true (or at least reasonable), allows us to construct the Population Table. So if validity is not true, then we cannot construct the Population Table.

### Exercise 27

Provide one reason why the assumption of validity might not hold for this problem.

```{r wisdom-27}
question_text(NULL,
	message = "We need to be careful about mistakes like measurement units, like centimeters in one and inches in the other. And there can be issues like: Are measurements taken with shoes on or shoes off?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There are several reasons why this data might not be valid, such as inaccurate measurements. But, for the most part, the “height” variable in NHANES in 2010 is a valid proxy for the “height” of individuals today. We can stack the two data sets together and consider them to have come from the same population.

### Exercise 28

Summarize the state of your work so far in one or two sentences. Make reference to the data you have and to the question you are trying to answer.

```{r wisdom-28}
question_text(NULL,
	message = "Using The nhanes data set from the National Health and Nutrition Examination Survey conducted from 2009 to 2011 by the Centers for Disease Control and Prevention includes 15 variables, including physical attributes like weight and height, we seek to create a model of height for adult men.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In `analysis.qmd`, add the summary from above at the end of the file. Make sure to change some things accordingly to make it better. Do not just copy the answer example. Render the file. 

## Justice
### 

*The arc of the moral universe is long, but it bends toward justice.* - Theodore Parker

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is the second Cardinal Virtue in data science. Justice starts with the Population Table. Each row of the Population Table is defined by a unique unit/time combination. 

We explore three key issues. First, does the relationship among the variables demonstrate stability? Second, are the rows associated with the data and, separately? Third, for causal models only, we consider unconfoundedness. The model we will be building is not a causal model so we do not have to worry too much about unconfoundedness.

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table, a structure which includes a row for every unit in the population. We generally break the rows in the Population Table into three categories: the data for units we want to have (the Preceptor Table), the data for units which we actually have (our actual data), and the data for units we do not care about (the rest of the population, not included in the data or the Preceptor Table).

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

*The longer the time period covered by the Preceptor Table (and the data), the more suspect the assumption of stability becomes.* 

### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "One possible reason for the failure of the assumption of stability would be if immigrants since 2011 have a different average adult male height. This will change the overall average adult male height in America.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The actual data comes from a study conducted on males in 2009-2011. Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship at the time the data was gathered the same as the relationship at the time references by the Preceptor Table?

### Exercise 5

In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods.

### Exercise 6

Provide one reason why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Since participation in the survey is voluntary, it could mean that, for example, taller men are more likely to answer this question.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

It is important that our data is accurately reflecting the population whom we want to measure. Our data might underrepresent people who do not want to participate in the study for various reasons. If these people have a different average height compared to the overall average, then the lack of their participation will impact our data. 

### Exercise 7

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-7}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. Our current data is not being used for a causal model so this assumption does not matter as much as the other ones. 

### Exercise 8

Summarize the state of your work so far in two or three sentences. Start with a copy from your answer from the end of the Wisdom section. Add a sentence which highlights at least one specific problem which casts doubt on your approach.

```{r justice-8}
question_text(NULL,
	message = "Using data from the National Health and Nutrition Examination Survey conducted from 2009 to 2011, we seek to create a model of height for adult men. In particular, what is the average height of an adult male in America in 2024? Since participation in the survey is voluntary, it could mean that, for example, taller men are more likely to answer this question.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit your summary paragraph in the `analysis.qmd` accordingly. Render the file.

## Courage
### 

*Courage is the commitment to begin without any guarantee of success.* - Johann Wolfgang von Goethe

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage begins with the exploration and testing of different models. It concludes with the creation of a Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In data science, we deal with words, math, and code, but the most important of these is code. We need Courage to create the model, to take the leap of faith that we can make our ideas real.

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

For this section, we use a simple linear model:

$$ y_i =  \mu + \epsilon_i $$

with $\epsilon_i \sim N(0, \sigma^2)$. $y_i$ is the height of male $i$. $\mu$ is the average height of all males in the population. $\epsilon_i$ is the "error term," the difference between the height of male $i$ and the average height of all males. $\epsilon_i$ is normally distributed with a mean of 0 and a standard deviation of $\sigma$. 

This is the simplest model we can construct. The model has two unknown parameters: $\mu$ and $\sigma$. 

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

The parameter we most care about is $\mu$. That is the parameter with a substantively meaningful interpretation. Not only is the meaning of $\sigma$ difficult to describe, we also don't particular care about its value. Parameters like $\sigma$ in this context are *nuisance* or *auxiliary* parameters. We still estimate their posterior distributions, but we don't really care what those posteriors look like.

### Exercise 4

Update the `analysis.qmd` file. In the code chunk with the other libraries, load the **tidybayes** and **brms** packages. Render the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", pattern = "tidybayes|brms")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The `brm()` function from the **brms** package is used to create linear models.

There are several ways to examine the fitted model. The simplest is to print it. Recall that just typing `x` at the prompt is the same as writing `print(x)`.

### Exercise 5

Create a model using `brm()` from the **brms** package. Your arguments are `formula = height ~ 1`, `data = ch5`, `family = gaussian()`, `silent = 2`, `refresh = 0`, and `seed = 12`.

<!-- Do not forget to create this model yourself in the setup chunk. Do this once, save the object, comment out that code and then just read_rds to create the object for this tutorial. -->

<!-- Depending on code speed, you can run this function multiple times, without assigning the return value, looking at the printout, and seeing how things change. -->

<!-- AC: ch5 doesn't exist in the qmd yet. Perhaps going back to Wisdom 22 and adding something about putting it into the qmd would help. Though that would also mess up the "Copy previous code" for the next exercise.  -->

```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
brm(...)
```

### 

Note:

* We will be looking at this print out many times in the rest of the *Primer*. You will get used to it. The header information about Family, Links and so on just confirms what we already know. Still, you want to check this to make sure you did not make a mistake in the call to `brm()`.

* The "Estimate" of 175.87 makes sense. After all, the simple mean of the `height` in the data is: 175.8707

```{r}
#| code-fold: false
mean(ch5$height)
```

### Exercise 6

Behind the scenes of this tutorial, an object called `fit_male_height` has been created which has the result of the `brm()` call from the code above. Type `fit_male_height` and hit "Run Code". This generates the same results as using `print(fit_male_height)`.

```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
fit_male_height 
```

```{r courage-6-test, include = FALSE}
fit_male_height
```

### 

This should result in the same thing as the exercise prior to this one. 

* There is a direct connection between the mathematical form of the model created under Justice and the code we use to fit the model under Courage. `height ~ 1` is the code equivalent of $y_i =  \mu$. 

### Exercise 7

Run `family()` on `fit_male_height`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable.

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
family(...)
```

```{r courage-7-test, include = FALSE}
family(fit_male_height)
```

### 

In this case, setting `family = gaussian()` implies that $\epsilon_i \sim N(0, \sigma^2)$, just as we assumed. That is not a coincidence! If $\epsilon_i$ had a different distribution, we would need to use a different statistical family. 

### Exercise 8

Run `formula()` on `fit_male_height`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s).

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
formula(...)
```

```{r courage-8-test, include = FALSE}
formula(fit_male_height)
```

### 

In this case, the key parameter is the "Intercept," which is the same thing as $\mu$ in the mathematical description of the model and the same thing as `1` when we set `formula = height ~ 1`. In other words, we are speaking three languages here: English ("Intercept"), math ($\mu$), and code (`height ~ 1`). But all three languages are referring to the same underlying concept.

### Exercise 9

Run `nobs()` on `fit_male_height`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-9-test, include = FALSE}
nobs(fit_male_height)
```

### 

The output should be 3658. This is the number of observations or, in other words, it is the number of rows.

### Exercise 10

Run `posterior_interval()` on `fit_male_height`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-10-test, include = FALSE}
posterior_interval(fit_male_height)
```

### 

$\mu$ is not the average height of the men in the sample. We can calculate that directly. It is `r mean(ch5$height)`. Instead, $\mu$ is the average height of men in the *population*. Recall that the population is the universe of people/units/whatever about which we seek to draw conclusions. On some level, this seems simple. On a deeper level, it is very subtle. Each case is a different and the details matter.

$\sigma$ is an estimate for the standard deviation of the errors,  i.e., variability in height after accounting for the mean. 

### Exercise 11

Run `fixef()` on `fit_male_height`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-11, exercise = TRUE}

```

```{r courage-11-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-11-test, include = FALSE}
fixef(fit_male_height)
```

### 

If a parameter’s estimated value is more than 2 or 3 standard errors away from zero, we generally keep that parameter (and its associated variable) in the model. This is, probably, a variable which “matters.” The main exception to this rule is a parameter whose value is so close to zero that changes in its associated variable, within the general range of that variable, can’t change the value of the outcome by much.

### Exercise 12

Run `pp_check()` on `fit_male_height`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-12-test, include = FALSE}
pp_check(fit_male_height)
```

### 

In this case, note how similar our actual data, $y$, is to the 10 versions of the replicated data, $y_rep$. They are close enough that we are happy to use `fit_male_height`. However, the match is not perfect! The actual data is slightly more "peaked" and also features some weird bumps in the tails, especially around 200 cm. It would be possible, but not easy, to1 modify our model to match the actual data more closely. For now, we will just accept `fit_male_height` as our data generating mechanism.

<!-- If the fake data had looked very different from the real data, we have had a problem. But, for the most part, we conclude that, although not perfect, pp_check() shows that the fake outcomes generated by our model are like the actual outcome data. -->

### Exercise 13

Add a new code chunk to `analysis.qmd`.  Copy the code from Exercise 5 to that code chunk, but assign the result to a new object, `fit_male_height`. Add `#| cache: TRUE` at the beginning of the code chunk. Render the file. 

In the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r courage-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Rendering the file the first time will take a while because the object has to be created. Render it again and you will notice that it took significantly less time. This is because `#| cache: TRUE` saves the object.

### Exercise 14

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-14, exercise = TRUE}

```

```{r courage-14-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-14-test, include = FALSE}
library(gtsummary)
```

### 

We modeled `height`, a continuous variable measured in centimeters, as a linear function of a constant term. The average adult male height in the US was around 176 cm. Mathematically:

$$ height_i =  176 + \epsilon_i $$

with $\epsilon_i \sim N(0, 0.75^2)$.

### Exercise 15

In `analysis.qmd` load the **gtsummary** package.

Render the file again and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", pattern = "gtsummary")
```

CP/CR.

```{r courage-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The **gtsummary** package creates presentation-ready tables summarizing data sets, regression models, and more.  

To learn more about **gtsummary**, type `?gtsummary` in the Console, this will open up a description page. Make sure to load the **gtsummary** package in the Console first. 

### Exercise 16

Run `tbl_regression()` on `fit_male_height` and set `intercept` equal to `TRUE` inside `tbl_regression()`.

```{r courage-16, exercise = TRUE}

```

```{r courage-16-hint-1, eval = FALSE}
tbl_regression(...)
```

```{r courage-16-test, include = FALSE}
fit_male_height |> 
  tbl_regression(intercept = TRUE)
```

### 

This is what the table should look like:

```{r}
#| echo: false

fit_male_height |> 
  tbl_regression(intercept = TRUE)
```

We can see some important numbers from our data in this table, such as the average height of 176 cm.

### Exercise 17

Copy the code from above and put it in a new code chunk in the `analysis.qmd` file. Render the file and in the Console, run: 

```
tutorial.helpers::show_file("analysis.qmd", start = -5)
```

CP/CR.

```{r courage-17}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The output in the `analysis.qmd` preview should have the same table from the previous question. Again, this table provides important numbers from the data we are working with. 

### Exercise 18

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice section. Add at least one sentence which describes the modelling approach which you are using, specifying at least the functional form and the dependent variable. 

```{r courage-18}
question_text(NULL,
	message = "Using data from the National Health and Nutrition Examination Survey conducted from 2009 to 2011, we seek to create a model of height for adult men. In particular, what is the average height of an adult male in America in 2024? Since participation in the survey is voluntary, it could mean that, for example, taller men are more likely to answer this question. We modeled height using an intercept-only regression.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit your summary paragraph in the `analysis.qmd` accordingly. Render the file.

## Temperance
### 

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha 

### Exercise 1

In your own words, describe the use of Temperance in finishing your data science project.

```{r temperance-1}
question_text(NULL,
	message = 'Temperance guides us in the use of the data generating mechanism --- or the "model" ---  we have created to answer the questions with which we began. We create posteriors for the quantities of interest.',
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.

### Exercise 2

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-2}
question_text(NULL,
	message = "We are investigating the height for adult men to answer the question: What is the probability that the next man we meet will be taller than 180 centimeters?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 3

To answer our question, we need to create a `newdata` object. Which variables (e.g., which columns) do we need to include in this object?

```{r temperance-3}
question_text(NULL,
	message = "The object will only have one variable: height.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Our question only concerns one variable, and our model will not be a causal model, so we only have to worry about one variable.

### Exercise 4

Which values do you want the variables in your `newdata` object to have?

```{r temperance-4}
question_text(NULL,
	message = "The height variable in the object should hold the values of the heights of adult men.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We will be using `tibble()` to create the `newdata` object. `tibble()` is used to create a data frame. Type `?tibble` in the Console to learn more about tibble.

### Exercise 5

Here is the R code which creates the `newdata` object: `tibble(.rows = 1)`. Type it into the code exercise block and hit "Run Code."

<!-- AC: It's not clear if we're assigning it to an object (`newdata`) or not. Also it might be a bit confusing that the output says "0 rows" (as with the next exercise).  -->

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}
newdata <- tibble(...)
```

```{r temperance-5-test, include = FALSE}
newdata <- tibble(.rows = 1)
```

### 

The `.rows = 1` creates a tibble that only has one row.

### Exercise 6

Behind the scenes, we have created the `ndata` object using this code. To confirm, type `ndata` and hit "Run Code."

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-test, include = FALSE}
ndata
```

### 

This should result in the same thing as `newdata`.

### Exercise 7

Now that we have the `newdata` object, we can create a pipe which uses out fitted model to answer our question. Begin by typing `fit_male_height` and clicking "Run Code."

```{r temperance-7, exercise = TRUE}

```

```{r temperance-7-test, include = FALSE}
fit_male_height
```

### 

With expected values, we are not interested in any specific individual. The individual value is irrelevant and we use `add_epred_draws()`.

### Exercise 8

<!-- AC: It may be a good idea to also set the seed for the draws.  -->

Pipe `fit_male_height` to `add_predicted_draws()` with the argument `newdata = ndata`.

```{r temperance-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-8-hint-1, eval = FALSE}
... |> 
  add_predicted_draws(...)
```

```{r temperance-8-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = ndata)
```

### 

There are two fundamentally different kinds of unknowns which we care about: expected values and predicted values. With the latter, the relevant function is `add_predicted_draws()`. 

### Exercise 9

Continue the pipe to `ggplot()` with `x` set to `.prediction` inside `aes()`. Then add `geom_histogram()` with `y` set to `after_stat(count / sum(count))` inside `aes()`. Also include `bins = 100` inside `geom_histogram()`.

```{r temperance-9, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-9-hint-1, eval = FALSE}
... |> 
  ggplot(aes(x = ...)) +
    geom_histogram(aes(y = ...), ...)
```

```{r temperance-9-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = ndata) |> 
  ggplot(aes(x = .prediction)) +
    geom_histogram(aes(y = after_stat(count / sum(count))),
                   bins = 100)
```

### 

The graph is starting to take form. We can see the shape of the graph. It is a bell curve with a center at roughly 176 cm.

### Exercise 10

Add a layer of `labs()` with a `title`, `subtitle`, `x`, `y`, and `caption`.

```{r temperance-10, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-10-hint-1, eval = FALSE}
... +
    labs(...)
```

```{r temperance-10-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = ndata) |> 
  ggplot(aes(x = .prediction)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior for Height of Random Male",
         subtitle = "Uncertainty for a single individual is much greater than for the expected value",
         x = "Height (cm)",
         y = "Probability",
         caption = "Data source: NHANES")
```

### 

At this point, the graph should look like this: 

```{r}
#| echo: false

fit_male_height |> 
  add_predicted_draws(newdata = ndata) |> 
  ggplot(aes(x = .prediction)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior for Height of Random Male",
         subtitle = "Uncertainty for a single individual is much greater than for the expected value",
         x = "Height (cm)",
         y = "Probability",
         caption = "Data source: NHANES")
```

### Exercise 11

Finally, add `scale_x_continuous()` and `scale_y_continuous()`. Inside `scale_x_continuous()`, have `labels = scales::number_format()` and inside `scale_y_continuous()`, have `labels = scales::percent_format(accuracy = 1)`.

```{r temperance-11, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-11-hint-1, eval = FALSE}
... + 
    scale_x_continuous(...) +
    scale_y_continuous(...)
```

```{r temperance-11-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = ndata) |> 
  ggplot(aes(x = .prediction)) +
    geom_histogram(aes(y = after_stat(count/sum(count))),
                   bins = 100) +
    labs(title = "Posterior for Height of Random Male",
         subtitle = "Uncertainty for a single individual is much greater than for the expected value",
         x = "Height (cm)",
         y = "Probability",
         caption = "Data source: NHANES") + 
    scale_x_continuous(labels = scales::number_format()) +
    scale_y_continuous(labels = scales::percent_format(accuracy = 1))
```

### 

The posterior for an individual is much wider than the posterior for the expected value.

Eyeballing, seems like there is a 1 out of 3 chance that the next man we meet, or any randomly chosen man, is taller than 180 cm.

### Exercise 12

Create a new code chunk in `analysis.qmd`. Label it with `#| label: plot`. Copy/paste the code which creates your graphic.  

You will need to create your own `ndata` object in `analysis.qmd` to make this code work. The code to make `ndata` is `ndata <- tibble(.rows = 1)`

`Command/Ctrl + Shift + K` to ensure that it all works as intended. At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r temperance-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We can calculate the exact probability by manipulating the tibble of draws directly.

### Exercise 13

<!-- AC: Again, might be better to set the seed here as well.  -->

Start a new pipe with `fit_male_height` to `add_predicted_draws()` with the argument `newdata = ndata`.

```{r temperance-13, exercise = TRUE}

```

```{r temperance-13-hint-1, eval = FALSE}
... |> 
  add_predicted_draws(...)
```

```{r temperance-13-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = ndata)
```

### 

This time, we will not make a graph. Instead, we will be finding the exact answer to our question by changing the data. 

### Exercise 14

Continue the pipe to `mutate()`. Inside, have `tall` set to `if_else()`. Have parameters `.prediction > 180, TRUE, FALSE` inside `if_else()`.

```{r temperance-14, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-14-hint-1, eval = FALSE}
... |> 
  mutate(...)
```

```{r temperance-14-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = tibble(.rows = 1)) |> 
  mutate(tall = if_else(.prediction > 180, TRUE, FALSE))
```

### 

Again, the key conceptual difficulty is the population. Now that we have created a model, we look to the virtue of Temperance for guidance in using that model. The data we have is never a perfect match for the world we face. We need to temper our confidence and act with humility. Our forecasts will never be as good as a naive use of the model might suggest. Reality will surprise us. We need to take the model’s claims with a family-sized portion of salt.

### Exercise 15

Finish up the pipe with `summarize()`. Inside, have `odds` set to `mean()` with parameter `tall`.

```{r temperance-15, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-15-hint-1, eval = FALSE}
... |> 
  summarize(...)
```

```{r temperance-15-test, include = FALSE}
fit_male_height |> 
  add_predicted_draws(newdata = tibble(.rows = 1)) |> 
  mutate(tall = if_else(.prediction > 180, TRUE, FALSE)) |>
  summarize(odds = mean(tall))
```

### 

If 30% or so of the draws from the posterior probability distribution are greater than 180 cm, then there is about a 30% chance that the next individual will be taller than 180 cm.

### Exercise 16

Copy/paste the code which creates the answer into a new code chunk in `analysis.qmd`. `Command/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r temperance-16}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We have answered our specific question. But the fun does not stop here! Just because one question was answered does not mean that we can’t consider other questions. Real data scientists look at many related questions to answer, not just one. But for this tutorial, we will only look at this one question. 

### Exercise 17

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI.

```{r temperance-17}
question_text(NULL,
	message = "Using data from the National Health and Nutrition Examination Survey conducted from 2009 to 2011, we seek to create a model of height for adult men. In particular, what is the average height of an adult male in America in 2024? Since participation in the survey is voluntary, it could mean that, for example, taller men are more likely to answer this question. We modeled height using an intercept-only regression. The average height of adult men in America in 2024 is 176 cm, with  standard deviation of 7.48 cm.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Revise your answer to make it better and then add it to the `analysis.qmd` file. Do not just copy/paste our answer.

As always, note that your estimate depends on all the assumptions in your model being true. But that is a lie! All your assumptions are not true. So, your mean estimate might be wrong, and your confidence intervals are certainly too narrow.

### Exercise 18

Rearrange the material in `analysis.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r temperance-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

### Exercise 19

Publish the `two-parameters` quarto document to Rpubs. Copy and paste the link of the published document.

```{r temperance-19}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

## Summary
### 

This tutorial covered [Chapter 5: Two Parameters](https://ppbds.github.io/primer/two-parameters.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/).

```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
