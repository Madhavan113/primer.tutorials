---
title: Ordered Factors
author: David Kane and Tanay Janmanchi
tutorial:
  id: ordered-factors
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Tutorial: Ordered Factors'
---

```{r setup, include = FALSE}
library(learnr)
library(tutorial.helpers)
library(gt)
library(primer.data)
library(tidyverse)
library(brms)
library(tidybayes)
library(gtsummary)

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

# XX: Never include setup code that takes more than a few seconds to run. For
# example, using brm() takes too much time. Instead, do the below, and see the
# relevant discussion in instructions.html.

colleges_2 <- colleges |>
  select(tuition, grad_rate, selectivity) |>
   filter(tuition > 2)

# fit_colleges <- brm(formula = grad_rate ~ tuition + selectivity,
#     family = gaussian(),
#     data = colleges_2,
#     silent = 2,
#     refresh = 0)
# 
# write_rds(fit_colleges, "data/colleges_1.rds")

fit_colleges <- read_rds("data/colleges_1.rds")

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Should we add the Temperance start and finish quotes from the Primer chapters? What about other classical quotes, like "You can never look at the data too much."?   -->

<!-- Every EDA should show a scatter plot of the outcome variable on the y-axis and one of (probably the most important or the treatment) covariates on the x-axis. -->

<!-- Consider adding the model creation and saving code to a separate model.R script. Then, in analysis.R, you could just read it in. Would also be useful, in at least some tutorials, to highlight using a small sample of the data in initial fitting. -->

<!-- Instructions to Users of this Template -->

<!-- Read https://ppbds.github.io/primer/cardinal-virtues.html for details on the Cardinal Virtues.  -->

<!-- This is the template tutorial for creating any tutorial which uses the Cardinal Virtues to answer a question given a data set. Although its primary use is for the main chapters in the Primer, it could be used for independent tutorials as well. The letters `XX` are used to indicate locations which require editing. Comments with instructions are interspersed. -->

<!-- The tutorial is not done until you deal with, and remove, every XX. In general, XX will either mark a comment, which you should delete entirely once you have read it, or it will mark an object which you need to replace with the name that you have chosen. -->

<!-- Once you decide the appropriate replacement for `fit_colleges` and `analysis.qmd`, you can do a global replace to fix them all. -->

<!-- We sometimes connect XX to another word or phrase, as in [XX: unit] or `[XX: the tibble]`. In these cases, the XX indicates that this is something that you need to replace and the other words/symbols are there to guide you as to what the replacement should be. But you delete everything within the backets. For example, you might replace [XX: unit] with "candidate" (with no quotation marks) or whatever the type of unit we have in this problem. Similarly, `[XX: the tibble]` would be replaced with `trains` or whatever tibble is used in this tutorial. In both cases, we provide the correct punctuation. The word "candidate" would not have any punctuation since it is just a word in a sentence. But a tibble like `trains` needs to be surrounded by backticks. -->

<!-- Once you have followed an instruction, you should delete it. -->

<!-- How much hand-holding you do depends on tutorial number. For tutorial 4, we would want to provide the same sort of questions and verbiage as we see in Project #2 in the RStudio and Github tutorial. For tutorial 10, we can go much more quickly. -->

<!-- Note that the questions are a mixture of our three types: code, written (with answer) and written (without answer). The last is only (?) used for questions in which we ask the student to run a command like `show_file()`. Otherwise, we always provide an excellent written answer because students will generally look closely at our answer because they are concerned about whether or not their written answer matches ours. -->

<!-- Whenever you tell a student to make a change in the QMD, you should tell them to `Command/Ctrl + Shift + K` in order to render the document. This will also cause it to be saved. This is good practice for catching bugs early. (Professionals do this.) Then, the last step in these exercises is often some version of show_file() and then CP/CR. -->

<!-- Make use of, e.g., `show_file("tutorial-6.qmd", start = -5)` to get just the last 5 lines of the QMD. We don't want students to copy/paste the whole document. We also don't need to ensure that we get whatever it is that was just changed. We never look! Instead, we are just plausibly threatening to look.  -->

<!-- There are many opportunities for knowledge drops, especially after definition questions. Use them! Point out something about the details of the particular problem from the chapter. Recall that students generally won't read the chapter, so we need to pull out the highlights. -->

<!-- Most of the questions in the Temperance section relate to constructing a graphic. This leads lots of opportunities for knowledge drops. This is a good place to mention items from Courage which you might not have had room for in that section. -->

<!-- Make sure to uncomment the test code chunks once you have created the necessary objects. -->

<!-- Future Improvements To Make in This Document -->

<!-- * Turn it into a vignette at some point?  -->

<!-- * In the same way that we give several quotes to choose from at the start of each section, we ought to give several different knowledge drops to choose from, in order of sophistication, for many of the standard questions, especially related to things like families and link functions. No need for authors to reinvent the wheel.  -->

<!-- * We might also consider splitting up some of the Virtues into separate topics. After all, 20+ questions in a single topic is a bit much. -->

<!-- * Would be nice if part of the testing would run all the object creation code so that we can be sure all that code works. But that would have to be during testing only. We don't want that code to execute during Run Tutorial because it often takes too long. -->



## Introduction
### 

This tutorial is best understood when done after reading [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 

<!-- XX: If your tutorial is based on something other than the Primer then, obviously, you need a different Introduction and Summary. Recall this advice: https://ppbds.github.io/tutorial.helpers/articles/instructions.html#structure -->

## The Question
### 

*The important thing is not to stop questioning.* - Albert Einstein


### Exercise 1

Load **tidyverse**.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The data that we will use was downloaded from Opportunity Insights. Based at Harvard University, Opportunity Insights focuses on using big data to understand and improve economic mobility. They have many downloadable data sets, check it out for yourself [here!](https://opportunityinsights.org/data/)

### Exercise 2

Load the **primer.data** package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from Opportunity Insights is available in the `college` tibble.

### Exercise 3

After loading **primer.data** in your Console, type `?college` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

`college` contains data from over 900 colleges and universities in the United States. These draw primarily on data from the Department of Education’s (DOE) [IPEDS](https://nces.ed.gov/ipeds/) database in 2013 and the College Scorecard. 


### Exercise 4

Colleges are the broad topic of this tutorial. Given that topic, which variable in `college` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "We will use `grad_rate`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

`grad_rate` is the rate of graduation at that college/university from the year 2013.

There are many acceptable answers that we could measure, but, for this tutorial we will stick wil `grad_rate`.

### Exercise 5

Let's imagine a brand new variable which **does not exist** in the data. This variable should be binary, meaning that it only takes on one of two values. It should also, at least in theory, be manipulable. In other words, if the value of the variable is "X," or whatever, then it generates one potential outcome and if it is "Y," or whatever, it generates another potential outcome.

How might we manipulate this variable?


```{r the-question-5}
question_text(NULL,
	message = "We could create a new variable called `impv_food` which sees whether or not a college improved their food. We could manipulate this by giving funds to certain schools to improve their food and check the graduation rate in 5 years in comparison to schools we did not fund.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If a campus had better food, you would be more likely to stay, wouldn't you? This is called a treatment variable, when we manipulate this, we are looking for the difference in graduation rate to see whether or not improving the food incentivizes people to stay.

This is not the only right answer, we could also make a variable that measures whether or not the college renovated its dorms and manipulate this by giving funds to colleges so they can build new dorms. There are many different answers here.


<!-- There is nothing wrong with naming an imaginary variable which is not in the data set if there is not a natural one. For example, if `height` is our outcome and `nhanes` is our tibble, then maybe there isn't a good candidate treatment variable. In that case, just assume the existence of a `vitamin` binary variable for which `1` means that the individual ate vitamins growing up and `0` means they did not. -->

<!-- XX: This question and the ones that follow are tricky. We are trying to drive home some related points. First, any data set can be used to construct a causal model as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. Second, any data set can be used to construct a predictive model. Third, the same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables. All of this stuff is a *conceptual* framework we apply to the data. It is never inherent in the data itself.-->

<!-- XX: Explain that there is no right answer and that the student's response was probably fine. But, going forward, the student should use the variable we have selected. That variable should be named in future questions so that this is clear to the student. -->

### Exercise 6

Given our choice of treatment variable `impv_food`, how many potential outcomes are there for each college? Explain why.


```{r the-question-6}
question_text(NULL,
	message = "There are 2 potential outcomes because the treatment variable `impv_food` takes on 2 posible values: a college improved their food or a college didn't improve their food.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Remember `impv_food` is a binary variable, meaning it can take on only two possible values. 


<!-- XX: I am not satisfied with the wording of this next question. Our end goal is the calculation, by the student, of a causal effect, as in Exercise 8. The previous step was to just determine the number of potential outcomes, as in Exercise 6. This question wants to get students to see that each different treatment is associated with a potential outcome. Is there a better approach? -->

### Exercise 7

Write a sentence which speculates as to value of the 2 different potential outcomes which we might observe in `grad_rate` for each college when we change the value of the treatment variable `impv_food`. 


```{r the-question-7}
question_text(NULL,
	message = "The graduation rate on average was 85% for schools that improved their food, but it was only around 65% for schools that didn't improve their food.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Again, your numbers are probably different from ours, but you get the picture. We see that each different treatment is associated with a potential outcome. Improving food gives us a different graduation rate than if we didn't improve the food.

<!-- XX: Your answer must include specific values for the outcomes, even though you need to make them up. -->

<!-- XX: Again, we allow the student to answer however they like. But, in succeeding questions, we make it clear that they should use our answer. For example, once we specify different values for treatment in this questions, we use those values in the next. -->

<!-- XX: More tricky discussion. The point of the Rubin Causal Models is that the definition of a causal effect is the difference between potential outcomes. So, there must be two (or more) potential outcomes for any causal model to make sense. This is simplest to discuss when the treatment only has two different values, thereby generating only two potential outcomes. But, if the treatment variable is continuous, (like income) then there are lots and lots of potential outcomes, one for each possible value of the treatment variable. -->

### Exercise 8

Write a few sentences which specify two different values for the treatment variable, for a single unit, and then guesses at the potential outcomes which would result, and then calculates the causal effect for that unit given those guesses.

```{r the-question-8}
question_text(NULL,
	message = "For a given college, assume that the value of the treatment variables might be `improved` or `standard`. If the collge gets their food improved, then the graduation rate would be 85%. If the college doesn't improve their food, then graduation rate would be 65%. The causal effect on the outcome of a treatment of `improved` versus `standard` is 0.85 - 0.65 --- i.e., the difference between two potential outcomes --- which equals 0.2, which is the causal effect.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Our causal effect is 0.2, meaning colleges that improve their dorm food on average increase their graduation rate by 20%!


<!-- XX: More trickiness. Again, we are trying to reinforce the the definition of a causal effect as the difference between two potential outcomes. Of course, you can't just say that the causal effect is 10. The exact value depends on which potential outcome comes first in the subtraction and which second. (There is, perhaps, a default sense in which the causal effect is defined as treatment minus control. But regardless, it is better to be clear.) -->

<!-- XX: Something like: "The causal effect on attitude toward immigration of treatment versus control is 1.5." Which implies that it is treatment minus control. Or: "The causal effect on longevity of receiving an income of 20,000 versus one of 19,000 is 6 years." In both cases, we specify the outcome variable explicitly. -->

<!-- XX: Throughout, we are making clear that any causal connection means exploring the *within row* different between two potential outcomes. We don't need to look at any other rows to have that conversation. -->

### Exercise 9

<!-- Replace stuff like `[XX: the tibble]` with just the name of the tibble, i.e., `trains`. -->

Let's consider a *predictive* model. Which variable in `colleges` do you think might have an important connection to `grad_rate`? (If you don't see a reasonable variable in the data, you can just name a variable which *might have been* included in the data.)


```{r the-question-9}
question_text(NULL,
	message = "One variable which might have an important connection could be `tuition`. People who pay more for a college may be more willing to spend time there.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

Again, there is no right answer. There are other interesting variables which could impact graduation rate, such as `selectivity` and the college `enrollment`, which we might explore later in this tutorial. But for now, we have selected the outcome and key covariate which will be used. 

### Exercise 10

Write a few sentences which specify two different groups of colleges with different values for tuition. Explain that the average value of the outcome variable might differ between these two groups.

```{r the-question-10}
question_text(NULL,
	message = "Some colleges might charge a tuition of $90,000 per year. Others might have a tuition of $30,000. Those two groups will, on average, have graduation rate.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

With a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be treatment variables. We assuming that all covariates are "fixed." In that case, we should not use words like "cause," "influence," "impact," or anything else which suggests causation.

### Exercise 11

Write a predicative question which connects the outcome variable `grad_rate` to a covariate of interest. 

```{r the-question-11}
question_text(NULL,
	message = "How does graduation rate differ between colleges at the 75th and 25th percentile of tuition?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You can only use causal language --- like "affect," "influence," "be associated with," "cause,", "causal effect," et cetera --- in your question if you are creating a causal model, one with a treatment variable which you might, at least in theory, manipulate and with at least two potential outcomes.

With a predictive model, your question should focus on a comparison between different rows, or groups of rows, in the Preceptor Table.


### Exercise 12

What is a Quantity of Interest which might help us to explore the answer to our question?

<!-- XX: In general, our initial question does not include any specific numbers. It just uses words. For precision, we need to specify a Quantity of Interest that we are interested in. This is harder than it might look! It also helps to set the stage of Temperance. In all cases, the quantity of interest involves the outcome variable. (How could it not?) It also involves specific values of the covariates.  -->

<!-- XX: For predictive models, the specific question is generally of two types. First, what is the *expected* value of the outcome for various values of the independent variables? Second, what is the comparison in the expected outcome between two different groups? We are *not* simply interested in predicting the outcome variable for one unit. (In fact, of course, we might ultimately be interested in just one unit, but we need to *pretend* to be interested in lots of units in order to motivate the creation of a model.) -->

<!-- XX: For causal models, we are almost always interested in the average causal effect of treatment versus control. We are *not* simply interested in the causal effect for one specific unit. (In fact, of course, we might ultimately be interested in just one unit, but we need to *pretend* to be interested in lots of units in order to motivate the creation of a model.) -->


```{r the-question-12}
question_text(NULL,
	message = "Difference in graduation rate for colleges in the 75th and 25th percentiles of tuiton",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers which we are interested in, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.



## Wisdom
### 

*All we can know is that we know nothing. And that’s the height of human wisdom.* - Leo Tolstoy

Our question:

> *What effect does the tuition of a college have on its graduation rate?*

### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- Not only are you discussing the data, but you are also discussing potential problems with the data, problems which will be more fully fleshed out in the Justice section. You want to pick 5 to 10 interesting facts about the data. (You may need to go to the original source, not simply relying on the chapter. ) 

It is always a good idea to knowledge drop a link to the actual data and to any articles/books/websites related to it.

You won't be drawing any conclusions or discussing the explicit violation of any assumptions. That discussion is saved until Justice and the specific questions about stability, representativeness, and (with causal models) unconfoundedness. You are, however, providing the details which you and the students can then use later. -->

### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually including in your model. It only includes covariates which you need to answer your question.

### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Our question is predicative. Not all predicative questions need covariates. If our question asked "What is the probability that a student will graduate Harvard University?" There would be no covariates in this Preceptor Table. Just one column stating whether or not the student graduated.

### Exercise 4

Create a new GitHub repository with the name `tutorial-12`. Add a README file and connect it to a new R Project. Edit the `.gitignore` to include `*.Rproj`. Commit/push everything to GitHub. In the console, run `tutorial.helpers::show_file(".gitignore")` CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Using GitHub is great because it allows you to save all your code in case something were to happen to your computer.

### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "Each individual college.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If our question asked "What is the probability that a student will graduate Harvard University?" Then our units would be each individual student at the college. These are the rows of the Preceptor Table.

### Exercise 6

What is/are the outcome/outcomes for this problem?

```{r wisdom-6}
question_text(NULL,
	message = "Graduation rate for each individual college.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If our question asked "What is the probability that a student will graduate Harvard University?" Our outcome variable would be whether or not the student graduated Harvard in the end. The outcome is the main column which we are measuring.


### Exercise 7

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

```{r wisdom-7}
question_text(NULL,
	message = "We will need `tuition` for sure, some others that might be useful are: `selectivity`, size of campus, location of campus (could be `region`, `state` or `zip`) and the prestige (or `tier`) of the school",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables which we have data for. Third, it is the set of covariates which we end up using in the model.

### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "Since this is a predicative model, there are no treatments.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In our question, we seek to predict the graduation rate of a college. If we wanted this to be a causal model, our question would be something like:

> What is the causal effect of charging more money for tuition on a colleges graduation rate?


### Exercise 9

What moment in time does the Preceptor Table refer to?

```{r wisdom-9}
question_text(NULL,
	message = "Now",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We want to know the relationship between these two variables with colleges **now**. Even though our data might be from 2013, recall that the Preceptor Table is the smallest possible table with rows and columns such that, if there is no missing data, our question is easy to answer. If our data was ideal and perfect, we would have the latest, most up to date data.

### Exercise 10

Describe in words the Preceptor Table for this problem.

```{r wisdom-10}
question_text(NULL,
	message = "The Preceptor Table contains a row for each college. There are three columns: one is tuition, which is our main covariate; next we have ID and finally the last one is graduation rate, which is our outcome variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

```{r}
library(gt)
library(tidyverse)


data <- tibble(
  ID = c("1", "2", "...", "10", "11", "...", "950"),
  graduation_rate = c(0.92, 0.55, "...", 0.42, 0.78, "...", 0.87),
  tuition = c(4.5, 1.3, "...", 2.9, 2.2, "...", 3.7)
)
data |>
  gt() |>
  tab_header(title = "Preceptor Table") |>
  cols_label(
    ID = md("ID"),
    graduation_rate = md("Graduation Rate"),
    tuition = md("Tuition (tens of thousands)")
  ) |>
  tab_style(
    cell_borders(sides = "right"),
    location = cells_body(columns = c(ID))
  ) |>
  tab_style(
    style = cell_text(align = "left", v_align = "middle", size = "large"), 
    locations = cells_column_labels(columns = c(ID))
  ) |>
  cols_align(align = "center", columns = everything()) |>
  cols_align(align = "left", columns = c(ID)) |>
  fmt_markdown(columns = everything()) |>
  tab_spanner(label = "Outcome", columns = c(graduation_rate)) |>
  tab_spanner(label = "Covariate", columns = c(tuition))

```

### 

Like all aspects of a data science problem, the Preceptor Table evolves as we work on the problem. For example, at the start, we aren't sure what right-hand side variables will be included in the model, so we are not yet sure which columns must be in the Preceptor Table.


### Exercise 11

Define causal effect.

```{r wisdom-11}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Drop some knowledge making it clear how this definition even applies, or might have applied, in the current problem. Note that we keep these causal questions even with a predictive model. We want to highlight that we could, if we chose, use this same data to explore a different question which required a causal model. -->

### Exercise 12

What is the fundamental problem of causal inference?

```{r wisdom-12}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Lets go back to our example earlier using the `impv_food` variable. We can either give funds to schools to improve their food or we cannot give funds, we can't do both.



### Exercise 13

Write one sentence describing the data you have to answer your question.

```{r wisdom-13}
question_text(NULL,
	message = "We are using data from the IPEDS, which contains data from 950 US colleges and universities.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

IPEDS gathers information from every college that participates in the federal student financial aid programs. The Higher Education Act of 1965, requires that institutions that participate in federal student aid programs report data to organizations like IPEDS and such. This data is made public to us through their website.

### Exercise 14

Go to `File -> New File -> Quarto Document`. Give it the title `"Ordered Factors"` and make yourself the author. Delete everything below the YAML header and render the file (`Control/Command + Shift + K`), give it the name `analysis.qmd.` In the console, run `tutorial.helpers::show_file("analysis.qmd")`. CP/CR.

```{r wisdom-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

The college that charges the highest tuition is Columbia University in New York, requiring students to pay around $51,000 per year. It has a graduation rate of around 94%.

### Exercise 15

Edit the `.gitignore` to include `*_files`. Run `tutorial.helpers::show_file(".gitignore")` in the console. CP/CR.

```{r wisdom-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Another school with a high tuition rate is Vassar College in Poughkeepsie, New York. It charges around $49,000 per year and has a graduation rate of around 94% also.

### Exercise 16

Load the **tidyverse** package.

```{r wisdom-16, exercise = TRUE}

```

```{r wisdom-16-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-16-test, include = FALSE}
library(tidyverse)
```

### Exercise 17

Load the **primer.data** package.

```{r wisdom-17, exercise = TRUE}

```

```{r wisdom-17-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-17-test, include = FALSE}
library(primer.data)
```

### Exercise 18

In `analysis.qmd`, add `execute: echo: false` to the YAML header. Create a new code chunk (`Command/Control + Option/Alt + I`) and add `#| label: setup` and `#| message: FALSE`. Then, load the **tidyverse** and **primer.data** libraries. Render the file and run `tutorial.helpers::show_file("analysis.qmd", start = -4)`. CP/CR

```{r wisdom-18}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

`execute: echo: false` prevents any R code from showing up. `#| message: FALSE` prevents anything from being displayed. This is what we want, since we don't want anyone viewing the document to see that we are loading up the libraries.


### Exercise 19

Print out `colleges` below.

```{r wisdom-19, exercise = TRUE}

```

```{r wisdom-19-hint-1, eval = FALSE}
colleges
```

```{r wisdom-19-test, include = FALSE}
colleges
```

### 

What you may not know is that the `tuition` column is in terms of $10,000 per year. This will make it easier to interpret our regression coefficients when we make our model.

### Exercise 20

Use `select()` to select the `tuition`, `grad_rate` and `selectivity` columns.

```{r wisdom-20, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-20-hint-1, eval = FALSE}
... |>
  select(..., ..., ...)
```

```{r wisdom-20-test, include = FALSE}
colleges |>
  select(tuition, grad_rate, selectivity)
```

### 

Take a look at this plot

```{r}
#| echo: FALSE
colleges |>
  select(tuition, grad_rate) |>
  ggplot(aes(x = tuition, y = grad_rate)) +
  geom_point() +
  geom_smooth() 
```

We see a very interesting relationship. For colleges with less than around 20k per year in tuition, there doesn't seem to be much of relationship between `tuition` and `grad_rate`. However, after that it seems to increase linearly.


### Exercise 21

Continue the pipe to `ggplot()`, map `tuition` to the x-axis. Add the `geom_histogram()` layer. 

```{r wisdom-21, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-21-hint-1, eval = FALSE}
... |>
  ggplot(aes(...)) +
  ...()
```

```{r wisdom-21-test, include = FALSE}
colleges |>
  select(tuition, grad_rate, selectivity) |> 
  ggplot(aes(x = tuition)) + 
  geom_histogram()
```

### 

Recall the scatter plot earlier we showed earlier where there didn't seem like much of a relationship between graduation rate and tuition for schools that charge less than 20k per year. Looking at the histogram, we might find a reason as to why. There are **so** many schools that charge less than 20k per year.

### Exercise 22

Select the `tuition`, `grad_rate` and `selectivity` columns from `colleges`. Filter `tuition` to be greater than 2. Set this equal to a new object, `colleges_2`.

```{r wisdom-22, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-22-hint-1, eval = FALSE}
colleges_2 <- colleges |> 
                select(...) |>
                filter(...)
```

```{r wisdom-22-test, include = FALSE}
colleges_2 <- colleges |>
  select(tuition, grad_rate, selectivity) |>
  filter(tuition > 2)
```

### 

Take University of Michigan, UCLA and UC Berkeley for example. These are the three highest ranked public universities in all of America. Since they are publics, they charge a relatively low tuition rate compared to that of private institutes. But, they all have high graduation rates since they are considered "nice" schools.

### Exercise 23

Pipe `colleges_2` to `ggplot()` map `tuition` to the x-axis and `grad_rate` to the y-axis.

```{r wisdom-23, exercise = TRUE}

```

```{r wisdom-23-hint-1, eval = FALSE}
colleges_2 |> 
  ggplot(aes(...))
```

```{r wisdom-23-test, include = FALSE}
colleges_2 |> 
  ggplot(aes(x = tuition, y  = grad_rate))
```

Recall University of Michigan, UCLA and UC Berkeley all have have very high graduation rates. They also have something else in common (and no it's not that they are publics), they are all very selective schools. Could there be a relationship there?

### Exercise 24

Add the `facet_wrap()` layer with `~ selectivity` as the argument. Then, add `geom_point()`

```{r wisdom-24, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r wisdom-24-hint-1, eval = FALSE}
... + 
  facet_wrap(~ ...) + 
  ...()
```

```{r wisdom-24-test, include = FALSE}
colleges_2 |> 
  ggplot(aes(x = tuition, y  = grad_rate)) + 
  facet_wrap(~ selectivity) + 
  geom_point()
```

### 

This seems kind of cool. If we start with "Elite" schools and make our way down to "Non-selective" schools, we see a big difference in `grad_rate`. There are also differences in `tuition`. `selectivity` seems like a covariate worth measuring.

### Exercise 25

Create a new code chunk in `analysis.qmd`. Add `#| label: eda`. Copy/Paste your code for the `colleges_2` object. Render and run `tutorial.helpers::show_file("analysis.qmd", start = -5)`. CP/CR.

```{r wisdom-25}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We will use this cleaned up data in Courage when we make our model using `brm()`


### Exercise 26

In your own words, define "validity" as we use the term.

```{r wisdom-26}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 27

Provide one reason why the assumption of validity might not hold for the outcome variable: `grad_rate`. Use the words "column" or "columns" in yor answer.

```{r wisdom-27}
question_text(NULL,
	message = "An instance where validity would not hold would be if the column `grad_rate` from the data could be referring to the graduation rate after 6 years, but, the 'Graduation Rate' column in the Preceptor Table is interested in graduation rate after 4 years.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In order to consider the Preceptor Table and the data to be drawn from the same population, the columns from one must have a *valid correspondence* with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table, which is the first step in Justice.


### Exercise 28

Provide one reason why the assumption of validity might not hold for the covariate: `tuiton`.

```{r wisdom-28}
question_text(NULL,
	message = "An instance where validity would not hold would be if the `tuition` column is referring tuition + fees, but the 'Tuition' column in the Preceptor Table is interested in base tuition.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

When we Google tuition online, it will give us the standard tuition. But, there are other costs associated with going to a college, such as dorm fees, food, transportation and books. The `tuition` column does not specify which one of these it is.

<!-- DK: Update with new knowledge drop -->

### Exercise 29

<!-- Example: *Using data from a 2012 survey of Boston-area commuters, we seek to understand the relationship between income and political ideology in Chicago and similar cities in 2020. In particular, what percentage of individuals who make more than $100,000 per year are liberal?* -->


Summarize the state of your work so far in one sentence. Make reference to the data you have and to the specific question you are trying to answer. 


```{r wisdom-29}
question_text(NULL,
	message = "Using data from a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. In particular, what is the difference in average graduation rate between schools who are in the top 75th percentile of tuition rate and schools who are in the bottom 25th percentile.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit you answer as you see fit, but do not copy/paste our answer exactly. Add this summary to `analysis.qmd`, `Command/Ctrl + Shift + K`, and then commit/push.


## Justice
### 

*The arc of the moral universe is long, but it bends toward justice.* - Theodore Parker

### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.


### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "The average graduation rate could have changed from 2013.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Recall our data is from 2013. A lot can happen in 11 years, such as the COVID-19 pandemic and other big events that may have affected average graduation rate. 

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods.

### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "Smaller schools may have been excluded from our dataset.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

For the most part, our data set seems to represent the greater population accurately. IPEDS is a very reputable database and they get data from most (if not all) US colleges. But, there is the chance that there are probably very, very small schools who are not included in this data because they are deemed irrelevant.

<!-- DK: Update with new template knowledge drops -->

### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

```{r justice-7}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods.


### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true.

Since we have a predicative model, unconfoudedness is not relevant.

### Exercise 9

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention one specific problem which casts doubt on your approach. 


```{r justice-9}
question_text(NULL,
	message = "Using data from a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. In particular, what is the difference in average graduation rate between schools who are in the top 75th percentile of tuition and schools who are in the bottom 25th percentile. Graduation rates could've changed tremendously since 2013.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `analysis.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.


## Courage
### 

*Courage is being scared to death, but saddling up anyway.* - John Wayne


<!-- Questions about models, tests, and the DGM. -->


### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage begins with the exploration and testing of different models. It concludes with the creation of a Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We will begin courage with making our model, then, we will run a few commands on it to examine our data.

### Exercise 2

Load the **brms** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(brms)
```

### 

If we use `arrange()` to look at the school with the lowest `grad_rate`, we get Bacone College. According to our data, Bacone College has a graduation rate of just 3%! The college was shut down in 2018, it seems like this is an outlier, but, it has been filtered out of `colleges_2` already, so no need to worry.

<!-- XX: The Courage section of each chapter is the most complex because modeling is hard. Use opportunities for knowledge drops, like this one, judiciously. -->

<!-- DK: See template. Many changes! -->

### Exercise 3

Load the **tidybayes** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(tidybayes)
```

### 

**tidybayes** is an R package that aims to make it easy to integrate popular Bayesian modeling methods into a tidy data + ggplot workflow.

### Exercise 4

Add `library(brms)` and `library(tidybayes)` to `analysis.qmd`. `Command/Ctrl + Shift + K`. At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", pattern = "brms|tidybayes")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

By setting `pattern` equal to `"brms|tidybayes"`, we pull out the lines from `analysis.qmd` which contain either `brms` or `tidybayes`.

### Exercise 5

Create a model using `brm()` from the **brms** package. Your arguments should be `formula = grad_rate ~ tuition + selectivity`, `family = gaussian()`, `data = colleges_2`, `silent = 2`, `refresh = 0` and `seed = 9`. 


```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
brm(formula = ...,
    family = ...,
    data = ...,
    silent = ...,
    refresh = ...,
    seed = ...)
```

<!-- XX: Note how there is no test case. If there were one, then a student would fit the model each time she hit "Run Tutorial." That takes too much time. -->

This code should take a while to run. 

<!-- TJ: Help with knowledge here -->

### Exercise 6

Behind the scenes, we have assigned the result of the `brm()` call to an object named `fit_colleges`. Type `fit_colleges` and hit "Run Code." This generates the same results as using `print(fit_colleges)`.


```{r courage-6, exercise = TRUE}

```

```{r courage-6-hint-1, eval = FALSE}
fit_colleges
```

```{r courage-6-test, include = FALSE}
# fit_colleges
```

### 

We see a lot of numbers and messages being thrown at us at once, so lets look at this model piece by piece. First, we are going to go through the top 4 rows.

### Exercise 7

Run `family()` on `fit_colleges`. `family()` provides information about the "family" of the error term and the link between it and the dependent variable. 

```{r courage-7, exercise = TRUE}

```

```{r courage-7-hint-1, eval = FALSE}
family(...)
```

```{r courage-7-test, include = FALSE}
family(fit_colleges)
```

### 

A gaussian model means that the left-hand side variable `grad_rate` is continuous, meaning there are an infinite number of values for it. If we had a fixed number of potential values, we would use either the bernoulli or categorical families.

### Exercise 8

Run `formula()` on `fit_colleges`. `formula()` returns the statistical equation which relates the dependent variable to the independent variable(s). 

```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
formula(...)
```

```{r courage-8-test, include = FALSE}
formula(fit_colleges)
```

### 

Our left hand side variable `grad_rate` is the dependant variable, or what we are trying to measure. Our right hand side variables `tuition` and `selectivity` are the independant variables.

### Exercise 9

Run `nobs()` on `fit_colleges`. The `nobs()` function returns the **n**umber of **obs**ervations.

```{r courage-9, exercise = TRUE}

```

```{r courage-9-hint-1, eval = FALSE}
nobs(...)
```

```{r courage-9-test, include = FALSE}
nobs(fit_colleges)
```

### 

You may be asking, "Doesn't the `colleges` dataset have data from 950 colleges?" Well, yes! But, recall we filtered out `tuition` to be at least 20k plus per year, which removed 408 schools from our dataset.

### Exercise 10

Write the mathematical formula for your model, using $\LaTeX$ math notation.

```{r courage-10}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Add the formula to `analysis.qmd`. `Command/Ctrl + Shift + K`. Ensure that the formula is looks correct. 

### Exercise 11

Create a new code chunk in `analysis.qmd`. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model using `brm()` into the code chunk, assigning the result to `fit_colleges`. 

`Command/Ctrl + Shift + K`. It may take some time to render `analysis.qmd`, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render `analysis.qmd`, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r courage-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Be sure not to edit your `model` code chunk, as it will have to render everything again and take a long time.

### Exercise 12

Run `posterior_interval()` on `fit_colleges`. The `posterior_interval()` function returns 95% intervals for all the parameters in our model.

```{r courage-12, exercise = TRUE}

```

```{r courage-12-hint-1, eval = FALSE}
posterior_interval(...)
```

```{r courage-12-test, include = FALSE}
posterior_interval(fit_colleges)
```

### 

We do not know the true value for any of these coefficients are, but we are 95% confident that it lies somewhere between these intervals.


### Exercise 13

Run `fixef()` on `fit_colleges`. The `fixef()` returns information about the **fix**ed **ef**fects in the model.

```{r courage-13, exercise = TRUE}

```

```{r courage-13-hint-1, eval = FALSE}
fixef(...)
```

```{r courage-13-test, include = FALSE}
fixef(fit_colleges)
```

### 

`fixef()` gives us the important regression coefficients needed to interpret our model.

### Exercise 14

What does the `Intercept` represent?

```{r courage-14}
question_text(NULL,
	message = "The `Intercept` is the overall predicted graduation rate for all the colleges in our model.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The `Intercept` shows us that the predicted graduation rate for these colleges is around 36.2%. 

### Exercise 15

Write a sentence about the `tuition` coefficient.

```{r courage-15}
question_text(NULL,
	message = "For every $10,000 extra a college charges in tuition, the graduation rate increases by approximately 8.9% from the intercept value of 36.2%",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

`tuition` is continuous, each time it goes up by a value of 1 (which remember, corresponds to 10k in tuition), our graduation rate increases by the `Estimate`.

### Exercise 16

Write a sentence about the confidence interval for `tuition.`

```{r courage-16}
question_text(NULL,
	message = "We never know what the true value is for the `tuition` coefficient, but we are 95% certain that it lies between 0.073496297 and 0.10524795.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

This is especially helpful for stating any uncertainty with your value when writing your final paragraph.

### Exercise 17

Write a sentence explaining the `selectivity.L` coefficient.

```{r courage-17}
question_text(NULL,
	message = "`selectivity.L` shows the linear effect of moving from Non-selective to Elite",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- TJ: I have never used ordered factors, so I need help -->
<!-- TJ: Doing some research on ordered factors in brm(). will finish this later -->

<!-- XX: Add at least three questions which require the student to interpret the meanings of a parameter estimate and/or its associated confidence interval. This is something that students are very bad at! And so we need to give them practice, both by asking them to do it and by providing excellent answers. These questions also feature good opportunities to knowledge drop about the meaning of intervals (confidence verus uncertainty) and about Frequentist versus Bayesian interpretations. See -->

<!-- Let's me give a couple of questions/answers to serve as examples, all based on this display. This is good for linear (meaning the Gaussian family) models. For other models, see the comments below. -->

<!-- fit_obj <- brm(formula = att_end ~ sex + treatment + age, data = trains) -->

<!-- > round(fixef(fit_obj), 2) -->
<!--                  Estimate Est.Error  Q2.5 Q97.5 -->
<!-- Intercept           10.99      0.95  9.17 12.83 -->
<!-- sexMale             -0.83      0.54 -1.88  0.22 -->
<!-- treatmentControl    -1.42      0.54 -2.45 -0.32 -->
<!-- age                 -0.01      0.02 -0.06  0.03 -->

<!-- Q: Write a sentence interpreting the -0.34 estimate for sexMale. -->

<!-- A: When comparing men with women, men have a 0.83 lower value for att_end, meaning that they are more liberal about immigration, relative to women, conditional on the other variables in the model. -->

<!-- Comment_1: Note how, whenever we consider non-treatment variables, we must never use terms like "cause," "impact" and so on. We can't make any statement which implies the existence of more than one potential outcome based on changes in non-treatment variables. We can't make any claims about within row effects. Instead, we can only compare across rows. Always use the phrase "when comparing X and Y" or something very similar. -->

<!-- Comment_2: The phrase "conditional on the other variables in the model" is important. It could be shorted as "conditional on the model." This phrase acknowledges that there are many, many possible models, just considering all the different combintions of indepdendent variables we might include. Each one would produce a different coefficient for sexmale. None of these is the *true* cofficient. Any claim we make about  -0.83, or any specific number, is always conditional on the fact that we assume that this model is true, that these covariates, and no others, belong in the regression. Does that mean that we always use the phrase? No. We leave it out all the time. But it is always understood to be there but knowledge readers. Still, this is probably a point worth making in various knowledge drops. -->


<!-- Q: Write a sentence interpreting the confidence interval for sexMale. -->

<!-- A: We do not know the true value for the coefficient for sexMale, but we can by 95% confident that it lies somewhere between -1.88  and 0.22.  -->

<!-- Comment: Because we are Bayesians, we believe that there is a true value and that the confidence or uncertainty interval includes it at the stated level. These questions provide an occasion in the knowledge drop to compare/contrast the Frequenist interpretation. See: https://ppbds.github.io/primer/cardinal-virtues.html#confidencecredibleuncertainty-intervals -->

<!-- Q: Write a sentence interpreting the -1.42  estimate for treatmentControl. -->

<!-- A: The causal effect of receiving the treatment of hearing Spanish-speakers on the train platform, relative to the control, is to have a 1.42  higher value for att_end, meaning that the treatment, relative to the control, makes one more conservative about immigration. (Note that you need to keep track of signs and of which 0/1 variable is being used.) -->

<!-- Comment: The interpretation of a treatment variable is very different than the interpretation of a standard covariate. Whenever your model includes a treatment variable, you must always have a question about it and about the associated confidence interval. -->

<!-- Q: Write one sentence interpreting the -2.45 to -0.32 interval for the treatmentControl coefficient. -->

<!-- A: Our best estimate for the causal effect is -1.42, meaning that being treated makes someone 1.42 units more conservative about immigration. Yet, the true value could be lower or higher. We are 95% certain that the true effect is somewhere between -2.45 to -0.32.  -->

<!-- Comment: It is OK if our answers are slightly longer than what we might expect from students, as long as those answers are *tight*, meaning that no word is wasted. In this case, the first two sentences are an attempt to ensure that the student understands what is going on. The last sentence is what we might expect students to write.  -->

<!-- Q: Write a sentence interpreting the -0.1 estimate for age.  -->

<!-- A: If we compare one group of people ten years older than another, the older group will, on average, have an attitude toward immigration 1 unit lower, i.e., less conservative. -->

<!-- Comment: Numeric variables are harder than binary variables because there are no longer just two well-defined groups to compare with each other. We must make those two groups ourselves. Fortunately, as long as there are no interaction terms, we can just pick two groups with any values for the variable. The most common two groups differ by one unit of the variable. But it is quite common to use groups which differ by more/less if doing so seems sensible and/or if it makes the math easier. In this case, two groups which differ by 10 years makes sense for both reasons. -->

<!-- Further comment: With a linear model, all these interpretations are fairly straightforward. With any other type of model, the math is too difficult to do in your head. You can't just look at a coefficient of 5 and know what it means in magnitude. But you can tell the direction, that a positive 5 means that -->

### Exercise 18

Run `pp_check()` on `fit_colleges`. The `pp_check()` runs a **p**osterior **p**redictive check.

```{r courage-18, exercise = TRUE}

```

```{r courage-18-hint-1, eval = FALSE}
pp_check(...)
```

```{r courage-18-test, include = FALSE}
pp_check(fit_colleges)
```

### 

`pp_check()` checks to see if our "fake data" matches the data we generated. In our case, the fake data looks very similar. For the most part, we can conclude that, although not perfect, `pp_check()` shows that the fake outcomes generated by our model are like the actual outcome data.


### Exercise 19

Use `library()` to load the [**gtsummary**](https://www.danieldsjoberg.com/gtsummary) package.

```{r courage-19, exercise = TRUE}

```

```{r courage-19-hint-1, eval = FALSE}
library(gtsummary)
```

```{r courage-19-test, include = FALSE}
library(gtsummary)
```

### 

**gtsummary** creates presentation-ready tables summarizing data sets, regression models, and more.


Pipe `fit_colleges` to `tbl_regression()`.


```{r courage-20, exercise = TRUE}

```

```{r courage-19-hint-2, eval = FALSE}
fit_colleges |> 
  tbl_...()
```

```{r courage-19-test, include = FALSE}
fit_colleges |>
  tbl_regression()
```

### 

`tbl_regression()` takes a regression model object in R (`fit_colleges`) and returns a formatted table of regression model results that is publication-ready. It is a lot nicer than using `fixef()` or the output of the call to `brm()` to display the expected values.


### Exercise 20

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add one sentence which describes the modelling approach which you are using, specifying the functional form and the dependent variable. Add one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-20}
question_text(NULL,
	message = "Using data from a system of interrelated surveys on postsecondary eduation in 2013, we seek to understand the relationship between graduation rates tuition for colleges/universities in the United States. In particular, what is the difference in average graduation rate between schools who are in the top 75th percentile of tuition and schools who are in the bottom 25th percentile, all charging more than $20,000 a year. Tuition rates and graduation rates could've changed tremendously since 2013. We modeled graduation rate, a continuous variable, as a linear function of both tuition and selectivity. Graduation rates seem to rise as tuition increases.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Update your answer in `analysis.qmd` accordingly, but, don't blindly copy our answer.

### Exercise 21

Update `analysis.qmd`. First, add `library(gtsummary)` to the `setup` code chunk,. Second, add the mathematical formula, in $\LaTeX$ and surrounded by double dollar signs, for your model. Third, add a new code chunk which creates the table of model parameters. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r courage-21}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Now that we've added our regression tibble to the document, anyone viewing it can see a nice table with all of our regression values.

<!-- TJ: Bad knowledge drop on my end -->

## Temperance
### 

*Temperance is a tree which as for its root very little contentment, and for its fruit calm and peace.* - Buddha
*Temperance is the greatest of all virtues. It subdues every passion and emotion, and almost creates a Heaven upon Earth.* - Joseph Smith Jr.
*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton
*Temperance is the firm and moderate dominion of reason over passion and other unrighteous impulses of the mind.* - Marcus Tullius Cicero
*Temperance to be a virtue must be free, and not forced.* - Philip Massinger
*Temperance is simply a disposition of the mind which binds the passion.* - Thomas Aquinas


### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the Data Generating Mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 2

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-2}
question_text(NULL,
	message = "XX: Should be exactly how you started the Wisdom section.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.

### Exercise 3

To answer our question, we need to create a `newdata` object. Which variables (e.g., which columns) do we need to include in this object?

```{r temperance-3}
question_text(NULL,
	message = "We will need `tuition` and `selectivity`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Must be all the right hand side variables in fit_colleges. And note that the type must (maybe not always . . .) match, like if `treatment` is a factor in the original data used to create fit_colleges then it must (?) be a factor in ndata. -->


### Exercise 4

<!-- XX: Sometimes useful to think about this question and the number of posterior questions together, or event to reverse them. -->

Which values do you want the variables in your `newdata` object to have? This is not easy! At the very least, one of the rows should have values which allow you to answer your original question. But, now that you have a model, there are many questions which you might want to answer, the better to get a fuller understanding.

```{r temperance-4}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Chapter 10 is a great example of this in its full complexity. We want to know how "different" units behave, where the very definition of "different" is that they do not have identical values for all the variables used in fit_colleges. -->

<!-- For example, one row in ndata will generally represent the answer to the specific question we started with. But that is just the posterior for one sort of unit. There are lots of different units! Which others might we be interested in? We can generate posteriors for each of them, and then, in some cool graphic, display all those posteriors together. -->

<!-- Note that, previously, this document claimed that the number of rows in ndata corresponded to the number of posteriors you wanted to calculate. But that is not true! -->

### Exercise 5

Here is the R code which creates the `newdata` object: `tibble(whatever) code here`. Type it into the code exercise block and hit "Run Code."

<!-- Asking students to create this object --- even after you help them figure out the columns, rows and values --- is too hard, at least until they get more experiences. Your knowledge drop, for this question and the next, should give them advice on the broad topic of how they can create newdata objects themselves. -->

```{r temperance-5, exercise = TRUE}

```

```{r temperance-5-hint-1, eval = FALSE}

```

```{r temperance-5-test, include = FALSE}

```

### 

### Exercise 6

Behind the scenes, we have created the `ndata` object using this code. To confirm, type `ndata` and hit "Run Code."

<!-- Of course, you need to have added the code to create `ndata` in the setup chunk at the top of the file. -->

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}

```

```{r temperance-6-test, include = FALSE}

```

### 

Note that, when you add Temperance-related code to your QMD, you will need to also add code which creates the `ndata` object.

### Exercise 7

Now that we have the `newdata` object, we can create a pipe which uses out fitted model to answer our question. Begin by typing `fit_colleges` and clicking "Run Code."

```{r temperance-7, exercise = TRUE}

```

```{r temperance-7-hint-1, eval = FALSE}

```

```{r temperance-7-test, include = FALSE}

```

### 

<!-- XX: Again, the main point of knowledge drops is this area is to explain to students why the newdata object looks the way it does and what it will produce. A great way to teach is via example. That is, explaining that if we had another way with these values, then we would get this posterior. Or, explaining what would be produced if we used add_epred instead of add_predict, and vice verse. -->


### Exercise 8

Pipe `fit_colleges` to [XX: either `add_epred_draws()` or `add_predicted_draws()`] with the argument `newdata = ndata`. 



```{r temperance-8, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r temperance-8-hint-1, eval = FALSE}

```

```{r temperance-8-test, include = FALSE}

```

### 

<!-- XX: How do students know whether to use add_epred_draws or add_predicted_draws? This is non-trivial. On some level, we just tell them with the above command. (We don't make them guess.) But we also address this issue explicitly in various knowledg drops, especially this one. -->

<!-- XX: Insert as many questions as necessary to build a nice-looking example of your final plot. In early chapters, this is simple since our questions are simple. They are just one posterior. In later chapters, they become more complex, with the inclusion of several posteriors, as well as manipulation of them to calculate causal effects and whatnot. See the voting postcard example. -->

### Exercise 9

Create a new code chunk in `analysis.qmd`. Label it with `label: plot`. Copy/paste the code which creates your graphic. Don't forget that, at the top of this chunk, you must include code which creates the `ndata` object.

`Command/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd", start = -8)
```

CP/CR.

```{r temperance-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 10

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) --- presumably one that answers your question -- and which provides a measure of uncertainty about that QoI.

<!-- XX: Most of the time, there will be some measure of uncertainty associated with your QoI. But not always! The most common counter-example involves a question which asks about the odds or probability of something happening. We would answer such a question by simulating the event with `add_predicted_draws()`. We would then calculate the odds/probability of something happening by seeing how many of the 4,000 draws met the criteria for the event. Assume that was 40%. So, we think that there is a 40% chance that event A will happen. Yet there is no uncertainty associated with that estimate because it, itself, is an expression of uncertainty.  -->

```{r temperance-10}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `analysis.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.


<!-- XX: Again, spend time to make your recommended paragraph perfect. Study the examples in https://ppbds.github.io/primer/cardinal-virtues.html closely. -->

### Exercise 11

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-11}
question_text(NULL,
	message = "XX: This is another example in which the quality of your answer is important. You might or might not suggest an alternate estimate. I always adjust the estimate toward my own subjective sense of a longrun average and/or typical value and/or zero. But that is not necessary. However, you should always increase the confidence interval since the assumptions of your model are always false.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 12

Rearrange the material in `analysis.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("analysis.qmd")
```

CP/CR.

```{r temperance-12}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.

### Exercise 13

Publish `analysis.qmd` to Rpubs. Choose a sensible slug. Copy/paste the url below.

```{r temperance-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

## Summary
### 

This tutorial covered [Chapter XX: XX](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
