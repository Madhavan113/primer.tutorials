---
title: Stops
author: Sanaka Dash and David Kane
tutorial:
  id: stops
output:
  learnr::tutorial:
    progressive: yes
    'allow_skip:': yes
runtime: shiny_prerendered
description: 'Tutorial: Stops'
---

```{r setup, include = FALSE}
# Required for the tutorial to work:

library(learnr)
library(tutorial.helpers)
library(gt)

# Any package from here is something that we want students to explicitly load up in the tutorial:

library(tidyverse)
library(tidymodels)
library(broom)
library(marginaleffects)
library(primer.data)

# Required for the tutorial to work:

knitr::opts_chunk$set(echo = FALSE)
options(tutorial.exercise.timelimit = 600, 
        tutorial.storage = "local") 

# Creates new df with 4 entries for race

stops_new <- stops |>
  filter(!race %in% c("other", "unknown"), zone %in% c("A", "X"))

# Store the `ndata` object for Temperance

ndata <- expand_grid(race = unique(stops_new$race),
                     sex = unique(stops_new$sex),
                     age = mean(stops_new$age),
                     zone = unique(stops_new$zone))

```

```{r copy-code-chunk, child = system.file("child_documents/copy_button.Rmd", package = "tutorial.helpers")}
```

```{r info-section, child = system.file("child_documents/info_section.Rmd", package = "tutorial.helpers")}
```

<!-- Should we add the Temperance start and finish quotes from the Primer chapters? What about other classical quotes, like "You can never look at the data too much."?   -->

<!-- Every EDA should show a scatter plot of the outcome variable on the y-axis and one of (probably the most important or the treatment) covariates on the x-axis. -->

<!-- Consider adding the model creation and saving code to a separate model.R script. Then, in analysis.R, you could just read it in. Would also be useful, in at least some tutorials, to highlight using a small sample of the data in initial fitting. -->

<!-- Whenever you tell a student to make a change in the QMD, you should tell them to `Command/Ctrl + Shift + K` in order to render the document. Then, the last step in these exercises is often some version of show_file() and then CP/CR. -->

<!-- Make use of, e.g., `show_file("tutorial-6.qmd", start = -5)` to get just the last 5 lines of the QMD. -->

<!-- DK: Add the new math approach which is available in the template tutorial. -->


## Introduction
### 

This tutorial is best understood when done after reading [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). It covers the `stops` dataset from the [primer.data](https://github.com/PPBDS/primer.data/) package.


## The Question
### 

*The power to question is the basis of all human progress.* - Indira Gandhi

<!-- FIX - add these in later: -->
<!-- Both a causal effect and a prediction are much fuzzier notions than you might think because there are so many, depending on AGGREGATION. -->

<!-- If you don't care what Joe would have done in a counter-factual world in which we got a different treatment, if all you care about is predicting what Joe does *given the treatment he received*, then you just need a predictive model. -->

### Exercise 1

Load **tidyverse**.

```{r the-question-1, exercise = TRUE}

```

```{r the-question-1-hint-1, eval = FALSE}
library(tidyverse)
```

```{r the-question-1-test, include = FALSE}
library(tidyverse)
```

### 

The data that we will use was sourced from the [Open Policing project](https://openpolicing.stanford.edu/findings/). Based at Stanford University, the project aims to improve police accountability and transparency by providing data on traffic stops across the United States. They have many downloadable datasets, and our data is specifically derived from their [New Orleans dataset.](https://openpolicing.stanford.edu/data/)


### Exercise 2

Load the **primer.data** package.

```{r the-question-2, exercise = TRUE}

```

```{r the-question-2-hint-1, eval = FALSE}
library(primer.data)
```

```{r the-question-2-test, include = FALSE}
library(primer.data)
```

### 

A version of the data from the Open Policing project is available in the `stops` tibble.


### Exercise 3

After loading **primer.data** in your Console, type `?stops` in the Console, and paste in the Description below.

```{r the-question-3}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

`stops` contains data from over 400,000 traffic stops in New Orleans from July 1, 2011 to July 18, 2018. The dataset includes information about the date, time, and location of each stop, as well as demographic details about the driver and the outcomes of the stop.


### Exercise 4

Arrests in traffic stops are the broad topic of this tutorial. Given that topic, which variable in `stops` should we use as our outcome variable? 

```{r the-question-4}
question_text(NULL,
	message = "We should be using the `arrested` variable.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

`arrested` is a binary variable indicating whether or not an arrest was made during the traffic stop. 


### Exercise 5

Let's imagine a brand new treatment variable which **does not exists** in the data. This variable should be binary, meaning that it only takes 2 values (TRUE/FALSE, etc.). It should also, at least in theory, be manipulable. In other words, if the value of the variable is "X," or whatever, then it generates one potential outcome and if it is "Y," or whatever, it generates another potential outcome.

How might we manipulate this variable?

```{r the-question-5}
question_text(NULL,
	message = "Imagine a variable called `mask`, indicating whether or not the person is wearing a mask. We can manipulate this, at least in theory, by giving out masks to half the motorists that we plan on studying, and seeing if the mask affects their chances of getting arrested.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

There can be many good answers for a question like this. However, for the rest of this section, you should stick with our treatment variable of `mask`.

Recall that in a treatment variable, when manipulated, we look for the difference in arrest rate to see whether or not wearing a mask results in a higher chance of getting arrested.

All of this stuff is a *conceptual* framework we apply to the data. It is never inherent in the data itself.

The same data set can be used to create, separately, lots and lots of different models, both causal and predictive. We can just use different outcome variables and/or specify different treatment variables.


### Exercise 6

Essentially, we are asking:

<!-- SD: I am getting vibes that the following is a bad question. How would I make a good question for this theoretical scenario? -->

> By how much does wearing a mask in New Orleans affect the likelihood of getting arrested at a traffic stop?

Given this choice of treatment variable `mask`, how many potential outcomes are there for each arrest? Explain why.

```{r the-question-6}
question_text(NULL,
	message = "There are 2 potential outcomes because the treatment variable `mask` takes on 2 posible values: either wearing a mask or not wearing one.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The same data set can be used to create both causal and predictive models. We can just use different outcome variables and/or specify different treatment variables for the different models, although sometimes, even this isn't required and the same variables work for both types of models.

For a Causal model, any data set can be used as long as there is at least one covariate that we can, at least in theory, manipulate. It does not matter whether or not anyone did, in fact, manipulate it. 

<!-- XX: I am not satisfied with the wording of this next question. Our end goal is the calculation, by the student, of a causal effect, as in Exercise 8. 

The previous step was to just determine the number of potential outcomes, as in Exercise 6. 

This question wants to get students to see that each different treatment is associated with a potential outcome. Is there a better approach? -->

<!-- SD: Changed the wording of the next quetion to make it easier to understand, hopefully this makes it a lot better. -->

### Exercise 7

Write a sentence which speculates how our 2 potential outcomes would change if we manipulated our treatment variable of `mask`. 

<!-- SD: Maybe I should make it shorter and remove the reasoning for why I think masked citizens are less likely to be arrested - wdy think Preceptor? -->

```{r the-question-7}
question_text(NULL,
	message = "We expect that the likelihood of getting arrested would decrease When `mask` is true, as the cops may feel safer near the peopel wearing masks. Likewise, when `mask` is false, we expect that the likelihood of getting arrested would be higher.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

You may have guessed something different for the potential outcomes and that is completely fine. Again, this is **your** assumption. However, for the remainder of this section, assume my answer to be true.

### 

The causal effect is the difference between potential outcomes. So, there must be two (or more) potential outcomes for any causal model to make sense.

In our case, this is simple as we have 2 binary outcomes for our variable. But, if the treatment variable is continuous, (like income) then there are lots and lots of potential outcomes, one for each possible value of the treatment variable.


### Exercise 8

Write a few sentences which specify the following:
- two different values for the treatment variable for every arrest
- guesses at the potential outcomes which would result
- calculate the causal effect for every arrest given those guesses

<!-- XX: Replace [XX: unit] with a better word below given the actual data set we are using. Replace all the XX terms as appropriate. -->

```{r the-question-8}
question_text(NULL,
	message = "For a given arrest, assume that the value of the treatment variable might be `is wearing a mask` or `isn't wearing a mask`. If the person `is wearing a mask`, then the likelihood of getting arrested would be 2%. If the person `isn't wearing a mask`, then the likelihood of getting arrested would be 15%. The causal effect on the outcome of a treatment of `mask = TRUE` versus `mask = FALSE` is 2 - 15 --- i.e., the difference between two potential outcomes --- which equals -13, which is the causal effect.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Notice how our Causal Effect is negative. This is because it depends on which potential outcome comes first in our question and which second.

Here is our Causal Effect statement below:

> The likelihood of getting arrested during a traffic stop in New Orleans is reduced by 13% if the person is wearing a mask.


### Exercise 9

Let's consider a *predictive* model. Which variable in `stops` do you think might have an important connection to `arrested`? (If you don't see a reasonable variable in the data, you can just name a variable which *might have been* included in the data.)

<!-- XX: Key question: Should we use the same variable in causal as in predictive? I am not sure which approach is best. You decide! -->

```{r the-question-9}
question_text(NULL,
	message = "Let's consider the variable `mask` again. Note that now, instead of being a treatment, it's our key covariate, whose connection to the outcome variable we most want to explore.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 2)
```

### 

Using the same variable allows us to see the true differences between the two model types, based on similar questions and the same variables. Of course, you may have said something else, and that is completely fine, but we should stick with `mask` for the rest of this section.


### Exercise 10

Write a few sentences which specify two different groups of traffic stops with different values for `mask`. Explain how the average value of `arrested` might differ between these two groups of traffic stops.

```{r the-question-10}
question_text(NULL,
	message = "XX: Some traffic stops might have a value for `mask` of `TRUE`. Others might have a value of `FALSE`. Those two groups will, on average, have different values for `arrested`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The key point is that, with a predictive model, there is only one outcome for each individual unit. There are not two potential outcomes because we are not considering any of the covariates to be treatment variables. We assuming that all covariates are "fixed." In that case, we should not use words like "cause," "influence," "impact," or anything else which suggests causation. The best phrasing is in terms of "differences" between groups of units with different values for the covariate of interest.


### Exercise 11

<!-- XX: This is a draft. Maybe rework? -->

Write a predictive question which connects the outcome variable `arrested` to a covariate of interest. 


<!-- FIX - This is the same question at the beginning of Wisdom, so if that gets changed then this gets changed too -->

```{r the-question-11}
question_text(NULL,
	message = "What is the difference in arrest rate between Black and White drivers adjusting for other variables?",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- FIX - cchange now that the question has changed -->

This is going to be our question for today! Notice how we specified age, sex and race, all in the same question! Our goal today will be to get you situated with using multiple variables to predict an outcome.

Note: we definitely didn't expecr you to write our exact question! Your answer was probably good!


### Exercise 12

What is a Quantity of Interest which might help us to explore the answer to our question?

<!-- XX: In general, our initial question does not include any specific numbers. It just uses words. For precision, we need to specify a Quantity of Interest that we are interested in. This is harder than it might look! It also helps to set the stage of Temperance. In all cases, the quantity of interest involves the outcome variable. (How could it not?) It also involves specific values of the covariates.  -->

<!-- XX: For predictive models, the specific question is generally of two types. First, what is the *expected* value of the outcome for various values of the independent variables? Second, what is the comparison in the expected outcome between two different groups? We are *not* simply interested in predicting the outcome variable for one unit. (In fact, of course, we might ultimately be interested in just one unit, but we need to *pretend* to be interested in lots of units in order to motivate the creation of a model.) -->

<!-- XX: For causal models, we are almost always interested in the average causal effect of treatment versus control. We are *not* simply interested in the causal effect for one specific unit. (In fact, of course, we might ultimately be interested in just one unit, but we need to *pretend* to be interested in lots of units in order to motivate the creation of a model.) -->

<!-- FIX - Need help fixing the question and the Quantity of Interest -->

```{r the-question-12}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Our Quantity of Interest might appear too specific, too narrow to capture the full complexity of the topic. There are many, many numbers which we are interested in, many numbers that we want to know. But we don't need to list them all here! We just need to choose one of them since our goal is just to have a specific number which helps to guide us in the creation of the Preceptor Table and, then, the model.


## Wisdom
### 

*The only true wisdom is in knowing you know nothing.* - Socrates

Recall our question:

> What is the difference in arrest rate between Black and White drivers adjusting for other variables?


### Exercise 1

In your own words, describe the key components of Wisdom when working on a data science problem.

```{r wisdom-1}
question_text(NULL,
	message = "Wisdom requires the creation of a Preceptor Table, an examination of our data, and a determination, using the concept of validity, as to whether or not we can (reasonably!) assume that the two come from the same population.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Open Policing project also has [visual maps](https://openpolicing.stanford.edu/explore/) regarding traffic stops. Sadly, there isn't one for New Orleans, but observe how different parts of Hartford, CT pull over different races of people!

<!-- XX: Not only are you discussing the data, but you are also discussing potential problems with the data, problems which will be more fully fleshed out in the Justice section. You want to pick 5 to 10 interesting facts about the data.

It is always a good idea to knowledge drop a link to the actual data and to any articles/books/websites related to it. -->


### Exercise 2

Define a Preceptor Table.

```{r wisdom-2}
question_text(NULL,
	message = "A Preceptor Table is the smallest possible table of data with rows and columns such that, if there is no missing data, we can easily calculate the quantities of interest.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table does not include all the covariates which you will eventually including in your model. It only includes covariates which you need to answer your question.


### Exercise 3

Describe the key components of Preceptor Tables in general, without worrying about this specific problem. Use words like "units," "outcomes," and "covariates."

```{r wisdom-3}
question_text(NULL,
	message = "The rows of the Preceptor Table are the units. The outcome is at least one of the columns. If the problem is causal, there will be at least two (potential) outcome columns. The other columns are covariates. If the problem is causal, at least one of the covariates will be a treatment.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 4

Create a Github repo called `stops`. Make sure to click the "Add a README file" check box.

Connect the `stops` Github repo to an R project on your computer. Name the R project `stops` also.

Select `File -> New File -> Quarto Document ...`. Provide a title (`"Stops"`) and an author (you). Render the document and save it as `stops.qmd`.

Edit the `.gitignore` by adding `*Rproj`. Save and commit this in the Git tab. Push the commit.

In the Console, run:

```         
show_file(".gitignore")
```

CP/CR.

```{r wisdom-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Remove everything below the YAML header from `stops.qmd` and render the file. `Command/Ctrl + Shift + K` renders the file, this automatically saves the file as well.


### Exercise 5

What are the units for this problem?

```{r wisdom-5}
question_text(NULL,
	message = "The units are the races of the people that have been pulled over.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

If our question were to have concerned the percentage of people that got arrested from traffic stops, then our units would have been the individual people. However, since it concerns the broad groups of people, it only makes sense for our units to be thos ebroad groups (the races).


### Exercise 6

What is/are the outcome/outcomes for this problem?

<!-- SD: Would it be valid to state all of th outcomes here, or should I just talk about the outcome variable? -->
```{r wisdom-6}
question_text(NULL,
	message = "There are two potential outcomes for this problem: either getting arrested or not getting arrested.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The variable `race` has multiple values, and with each value comes the the condition of the `arrested` variable. So, XX variables for `race` * 2 values for `arrested` (TRUE or FALSE) = XX total outcomes.

<!-- XX: A good knowledge drop for this exercise might involve other outcomes which might be useful for related questions. For example, if the outcome for a presidential election are votes cast than, with a slightly different question, the outcomes might be the electoral votes. We want to show them the interplay between the exact question and which outcomes define the Preceptor Table. -->

<!-- Specifying the Preceptor Table forces us to think clearly about the units and outcomes implied by the question. The resulting discussion sometimes leads us to modify the question we started with. No data science project follows a single direction. We always backtrack. There is always dialogue. -->


### Exercise 7

What are some covariates which you think might be useful for this problem, regardless of whether or not they might be included in the data?

```{r wisdom-7}
question_text(NULL,
	message = "We obviously need `race`. However, other characteristics like the person's age, sex, and the type of car they're driving might also affect `race`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

For your information, the term "covariates" is used in at least three ways in data science. First, it is all the variables which might be useful, regardless of whether or not we have the data. Second, it is all the variables which we have data for. Third, it is the set of covariates which we end up using in the model.


### Exercise 8

What are the treatments, if any, for this problem?

```{r wisdom-8}
question_text(NULL,
	message = "Our key covariates would be `race`, `sex`, and `age`.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Note that because we're creating a Predictive model, there is no treatment variable per se. However, we still have key covariates.

<!-- XX: Again, we dialogue. Any question, or broad topic, will use words. And words are not precise! Lots of possible treatments, each different from the other, are close to the original words. Drop some knowledge, or even speculation, about what sorts of treatments might be relevant in similar problems.  -->


### Exercise 9

What moment in time does the Preceptor Table refer to?

<!-- SD: How should I go about handling this situation? Do I make a random Preceptor Table or do I use something else, or do I just not make one at all? -->
```{r wisdom-9}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- FIX - XX: Add question: Explain why you want to use a predictive model or a causal model. Answer is almost always, you care about what happens to the same unit under two different treatments or you don't care. Often uses words like "causal," or "effect" or "affect" or "influence" or "impact" or . . . Actually, this should now be handled in The Question section. -->


### Exercise 10

Define causal effect.

```{r wisdom-10}
question_text(NULL,
	message = "A causal effect is the difference between two potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

In a Causal model, our causal effect would measure the different in probability of getting arrested between the different races. WE AREN'T DOING THIS!!!

<!-- SD: FIX - This is wrong, maybe some help from Preceptor: -->

This isn't to be confused with a predictive model, where we would be just predicting the probability of getting arrested for, say, the average white person (or to any specific given scenario).


### Exercise 11

What is the fundamental problem of causal inference?

```{r wisdom-11}
question_text(NULL,
	message = "The fundamental problem of causal inference is that we can only observe one potential outcome.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- FIX - XX: More discussion about potential outcomes. Counter-factuals are hard to think about. Help students by providing discussion of the ones under consideration here, or which might be under consideration with a different question. Are they plausible? What would make them more plausible? -->

### Exercise 12

How does the motto "No causal inference without manipulation." apply in this problem?

```{r wisdom-12}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- FIX -  -->
<!-- XX: With tutorial which uses a predictive model, it is fair for your answer to this question to be. "The motto does not apply because this is a predictive, not causal, model." -->

<!-- XX: For a causal model, can you really manipulate the treatments? In reality or in theory? How? What details would need to change to make this more or less plausible? -->

### Exercise 13

Describe in words the Preceptor Table for this problem.

```{r wisdom-13}
question_text(NULL,
	message = "XX. Make sure your words given an excellent description of the Preceptor Table which you are about to show the student.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Preceptor Table for this problem looks something like this:

<!-- FIX - -->
<!-- XX. Show the Preceptor Table. You can just copy/paste the code from the Primer, or use that code as a guide for creating your own ...-->

<!-- XX: Note that, like all aspects of a data science problem, the Preceptor Table evolves as we work on the problem. For example, at the start, we aren't sure what right-hand side variables will be included in the model, so we are not yet sure which columns must be in the Preceptor Table. -->


### Exercise 14

Write one sentence describing the data you have to answer your question.

```{r wisdom-14}
question_text(NULL,
	message = "FIX - XX. Make sure that your example sentence is a good one. Obviously, the date that the data was gathered is important, as well as the person/organization doing the gathering. The number of observations might also be useful, along with an indication as to the sort of variables included. But no need to include all of that! Use your best judgement. ",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 15

In `stops.qmd`, load the **tidyverse** and the **primer.data** packages in a new code chunk. Label it the set up by adding `#| label: setup`. Render the file.

Notice that the file does not look good because it is has code that is showing and it also has messages. To take care of this, add `#| message: false` to remove all the messages in the setup chunk. Also add the following to the YAML header to remove all echo from the whole file:

```         
execute: 
  echo: false
```

In the Console, run:

```         
show_file("stops.qmd", start = -5)
```

CP/CR.

```{r wisdom-15}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Render again. Everything looks nice because we have added code to make the file look better and more professional.


### Exercise 16

Load the **tidyverse** package.

```{r wisdom-16, exercise = TRUE}

```

```{r wisdom-16-hint-1, eval = FALSE}
library(...)
```

```{r wisdom-16-test, include = FALSE}
library(tidyverse)
```

### 

<!-- FIX -  -->
<!-- XX: Insert comments about the data. This continues to be the primary type of knowledge drop. These comments can also be sophisticated, especially in the way that they connect the data to the Preceptor Table and to the population. -->

<!-- XX: Load any other packages that are needed, one package per question. (But make sure that they are also included in the setup chunk.) primer.data, for example, is often needed. But save brms and tidybayes for the Courage section. -->

<!-- XX: It is now time for the third set of QMD edits. Add a new code chunk, the setup chunk, to the QMD. Copy/paste all the library commands to it. Render. Note all the ugliness. Add #| message: false. Add execute: echo: false to the YAML header. Add #| label: setup. Render again. Everything looks nice. Again, these could be several questions in the earlier tutorials or just one long question later. Ends with show_file("analysis.qmd", start = -5). This will be the most common ending question in QMD-editing exercises to come. -->

<!-- XX: Add code questions about EDA with your data. In particular, add at least one question about the dependent variable in the model along with one or more questions about covariates. If there is a treatment variable, you must include a question about it. -->

<!-- Variable questions come in two types. First there are questions which require the student to run, say, summary() on the variable. Then, knowledge about the variable can be dropped. Second, there are questions which ask for a one sentence summary about the variable, something which could be used in our summary of the project. For example: "Civility is measured on a 1 through 7 scale with higher values corresponding to greater civility." -->

<!-- XX: If necessary, provide code exercises which, line-by-line, create the pipeline which creates the cleaned data that will be used in modeling. For many tutorials, this is unnecessary since we can just use the raw tibble that is available in whatever package. But we sometimes need some code like

nes |> 
  filter(year == 1992) |> 
  drop_na()

We have three code exercises, each adding one line to the pipeline, explaining what we are doing and why. It is nice that, for each exercise, something is spat out.
-->

<!-- XX: If such a pipeline was built, there is one QMD question which requires that you add a new code chunk to the QMD, copy/paste the pipeline and assign the result to some object like `model_data` or whatever:

nes_92 <- nes |> 
  filter(year == 1992) |> 
  drop_na()

`Command/ctrl + Shift + K` follows, perhaps with a show_file("analysis.qmd", start = -5)
-->


### Exercise 17

Let's get to know our data.

Start by exploring our dataset, by typing `stops` into the Console. Ensure that the **Tidyverse** package is loaded in the Console, as without it, the full dataset would be displayed.

```{r wisdom-17, exercise = TRUE}

```

```{r wisdom-17-hint-1, eval = FALSE}
stops
```

```{r wisdom-17-test, include = FALSE}
stops
```

### 

In this first glimpse, I only see two races present. I wonder if this dataset contains more...


### Exercise 18

To find out if we have more than 2 races, run the following command in the box below.

```{r wisdom-18, exercise = TRUE}
table(stops$race)
```

```{r wisdom-18-test, include = FALSE}
table(stops$race)
```

### 

By using `$` to specify a specific variable, `table()` shows the different unique entries in the column, displaying the number of times that it has been mentioned.


### Exercise 19

For our model, we want to remove the entries for `other` and `unknown` (due to their low number of observations, and the fact that they don't provide any useful data) while still retaining everything else in the dataset.

We can do this in 2 ways: we can either remove those entries, or we can select the entries to retain. For this tutorial, we will be doing the former.

To do this, start by piping `stops` to `filter()`. Then, inside `filter()`, use the argument `!race %in% c("other", "unknown")`.

```{r wisdom-19, exercise = TRUE}

```

```{r wisdom-19-hint-1, eval = FALSE}
... |>
filter(!race %...% c("other", "..."))
```

```{r wisdom-19-test, include = FALSE}
stops |>
filter(!race %in% c("other", "unknown"))
```

### 

To instead select races, we could have removed the `!` in the argument and used the variables that we wanted to keep.


### Exercise 20

We should also consider `zone` as a key variable. Would the values for different races change in different zones?

Let's first observe the `zone` variable. Use `table()` on `stops$zone`.

```{r wisdom-20, exercise = TRUE}

```

```{r wisdom-20-hint-1, eval = FALSE}
table(...$zone)
```

```{r wisdom-20-test, include = FALSE}
table(stops$zone)
```

### 

Notice how some zones have a higher number of observations than other zones. I wonder if this would affect the confidence intervals.


### Exercise 21

Let's use the zones "A" and "X" (at random).

The box below contains your code from Exercise 19. Inside `filter()`, add the argument `zone %in% c("A", "X")`.

```{r wisdom-21, exercise = TRUE}
stops |>
filter(!race %in% c("other", "unknown"))
```

```{r wisdom-21-hint-1, eval = FALSE}
stops |>
filter(!race %in% c("other", "unknown"), zone %in% c("...", "X"))
```

```{r wisdom-21-test, include = FALSE}
stops |>
filter(!race %in% c("other", "unknown"), zone %in% c("A", "X"))
```

### Exercise 22

We have saved this pipeline to the following object:

```
stops_new <- stops |>
  filter(!race %in% c("other", "unknown"), zone %in% c("A", "X"))
```

Create a new code chunk in `stops.qmd`. Add `#| label: eda`. Copy/Paste the code for the `stops_new` object. Render and run `tutorial.helpers::show_file("stops.qmd", chunk = "last")`. CP/CR.

```{r wisdom-22}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

We will use this cleaned up data in Courage when we make our model.


### Exercise 23

In your own words, define "validity" as we use the term.

```{r wisdom-23}
question_text(NULL,
	message = "Validity is the consistency, or lack thereof, in the columns of the data set and the corresponding columns in the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Validity is always about the *columns* in the Preceptor Table and the data. Just because columns from these two different tables have the same *name* does not mean that they are the same *thing*.

### Exercise 24

<!-- FIX - XX: For the validity questions, specifics matter. There is always a reason why the outcome column in the data is not the same as the outcome columns in the Preceptor Table, even in the case of simple sampling. For example, consider a historical question connecting sex with presidential vote. Our data is a subset of our Preceptor Table. We have information on a few thousand voters and want to draw inferences about millions of voters. But, even in this case, the outcome columns are different. The data is who people told a survey they voted for. The Preceptor Table is who people actually did vote for. Those are not the same things. If they, in your view, are different enough than validity is violated. -->

Provide one reason why the assumption of validity might not hold for the outcome variable `arrested`.

```{r wisdom-24}
question_text(NULL,
	message = "FIX - XX: Answers to validity question should always use the word 'column(s)'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Note that these questions are all about detecting issues early on so that they don't become a problem (however minor they may be) later. -->


### Exercise 25

<!-- FIX - XX: Pick the most important covariate or at least one that you know/suspect will be used in the model. This is similar to the previous question, but we want to ensure that students understand that validity is about comparing the columns in the data set with the columns in the Preceptor Table. -->

Provide one reason why the assumption of validity might not hold for the covariate: `XX`.

```{r wisdom-25}
question_text(NULL,
	message = "XX: Don't forget the word 'column'.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 26

<!-- FIX - Example: *Using data from a 2012 survey of Boston-area commuters, we seek to understand the relationship between income and political ideology in Chicago and similar cities in 2020. In particular, what percentage of individuals who make more than $100,000 per year are liberal?* -->

<!-- It is very difficult to craft a question which causes students to give a sentence that is good. Do your best. -->

Summarize the state of your work so far in one sentence. Make reference to the data you have and to the specific question you are trying to answer. 


```{r wisdom-26}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit you answer as you see fit, but do not copy/paste our answer exactly. Add this summary to `stops.qmd`, `Command/Ctrl + Shift + K`, and then commit/push.


## Justice
### 

*Justice delayed is justice denied.* - William E. Gladstone


### Exercise 1

In your own words, name the four key components of Justice for working on a data science problem.

```{r justice-1}
question_text(NULL,
	message = "Justice concerns four topics: the Population Table, stability, representativeness, and unconfoundedness.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Justice is about concerns that you (or your critics) might have, reasons why the model you create might not work as well as you hope. 

### Exercise 2

In your own words, define a Population Table.

```{r justice-2}
question_text(NULL,
	message = "The Population Table includes a row for each unit/time combination in the underlying population from which both the Preceptor Table and the data are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

The Population Table is almost always much bigger than the combination of the Preceptor Table and the data because, if we can really assume that both the Preceptor Table and the data are part of the same population, than that population must cover a broad universe of time and units since the Preceptor Table and the data are, themselves, often far apart from each other.

### Exercise 3

In your own words, define the assumption of "stability" when employed in the context of data science.

```{r justice-3}
question_text(NULL,
	message = "Stability means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability is all about *time*. Is the relationship among the columns in the Population Table stable over time? In particular, is the relationship --- which is another way of saying "mathematical formula" --- at the time the data was gathered the same as the relationship at the (generally later) time references by the Preceptor Table.


### Exercise 4

Provide one reason why the assumption of stability might not be true in this case.

```{r justice-4}
question_text(NULL,
	message = "FIX - XX. Again, students read these 'official' answers as closely as anything else you will write. Make your example precise and excellent.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 5

We use our data to make inferences about the overall population. We use information about the population to make inferences about the Preceptor Table: `Data -> Population -> Preceptor Table`. In your own words, define the assumption of "representativeness" when employed in the context of data science.

```{r justice-5}
question_text(NULL,
	message = "Representativeness, or the lack thereof, concerns two relationships among the rows in the Population Table. The first is between the data and the other rows. The second is between the other rows and the Preceptor Table.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Stability looks across time periods. Representativeness looks within time periods.


### Exercise 6

We do not use the data, directly, to estimate missing values in the Preceptor Table. Instead, we use the data to learn about the overall population. Provide one reason, involving the relationship between the data and the population, for why the assumption of representativeness might not be true in this case.

```{r justice-6}
question_text(NULL,
	message = "FIX - XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Remember that our data and our Preceptor Table are two completely different datasets, and are only able to merge once we have identified that they both concern the same population.

It's always a concern regarding the methods that the data was collected. If they were collected from different bodies or populations that didn't meet eye-to-eye in key aspects, the data may be conflicting.


### Exercise 7

We use information about the population to make inferences about the Preceptor Table. Provide one reason, involving the relationship between the population and the Preceptor Table, for why the assumption of representativeness might not be true in this case.

<!-- SD: Isn't this the same as the last question? Wouldn't the first part oft this question be better as a knowledge drop to the last? -->
```{r justice-7}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### Exercise 8

In your own words, define the assumption of "unconfoundedness" when employed in the context of data science.

```{r justice-8}
question_text(NULL,
	message = "Unconfoundedness means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- FIX - XX: Keep one. -->

<!-- This assumption is only relevant for causal models. We describe a model as "confounded" if this is not true.  -->

<!-- The easiest way to ensure unconfoundedness is to assign treatment randomly. -->

### Exercise 9

<!-- FIX - XX: Delete this question for non-causal models. -->

Provide one reason why the assumption of unconfoundedness might not be true (or relevant) in this case.

```{r justice-9}
question_text(NULL,
	message = "FIX - XX. There is nothing harder for students than coming up with examples of possible confounds. So, your example should be a good one, should specify precisely how treatment assignment is correlated with the potential outcomes.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- FIX - XX: Most of our simple examples use random assignment. So, if fact, confoundedness is not a concern. But this knowledge drop, and perhaps the couple before, should address this topic, by pondering what we would worry about if treatment assignment had not been random.  -->


### Exercise 10

Summarize the state of your work so far in two or three sentences. Make reference to the data you have and to the question you are trying to answer. Feel free to copy from your answer at the end of the Wisdom Section. Mention one specific problem which casts doubt on your approach. 
```{r justice-10}
question_text(NULL,
	message = "FIX - XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `stops.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`, and then commit/push.


## Courage
### 

*Courage is the commitment to begin without any guarantee of success.* - Johann Wolfgang von Goethe


<!-- XX: Insert a sentence or two which reminds the student about the outcome variable and the key covariate(s), if any. Remind them of the variable type of the outcome variable. This sets the stage, in Exercise 2, for the discussion of the probability family. Also, remind them of the key covariate. Of course, in more advanced tutorials, we might consider including this material (and the probability family and link function knowledge drops below) as fodder for Exercises. But that is a step too far for now. -->

### Exercise 1

In your own words, describe the components of the virtue of Courage for analyzing data.

```{r courage-1}
question_text(NULL,
	message = "Courage starts with math, explores models, and then creates the Data Generating Mechanism.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

A statistical model consists of two parts: the *probability family* and the *link function*. The probability family is the probability distribution which generates the randomness in our data. The link function is the mathematical formula which links our data to the unknown parameters in the probability distribution. 

### Exercise 2

Load the **tidymodels** package.

```{r courage-2, exercise = TRUE}

```

```{r courage-2-hint-1, eval = FALSE}
library(...)
```

```{r courage-2-test, include = FALSE}
library(tidymodels)
```

### 

Because `arrested` is a binary variable, we assume that the outcome of getting arrested (or not) is produced from a Bernoulli distribution.

$$ arrested_i  \sim Bernoulli(\rho) $$

Note that "binomial" is another, more common, word for Bernoulli.


### Exercise 3

Load the **broom** package.

```{r courage-3, exercise = TRUE}

```

```{r courage-3-hint-1, eval = FALSE}
library(...)
```

```{r courage-3-test, include = FALSE}
library(broom)
```

### 

Because we are using a Bernoulli distribution, the link function is logit. That is:

$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 x_1 + \dots)}}$$

<!-- DK: What knowledge do we drop after giving the link formula? -->


### Exercise 4

Add `library(tidymodels)` and `library(broom)` to the `setup` code chunk in `stops.qmd`. Copy and paste the below code for the mathematical structure of the model to the body of `stops.qmd`. `Command/Ctrl + Shift + K`. 

```
$$ arrested_i  \sim Bernoulli(\rho) $$
$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 x_1 + \dots)}}$$
```

At the Console, run:

```
tutorial.helpers::show_file("stops.qmd", pattern = "tidymodels|broom|\\$\\$")
```

CP/CR.

```{r courage-4}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Of course, our model must make use of the variables we actually have. Consider:

$$\rho = \frac{1}{1 + e^{-(\beta_0 +\beta_1 sexmale + \dots)}}$$

<!-- FIX - Mention other important details here. For example, in a categorical or ordinal models, the probabilities must sum to 1. Also, we might only give the formula for one $\rho$. Mention that the other formulas would be the same, but with different parameters. -->


### Exercise 5

Because our outcome variable is binary, start to create the model by using `linear_reg()`.

```{r courage-5, exercise = TRUE}

```

```{r courage-5-hint-1, eval = FALSE}
linear_...()
```

```{r courage-5-test, include = FALSE}
linear_reg()
```

**Note:** This will give you an error that we will be fixing later.

### 

In data science, we deal with words, math, and code, but the most important of these is code. We created the mathematical structure of the model and then wrote a model formula in order to estimate the unknown parameters.


### Exercise 6

Continue the pipe with `set_engine("lm")`.

```{r courage-6, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-6-hint-1, eval = FALSE}
... |> 
  set_engine("...")
```

```{r courage-6-test, include = FALSE}
linear_reg() |> 
  set_engine("lm")
```

### 

<!-- FIX - Discuss alternate engines one might use instead. -->


### Exercise 7

We will be using the following formula:

```
arrested ~ sex + race + age + zone
```

Continue the pipe to `fit()`, pasting in the formula, and then adding the argument `data = stops_new`.

```{r courage-7, exercise = TRUE}

```

<button onclick = "transfer_code(this)">Copy previous code</button>

```{r courage-7-hint-1, eval = FALSE}
... |> 
  fit(arrested ~ ... + race + ... + zone, data = ...)
```

```{r courage-7-test, include = FALSE}
linear_reg() |>
  set_engine("lm") |>
  fit(arrested ~ sex + race + age + zone, data = stops_new)
```

### 

<!-- FIX - Should we have a knowledge drop here? Maybe just state misc. stuff -->


### Exercise 8

Behind the scenes of this tutorial, an object called `fit_stops` has been created which is the result of the code above. Type `fit_stops` and hit "Run Code." This generates the same results as using `print(fit_stops)`.


```{r courage-8, exercise = TRUE}

```

```{r courage-8-hint-1, eval = FALSE}
fit_stops
```

```{r courage-8-test, include = FALSE}
fit_stops
```

### 

The Intercept parameter indicates when `sexmale = 0`, i.e. it indicates females on average. 

Simplified, the age parameter is showing that if one person is 10 years older than another person, they are roughly -2.5% more likely (i.e. 2.5% less likely) to get arrested compared to the person 10 years younger.

### Exercise 9

Create a new code chunk in `stops.qmd`. Add two code chunk options: `label: model` and `cache: true`. Copy/paste the code from above for estimating the model into the code chunk, assigning the result to `fit_stops`. 

`Command/Ctrl + Shift + K`. It may take some time to render `stops.qmd`, depending on how complex your model is. But, by including `cache: true` you cause Quarto to cache the results of the chunk. The next time you render `stops.qmd`, as long as you have not changed the code, Quarto will just load up the saved fitted object.

To confirm, `Command/Ctrl + Shift + K` again. It should be quick.

At the Console, run:

```
tutorial.helpers::show_file("stops.qmd", start = -8)
```

CP/CR.

```{r courage-9}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 8)
```

### 

<!-- FIX - Again, what do we add here? -->

### Exercise 10

<!-- XX: You may use other arguments to tidy if that is useful. -->

Run `tidy()` on `fit_stops` with the argument `conf.int` set equal to `TRUE`. The returns 95% intervals for all the parameters in our model.

```{r courage-10, exercise = TRUE}

```

```{r courage-10-hint-1, eval = FALSE}
tidy(..., conf.int = ...)
```

```{r courage-10-test, include = FALSE}
tidy(fit_stops, conf.int = TRUE)
```

### 

<!-- FIX - 

XX: Add at least three questions which require the student to interpret the meanings of a parameter estimate and/or its associated confidence interval. These questions also feature good opportunities to knowledge drop about the meaning of intervals (credible versus confidence versus uncertainty) and about Frequentist versus Bayesian interpretations. See https://ppbds.github.io/primer/cardinal-virtues.html#confidencecredibleuncertainty-intervals-->

<!-- XX: The key point is that predictive models involve comparisons *between different rows* in the Preceptor Table while causal models involve subtraction between two potential outcomes *within the same row*. Of course, we are rarely interested in comparing just two rows or in looking at the difference in potential outcomes within just one row. -->

<!-- That is, we don't ask: How does Sam's height differ from John's? We ask about the difference in average height between people from New York (where Sam is from) and people in Boston (which John is from). We don't ask: What is the causal effect for Sarah? We ask: What is the average causal effect for all the people in Florida (where Sarah is from)? -->

<!-- Consider some example questions and answers, along with comments about the larger picture, all based on this display. This is good for linear (meaning the Gaussian family) models. For other models, see the comments below. -->

<!-- ```{r} -->
<!-- linear_reg() |> -->
<!--   set_engine("lm") |> -->
<!--   fit(att_end ~ sex + treatment + age, data = trains) |> -->
<!--   tidy(conf.int = TRUE) -->
<!-- ``` -->


<!--   term             estimate std.error statistic  p.value conf.low conf.high -->
<!--   <chr>               <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl> -->
<!-- 1 (Intercept)       11.0       0.962     11.4   1.86e-20   9.09     12.9    -->
<!-- 2 sexMale           -0.829     0.523     -1.59  1.16e- 1  -1.86      0.207  -->
<!-- 3 treatmentControl  -1.41      0.529     -2.67  8.73e- 3  -2.46     -0.364  -->
<!-- 4 age               -0.0143    0.0217    -0.660 5.11e- 1  -0.0572    0.0286 -->

<!-- Q: Write a sentence interpreting the -0.83 estimate for sexMale. -->

<!-- A: When comparing men with women, men have a 0.83 lower value for att_end, meaning that they are more liberal about immigration, relative to women, conditional on the other variables in the model. -->

<!-- Comment 1: Note how, whenever we consider non-treatment variables, we must never use terms like "cause," "impact" and so on. We can't make any statement which implies the existence of more than one potential outcome based on changes in non-treatment variables. We can't make any claims about within row effects. Instead, we can only compare across rows. Always use the phrase "when comparing X and Y" or something very similar. -->

<!-- Comment 2: The phrase "conditional on the other variables in the model" is important. It could be shortened to "conditional on the model." This phrase acknowledges that there are many, many possible models, just considering all the different combinations of independent variables we might include. Each one would produce a different coefficient for sexmale. None of these is the *true* coefficient. Any claim we make about  -0.83, or any specific number, is always conditional on the fact that we assume that this model is true, that these covariates, and no others, belong in the regression. Does that mean that we always use the phrase? No. We leave it out all the time. But it is always understood to be there by knowledgeable readers. Still, this is probably a point worth making in various knowledge drops. -->

<!-- Q: Write a sentence interpreting the confidence interval for sexMale. -->

<!-- A: We do not know the true value for the coefficient for sexMale, but we can be 95% confident that it lies somewhere between -1.86  and 0.21.  -->

<!-- Comment 1: Because we are Bayesians, we believe that there is a true value and that the confidence or credible or uncertainty interval includes it at the stated level. These questions provide an occasion in the knowledge drop to compare/contrast the Frequenist interpretation. See: https://ppbds.github.io/primer/cardinal-virtues.html#confidencecredibleuncertainty-intervals -->

<!-- Comment 2: Most of the time parameters in a model have no direct relationship with any population parameter which we might be interested. This is especially true in complex and/or non-linear models. That is, in those cases, a coefficient like $\beta_1$ does not "mean" anything. But, in simple, small, linear models, it sometimes happens that a parameter does correspond to something real. In this case, the coefficient of sexmale does correspond to the difference between the population average of att_end between men and women, adjusting for the other variables in the model. -->

<!-- Q: Write a sentence interpreting the -1.41  estimate for treatmentControl. -->

<!-- A: If this is a causal model, then the average causal effect of receiving the treatment of hearing Spanish-speakers on the train platform, relative to the control, is to have a 1.41  higher value for att_end, meaning that the treatment, relative to the control, makes one more conservative about immigration. (Note that you need to keep track of signs and of which 0/1 variable is being used.) -->

<!-- A 2: If this is a predictive model, then, if we compare people who receive the treatment with people who receive the control, the treated people have, on average, a 1.41 more conservative attitude toward immigration, adjusting for other individual characteristics. -->

<!-- Comment 1: The interpretation of a treatment variable is very different than the interpretation of a standard covariate. Whenever your model includes a treatment variable, you must always have a question about it and about the associated confidence interval. -->

<!-- Comment 2: The key point is that there is no such thing as a causal (versus preditive) data set nor a causal (versus predictive) R code formula. You can use the same data set (and the same R code!) for both causal and predictive models. The difference lies in the assumptions you make.  -->

<!-- Q: Write one sentence interpreting the -2.46 to -0.36 interval for the treatmentControl coefficient. -->

<!-- A: Our best estimate for the average causal effect is -1.41, meaning that being treated makes someone 1.41 units more conservative about immigration. Yet, the true value could be lower or higher. We are 95% certain that the true effect is somewhere between -2.46 to -0.36.  -->

<!-- Comment: It is OK if our answers are slightly longer than what we might expect from students, as long as those answers are *tight*, meaning that no word is wasted. In this case, the first two sentences are an attempt to ensure that the student understands what is going on. The last sentence is what we might expect students to write.  -->

<!-- Q: Write a sentence interpreting the -0.01 estimate for age.  -->

<!-- A: If we compare one group of people ten years older than another, the older group will, on average, have an attitude toward immigration 0.1 unit lower, i.e., less conservative. -->

<!-- Comment 1: Numeric variables are harder than binary variables because there are no longer just two well-defined groups to compare with each other. We must make those two groups ourselves. Fortunately, as long as there are no interaction terms, we can just pick two groups with any values for the variable. The most common two groups differ by one unit of the variable. But it is quite common to use groups which differ by more/less if doing so seems sensible and/or if it makes the math easier. In this case, two groups which differ by 10 years makes sense for both reasons. -->

<!-- What about non-linear models, or linear models with lots of interaction terms? -->


<!-- logistic_reg() |>  -->
<!--   set_engine("glm") |>  -->
<!--   fit(as.factor(arrested) ~ sex + race, data = stops) |>  -->
<!--   tidy(conf.int = TRUE) -->

<!--   term         estimate std.error statistic  p.value conf.low conf.high -->
<!--   <chr>           <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl> -->
<!-- 1 (Intercept)   -2.56     0.0633    -40.5   0         -2.69     -2.44   -->
<!-- 2 sexmale        0.368    0.00861    42.8   0          0.352     0.385  -->
<!-- 3 raceblack      1.19     0.0631     18.8   6.16e-79   1.07      1.31   -->
<!-- 4 racehispanic   0.805    0.0676     11.9   1.05e-32   0.674     0.939  -->
<!-- 5 raceother      0.337    0.192       1.76  7.89e- 2  -0.0537    0.700  -->
<!-- 6 raceunknown   -0.0824   0.0913     -0.902 3.67e- 1  -0.262     0.0965 -->
<!-- 7 racewhite      0.928    0.0635     14.6   1.88e-48   0.806     1.05   -->


<!-- With a linear model, all these interpretations are fairly straightforward. With any other type of model, the math is too difficult to do in your head. You can't just look at a coefficient of 5 and know what it means in magnitude. But you can tell the direction, that a positive 5 means that higher values of the variable are associated with higher values of the outcome variable. So, with anything other than linear models, we restrict ourselves to direction and significance interpretations. -->

<!-- Q: Write a sentence interpreting the 0.37 estimate for Sexmale. -->

<!-- A: In comparison with women, men are more likely to be arrested. -->

<!-- Comment 1: Categorical variables (with N categories), like sex (with two values),  are always replaced with (N-1) 0/1 dummy variables like sexMale. Students are often confused about this point, so we should make it a knowledge drop in every tutorials. -->

<!-- Comment 2: We can't (easily) know how big 0.37 is. Because the model is non-linear, you can't (easily) determine whether men are 1% or 50% more likely to be arrested. -->

<!-- Q: Write a sentence interpreting the 1.07 to 1.31 confidence interval for raceblack. -->

<!-- A: In comparison with Asian/Pacific Islanders, Blacks are more likely to be arrested. In fact, they are more likely to be arrested than any other racial group. -->

<!-- Comment 1: Dummy variables must always be interpreted in the context of the base value for that variable, which is always included in the intercept. For example, the base value here is "asian/pacific islander." (The base value is the first alphabetically by default for character variables. However, if it is a factor variable, you can change that by setting the order of the levels by hand.) -->

<!-- Comment 2:  We look for two things in the confidence interval. First, does it exclude zero? If not, then we can't be sure if the relationship is positive or negative. Second, does it overlap with the confidence intervals for other dummy columns derived from this variable? If so, then we can be sure that the ordering as to which comparisons are bigger. If there is overlap, as for examle between raceother and raceunknow, we can't be sure how the average comparison would go. Because the estimate for raceother > the estimate for raceunknown, our best guess is that others are more likely to be arrested. But, because the confidence intervals overlap, there is a good chance (more than 5% certainly) that the ordering is the opposite. -->


### Exercise 11

<!-- XX: We still have some details to worry about in terms of what the table should look like. Not sure on the best approach. If we use the gt() package, we need to load it. Maybe we just give all the code, includeing library(gt), and then can just copy it in. Ought to get rid of the statistic and p.value columns. -->

Create a new code chunk in `stops.qmd`. Add a code chunk option: `label: table`. Add this code to the code chunk.

```
tidy(fit_stops, conf.int = TRUE)
```


`Command/Ctrl + Shift + K`. 

At the Console, run:

```
tutorial.helpers::show_file("stops.qmd", start = -4)
```

CP/CR.

```{r courage-11}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### Exercise 12

Write a few sentence which summarize your work so far. The first few sentences are the same as what you had at the end of the Justice Section. Add one sentence which describes the modelling approach which you are using, specifying the functional form and the dependent variable. Add one sentence which describes the *direction* (not the magnitude) of the relationship between one of your independent variables and your dependent variable.

```{r courage-12}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

## Temperance
### 

*Temperance is a bridle of gold; he, who uses it rightly, is more like a god than a man.* - Robert Burton


### Exercise 1

In your own words, describe the use of Temperance in data science.

```{r temperance-1}
question_text(NULL,
	message = "Temperance uses the Data Generating Mechanism to answer the question with which we began. Humility reminds us that this answer is always a lie.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Courage gave us the data generating mechanism. Temperance guides us in the use of the DGM — or the “model” — we have created to answer the questions with which we began. We create posteriors for the quantities of interest. We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.


### Exercise 2

Load the [**marginaleffects**](https://marginaleffects.com/) package.

```{r temperance-2, exercise = TRUE}

```

```{r temperance-2-hint-1, eval = FALSE}
library(...)
```

```{r temperance-2-test, include = FALSE}
library(marginaleffects)
```

### 

<!-- FIX - Knowledge Drop? -->


### Exercise 3

What is the general topic we are investigating? What is the specific question we are trying to answer? 

```{r temperance-3}
question_text(NULL,
	message = "We are generally investigating the likelihood of getting arrested during a Traffic Stop in New Orleans. FIX - update the specific question.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Data science projects almost always begin with a broad topic of interest. Yet, in order to make progress, we need to drill down to a specific question. This leads to the creation of a data generating mechanism, which can now be used to answer lots of questions, thus allowing us to explore the original topic broadly.


### Exercise 4

To answer our question, we need to create an object --- call it `ndata` --- which we will pass in as a value to the `newdata` argument in whichever **marginaleffects** functions we decide to use. Which variables (e.g., which columns) do we need to include in this object?

```{r temperance-4}
question_text(NULL,
	message = "We need to include the variables `race`, `sex`, `age`, and `zone` in our `ndata` Tibble.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.


### Exercise 5

<!-- XX: Sometimes useful to think about this question and the number of posterior questions together, or event to reverse them. -->

Which values do you want the variables in your `ndata` object to have? This is not easy! At the very least, one or more of the rows should have values which allow you to answer your original question. But, now that you have a model, there are many questions which you might want to answer, the better to get a fuller understanding.

```{r temperance-5}
question_text(NULL,
	message = "FIX - XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

<!-- XX: Chapter 10 is a great example of this in its full complexity. We want to know how "different" units behave, where the very definition of "different" is that they do not have identical values for all the variables used in fit_stops. -->

<!-- For example, one row in ndata will generally represent the answer to the specific question we started with. But that is just the posterior for one sort of unit. There are lots of different units! Which others might we be interested in? We can generate posteriors for each of them, and then, in some cool graphic, display all those posteriors together. -->

<!-- Note that, previously, this document claimed that the number of rows in ndata corresponded to the number of posteriors you wanted to calculate. But that is not true! -->


### Exercise 6

Here is the R code which creates the `ndata` object: 

```
expand_grid(race = unique(stops_new$race),
            sex = unique(stops_new$sex),
            age = mean(stops_new$age),
            zone = unique(stops_new$zone))
```

Notice how we're using the mean age to calculate with, as we don't want different graphs relating to different ages, so it would be convenient to have every other parameter using the mean age rather than separate ages.

Type the code into the code exercise block and hit "Run Code."

```{r temperance-6, exercise = TRUE}

```

```{r temperance-6-hint-1, eval = FALSE}

```

```{r temperance-6-test, include = FALSE}

```

### 

<!-- SD: What does "XX" mean here? -->

It is best to ensure that the variable types in `ndata` match the variable types on `XX`. The easiest way to ensure that is by using `XX` itself in the creation `ndata`. 


### Exercise 7

Behind the scenes, we have created the `ndata` object using this code. To confirm, type `ndata` and hit "Run Code."

```{r temperance-7, exercise = TRUE}

```

```{r temperance-7-hint-1, eval = FALSE}
ndata
```

```{r temperance-7-test, include = FALSE}
ndata
```

### 

Functions like `unique()` --- to grab all the possible values in a variable --- and `expand_grid()` --- to create all possible combinations of different variables --- are often useful in creating `ndata`.


### Exercise 8

Add `library(marginaleffects)` to the `stops.qmd` setup code chunk. Create a new code chunk in `stops.qmd` which creates the `ndata` object. Don't forget to add `#| label: ndata` to this chunk. `Command/Ctrtl + Shift + K`.

At the Console, run:

```
tutorial.helpers::show_file("stops.qmd", pattern = "marginaleffects|ndata")
```

CP/CR.

```{r temperance-8}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

<!-- FIX - Again, the main point of knowledge drops is this area is to explain to students why the ndata object looks the way it does and what it will produce. A great way to teach is via example. That is, explaining that if we had another way with these values, then we would get this posterior. Or, explaining what would be produced if we used add_epred instead of add_predict, and vice verse. -->


### Exercise 9

Enter this code into the exercise code block and hit "Run Code."

```
plot_predictions(fit_stops,
                 newdata = ndata,
                 by = c("sex", "race", "zone")) +
  labs(title = "Likelihood of Arrest by Race in New Orleans, Zones A & X",
       subtitle = "Asian/Pacific Islander and Hispanic have higher uncertainty as there is less data regarding these races.",
       x = "Sex",
       y = "% Likelihood of Arrest",
       color = "Race",
       caption = "Data from the Open Policing Project by Stanford")
```

```{r temperance-9, exercise = TRUE}

```

```{r temperance-9-hint-1, eval = FALSE}
plot_predictions(fit_stops,
                 newdata = ndata,
                 by = c("sex", "race", "zone")) +
  labs(title = "Likelihood of Arrest by Race in New Orleans, Zones A & X",
       subtitle = "Asian/Pacific Islander and Hispanic have higher uncertainty as there is less data regarding these races.",
       x = "Sex",
       y = "% Likelihood of Arrest",
       color = "Race",
       caption = "Data from the Open Policing Project by Stanford")
```

```{r temperance-9-test, include = FALSE}
plot_predictions(fit_stops,
                 newdata = ndata,
                 by = c("sex", "race", "zone")) +
  labs(title = "Likelihood of Arrest by Race in New Orleans, Zones A & X",
       subtitle = "Asian/Pacific Islander and Hispanic have higher uncertainty as there is less data regarding these races.",
       x = "Sex",
       y = "% Likelihood of Arrest",
       color = "Race",
       caption = "Data from the Open Policing Project by Stanford")
```

### 

<!-- FIX - There are a lot of interesting options in plot_predictions. Check them out. You may want to use some of them in your plot. I think `points` is quite interesting. Feel free to add a couple more questions which add some options. Also, feel free to use the standard ggplot() commands, like `labs()`, to modify the plot. We want to encourage students to create publication-quality graphics.  -->

<!-- XX: If such a plot would be complex and/or the tutorial is long enough, you can just include all the code for a plot in the exercise code chunk and tell students to just press "Run Code." This will, at least, allow them to see what a good plot looks like. -->


### Exercise 10

Create a new code chunk in `stops.qmd`. Label it with `label: plot`. Copy/paste the code which creates your graphic. 

`Command/Ctrl + Shift + K` to ensure that it all works as intended.

At the Console, run:

```
tutorial.helpers::show_file("stops.qmd", start = -8)
```

CP/CR.

```{r temperance-10}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

### Exercise 11

Write a paragraph which summarizes the project in your own words. The first few sentences are the same as what you had at the end of the Courage section. But, since your question may have evolved, you should feel free to change those sentences. Add at least one sentence which describes at least one quantity of interest (QoI) and which provides a measure of uncertainty about that QoI. (It is OK if this QoI is not the one that you began with. The focus of a data science project often changes over time.)

<!-- XX: Most of the time, there will be some measure of uncertainty associated with your QoI. But not always! The most common counter-example involves a question which asks about the odds or probability of something happening. We would answer such a question by simulating the event with `add_predicted_draws()`. We would then calculate the odds/probability of something happening by seeing how many of the 4,000 draws met the criteria for the event. Assume that was 40%. So, we think that there is a 40% chance that event A will happen. Yet there is no uncertainty associated with that estimate because it, itself, is an expression of uncertainty. But, the vast majority of projects are not concerned with individual prediction. Instead, they focus on expected/average values. -->

```{r temperance-11}
question_text(NULL,
	message = "XX",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

Edit the summary paragraph in `stops.qmd` as you see fit, but do not copy/paste our answer exactly. `Command/Ctrl + Shift + K`.


<!-- XX: Again, spend time to make your recommended paragraph perfect. Study the examples in https://ppbds.github.io/primer/cardinal-virtues.html closely. -->

### Exercise 12

Write a few sentences which explain why the estimates for the quantities of interest, and the uncertainty thereof, might be wrong. Suggest an alternative estimate and confidence interval, if you think either might be warranted.

```{r temperance-12}
question_text(NULL,
	message = "XX: This is another example in which the quality of your answer is important. You might or might not suggest an alternate estimate. I always adjust the estimate toward my own subjective sense of a long-run average and/or typical value and/or zero. But that is not necessary. However, you should always increase the confidence interval since the assumptions of your model are always false.",
	answer(NULL, correct = TRUE),
	allow_retry = FALSE,
	incorrect = NULL,
	rows = 6)
```

### 

### Exercise 13

Rearrange the material in `stops.qmd` so that the order is graphic, paragraph, math and table. Doing so, of course, requires sensible judgment. For example, the code chunk which creates the fitted model must occur before the chunk which creates the graphic. `Command/Ctrl + Shift + K` to ensure that everything works.

At the Console, run:

```
tutorial.helpers::show_file("stops.qmd")
```

CP/CR.

```{r temperance-13}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

### 

Add `rsconnect` to the `.gitignore` file. You don't want your personal Rpubs details stored in the clear on Github. Commit/push everything.


### Exercise 14

Publish `stops.qmd` to Rpubs. Choose a sensible slug. Copy/paste the url below.

```{r temperance-14}
question_text(NULL,
	answer(NULL, correct = TRUE),
	allow_retry = TRUE,
	try_again_button = "Edit Answer",
	incorrect = NULL,
	rows = 3)
```

## Summary
### 

This tutorial covered [Chapter XX: XX](https://ppbds.github.io/primer/XX.html) of [*Preceptor’s Primer for Bayesian Data Science: Using the Cardinal Virtues for Inference*](https://ppbds.github.io/primer/) by [David Kane](https://davidkane.info/). 



```{r download-answers, child = system.file("child_documents/download_answers.Rmd", package = "tutorial.helpers")}
```
